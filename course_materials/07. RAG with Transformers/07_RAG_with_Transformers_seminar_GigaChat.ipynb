{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHvoxJKaeSfy","outputId":"2794ec6d-36f2-47da-ec61-561a5f8f2d42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gigachat\n","  Downloading gigachat-0.1.42.post2-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (0.28.1)\n","Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (2.11.10)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (2.33.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.4.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1->gigachat) (1.3.1)\n","Downloading gigachat-0.1.42.post2-py3-none-any.whl (69 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gigachat\n","Successfully installed gigachat-0.1.42.post2\n","Collecting pypdf\n","  Downloading pypdf-6.1.2-py3-none-any.whl.metadata (7.1 kB)\n","Downloading pypdf-6.1.2-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-6.1.2\n","Collecting langchain-gigachat\n","  Downloading langchain_gigachat-0.3.12-py3-none-any.whl.metadata (3.0 kB)\n","Collecting langchain-chroma\n","  Downloading langchain_chroma-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n","Collecting langchain-core\n","  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (0.3.11)\n","Collecting langchain-text-splitters\n","  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting langchain-community\n","  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: gigachat<0.2.0,>=0.1.41.post1 in /usr/local/lib/python3.12/dist-packages (from langchain-gigachat) (0.1.42.post2)\n","Collecting types-requests<3.0,>=2.32 (from langchain-gigachat)\n","  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n","Collecting chromadb<2.0.0,>=1.0.20 (from langchain-chroma)\n","  Downloading chromadb-1.2.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","INFO: pip is looking at multiple versions of langchain-chroma to determine which version is compatible with other requirements. This could take a while.\n","Collecting langchain-chroma\n","  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma) (2.0.2)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.35)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.11.10)\n","INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n","Collecting langchain-community\n","  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n","Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n","  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.0)\n","Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.0)\n","Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.37.0)\n","Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n","Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.22.1)\n","Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.67.1)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.75.1)\n","Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.19.2)\n","Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Collecting mmh3>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.11.3)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (13.9.4)\n","Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.25.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.2.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.16.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.27.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.38.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.0.0)\n","Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.32.5->langchain-community)\n","  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (25.9.23)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.13.3)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.7.0)\n","Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.70.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.19.2)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.35.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.3.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.5.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n","Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (15.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.1.10)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.23.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.1.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.3.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.6.1)\n","Downloading langchain_gigachat-0.3.12-py3-none-any.whl (27 kB)\n","Downloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n","Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chromadb-1.2.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.4/20.4 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n","Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=a4717335b028f9684366ed3971889cf8d92aa005b5ddb1e0b2ed9547e34386aa\n","  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, types-requests, requests, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, dataclasses-json, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-gigachat, chromadb, langchain-chroma, langchain-community\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.5.0\n","    Uninstalling urllib3-2.5.0:\n","      Successfully uninstalled urllib3-2.5.0\n","  Attempting uninstall: opentelemetry-proto\n","    Found existing installation: opentelemetry-proto 1.37.0\n","    Uninstalling opentelemetry-proto-1.37.0:\n","      Successfully uninstalled opentelemetry-proto-1.37.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.4\n","    Uninstalling requests-2.32.4:\n","      Successfully uninstalled requests-2.32.4\n","  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n","    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n","    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n","      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n","  Attempting uninstall: opentelemetry-api\n","    Found existing installation: opentelemetry-api 1.37.0\n","    Uninstalling opentelemetry-api-1.37.0:\n","      Successfully uninstalled opentelemetry-api-1.37.0\n","  Attempting uninstall: opentelemetry-semantic-conventions\n","    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n","    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n","      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n","  Attempting uninstall: opentelemetry-sdk\n","    Found existing installation: opentelemetry-sdk 1.37.0\n","    Uninstalling opentelemetry-sdk-1.37.0:\n","      Successfully uninstalled opentelemetry-sdk-1.37.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n","google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.2.0 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-chroma-0.2.6 langchain-community-0.3.31 langchain-gigachat-0.3.12 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.1 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 requests-2.32.5 types-requests-2.32.4.20250913 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"]}],"source":["!pip install gigachat\n","!pip install pypdf\n","!pip install -U langchain-gigachat langchain-chroma langchain-core langchain-text-splitters langchain-community\n"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub\")"],"metadata":{"id":"DTfOnaoHrC8T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GigaChat RAG example\n","\n","Let us build a RAG system, which uses GigaChat.\n","\n","## GigaChat basic usage exmaple\n"],"metadata":{"id":"1xWLWcySo68Y"}},{"cell_type":"markdown","source":["Fist, we need to initialize a GigaChat model."],"metadata":{"id":"Z5MRQ-z9pMMl"}},{"cell_type":"code","source":["from gigachat import GigaChat\n","token = 'YOUR_TOKEN'\n","print(len(token))\n","giga = GigaChat(\n","   credentials=token,\n","   scope=\"GIGACHAT_API_PERS\",\n","   model=\"GigaChat-2-Max\",\n","   verify_ssl_certs=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xe3k9xdweXhP","outputId":"83d7a144-451b-45b7-856c-03111ddde935"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n"]}]},{"cell_type":"markdown","source":["Basic usage."],"metadata":{"id":"lFaTTqdwpYlg"}},{"cell_type":"code","source":["text = \"Какие риски при использовании LLM?\"\n","response = giga.chat(text)\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADZrLMmfeiHq","outputId":"b4172846-d1c2-4db8-d9f9-340cf04ec1fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Использование больших языковых моделей (LLM), таких как GPT-4, BERT, PaLM и другие подобные модели, связано с рядом рисков и проблем. Вот наиболее важные из них:\n","\n","### 1. **Генерация недостоверной информации («галлюцинация»)**\n","   Языковые модели иногда генерируют правдоподобную, но ложную информацию, поскольку работают исключительно на основе статистического анализа текста и не имеют встроенных механизмов проверки фактов. Это особенно опасно в сферах медицины, права, финансов и науки, где ошибка может привести к серьезным последствиям.\n","   \n","### 2. **Непредсказуемость поведения модели**\n","   Несмотря на наличие предварительной настройки и фильтраций, модели могут неожиданно выдавать некорректный или неуместный контент: шутки на деликатные темы, дискриминационные высказывания, сексистские или расистские утверждения. Особенно рискованно использование моделей в публичных сервисах без должного контроля и фильтрации.\n","\n","### 3. **Утечка конфиденциальной информации**\n","   Если пользователи вводят личные данные, коммерческую тайну или другую чувствительную информацию в диалоги с моделью, существует риск её случайного сохранения или обработки моделью. Даже защищённые системы хранения данных уязвимы перед атаками злоумышленников.\n","\n","### 4. **Плагиат и авторское право**\n","   Модели часто используют тексты из интернета для формирования своего понимания мира. Иногда они воспроизводят фрагменты исходных источников без надлежащей атрибуции, что нарушает авторские права владельцев оригинального контента.\n","\n","### 5. **Манипуляция общественным мнением**\n","   Возможность создавать убедительные аргументы и фальсифицированные материалы делает такие модели инструментом манипуляции массовым сознанием — от распространения дезинформации до влияния на выборы через соцсети.\n","\n","### 6. **Технологические ограничения**\n","   Некоторые крупные языковые модели требуют значительных вычислительных ресурсов для работы, что ограничивает доступ к ним и увеличивает расходы компаний-разработчиков и пользователей.\n","\n","### 7. **Этика и безопасность**\n","   Этика взаимодействия с моделями ещё недостаточно изучена. Например, неясно, насколько допустимо использовать эти технологии для принятия решений, влияющих на жизнь людей (например, медицинские диагнозы).\n","\n","### 8. **Регулирование и нормативная база**\n","   В разных странах подходы к регулированию ИИ различаются. Отсутствие чётких правил и стандартов может приводить к злоупотреблениям и несправедливости в отношении отдельных групп населения.\n","\n","---\n","\n","Эти проблемы становятся всё более значимыми по мере расширения сфер применения больших языковых моделей, и разработчики постоянно ищут пути минимизации указанных рисков.\n"]}]},{"cell_type":"code","source":["text = \"Что такое задача понижения размерности?\"\n","response = giga.chat(text)\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4RObk6enq3L","outputId":"de760d79-13ca-47be-a6df-3c415b5fc091"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Задача понижения размерности (Dimensionality Reduction) — это метод обработки многомерных данных, направленный на уменьшение количества признаков (размерности пространства), сохраняя наиболее значимую информацию. Она помогает упростить структуру данных, улучшить интерпретируемость моделей машинного обучения и уменьшить вычислительные затраты.\n","\n","## Основные цели снижения размерности:\n","- **Уменьшение избыточности**: устранение дублирования информации между признаками.\n","- **Повышение производительности алгоритмов**: снижение временных затрат на обучение и работу модели.\n","- **Снижение вероятности переобучения** («проклятие размерности»).\n","- **Облегчение визуализации данных**, особенно когда исходное пространство имеет высокую размерность.\n","  \n","## Методы снижения размерности:\n","### Линейные методы:\n","1. **PCA (Principal Component Analysis)** — один из популярных методов, который находит новые оси координат, максимизирующие дисперсию данных.\n","   \n","   *Пример:* Представьте набор изображений рукописных цифр размером 64×64 пикселя (всего 4096 признаков). С помощью PCA можно представить эти данные в пространстве меньшего числа главных компонент, сохранив основную вариативность объектов.\n","\n","2. **LDA (Linear Discriminant Analysis)** — применяется для классификации, ориентируется на разделение классов путем минимизации внутриклассовых расстояний и увеличения межклассовых дистанций.\n","\n","### Нелинейные методы:\n","1. **t-SNE (t-Distributed Stochastic Neighbor Embedding)** — используется преимущественно для визуализации, отображая сходство точек из многомерного пространства в двухмерной плоскости.\n","   \n","2. **Autoencoders** — глубокие нейронные сети, способные извлекать скрытые представления данных через сжатое промежуточное представление.\n","\n","Таким образом, задача понижения размерности позволяет значительно сократить количество переменных, необходимых для описания объекта, одновременно уменьшая сложность и повышая эффективность анализа данных.\n"]}]},{"cell_type":"markdown","source":["### RAG\n","\n","For GigaChat we will use `langchain_gigachat` instead of the vanilla `langchain`, which is the official integration between GigaChat and LangChain.\n","\n","It provides LangChain-compatible classes so you can use GigaChat in:\n","* Retrieval-Augmented Generation (RAG)\n","* LCEL (LangChain Expression Language)\n","* Agents & Tools\n","* Chains (like RetrievalQA, LLMChain)\n","* Vector stores and document QA"],"metadata":{"id":"tgx7owlwproB"}},{"cell_type":"code","source":["# Imports\n","import os\n","from glob import glob\n","from langchain_core.documents import Document\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_chroma import Chroma\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n","from langchain_core.embeddings import Embeddings\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.chains import RetrievalQA\n","\n","from sentence_transformers import SentenceTransformer\n"],"metadata":{"id":"e2C2mbv_fedZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Russian Embedder\n","To work with Russian documents we need a Russian embedder model. Today, we will use [FRIDA](https://huggingface.co/ai-forever/FRIDA), which is a good Russian-English embedder.\n","\n","FRIDA was trained for several embedding tasks with special prefixes, which indicate the embedding type.\n","\n","For retrieval the following prefixes are used:\n","* `search_query`: for queries\n","* `search_document`: for documents\n"],"metadata":{"id":"bhUbqiuGks-J"}},{"cell_type":"code","source":["import torch\n","class FridaEmbeddings(Embeddings):\n","\n","    def __init__(self, model_name = \"ai-forever/FRIDA\"):\n","        self.model = SentenceTransformer(model_name)\n","\n","        # Device handling\n","        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = self.model.to(device)\n","        self.device = device\n","\n","    def embed_documents(self, texts):\n","        texts = [f\"search_document: {t}\" for t in texts]\n","        # convert_to_numpy=True возвращает np.ndarray; tolist() -> list[list[float]]\n","        return self.model.encode(texts, normalize_embeddings=True, convert_to_numpy=True).tolist()\n","\n","    def embed_query(self, text):\n","        return self.model.encode(f\"search_query: {text}\",\n","                                 normalize_embeddings=True, convert_to_numpy=True).tolist()\n"],"metadata":{"id":"7d4QBFCOh82u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# select which embeddings we want to use\n","from langchain.embeddings import HuggingFaceEmbeddings\n","embedding_model_name = \"ai-forever/FRIDA\"\n","embeddings = FridaEmbeddings(model_name=embedding_model_name)"],"metadata":{"id":"FlO7quWBiyDT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Documents\n","\n"],"metadata":{"id":"wLyY8VYBjTT7"}},{"cell_type":"code","source":["! wget https://raw.githubusercontent.com/esokolov/ml-course-hse/master/2025-fall/lecture-notes/lecture01-intro.pdf -O lecture01-intro.pdf\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mFRMZ-Oj2Zx","outputId":"357dad84-80e4-48c6-9391-b6635deabff2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-10-19 14:11:20--  https://raw.githubusercontent.com/esokolov/ml-course-hse/master/2025-fall/lecture-notes/lecture01-intro.pdf\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 134730 (132K) [application/octet-stream]\n","Saving to: ‘lecture01-intro.pdf’\n","\n","lecture01-intro.pdf 100%[===================>] 131.57K  --.-KB/s    in 0.01s   \n","\n","2025-10-19 14:11:20 (9.30 MB/s) - ‘lecture01-intro.pdf’ saved [134730/134730]\n","\n"]}]},{"cell_type":"markdown","source":["RAG-system is build on the first [ML-lecture notes](https://github.com/esokolov/ml-course-hse/blob/master/2025-fall/lecture-notes/lecture01-intro.pdf) from HSE ML-course."],"metadata":{"id":"PfMByk9krNJ4"}},{"cell_type":"code","source":["# load document\n","loader = PyPDFLoader(\"lecture01-intro.pdf\")\n","documents = loader.load()"],"metadata":{"id":"hUQAK2vSjWNn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vector database"],"metadata":{"id":"LMsgsFpUiadL"}},{"cell_type":"markdown","source":["`RecursiveCharacterTextSplitter` is a text-splitting utility from LangChain designed to divide long documents into manageable chunks while preserving as much semantic meaning and context as possible.\n","\n","**What it does?**\n","\n","It takes long text and splits it into smaller pieces (chunks) using a recursive hierarchy of separators (like paragraphs → sentences → words → characters).\n","\n","**This ensures:**\n","\n","* Chunks are within a maximum token or character limit.\n","* Text is split at logical boundaries whenever possible.\n","* Only if no larger boundaries exist, it splits more aggressively.\n","\n","**Why it’s useful**\n","\n","Language models have context length limits (like 4k, 8k, 32k tokens).\n","To use long texts in RAG, summarization, embedding, or indexing, you must split them.\n","\n","RecursiveCharacterTextSplitter is preferred because:\n","* Smarter than simple character splitting\n","* Keeps sentences and paragraphs intact when possible\n","* Handles multilingual and noisy text well\n","* Supports overlaps to preserve context across chunks"],"metadata":{"id":"9O4oH7NKiPJt"}},{"cell_type":"code","source":["splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=120)\n","docs = splitter.split_documents(documents)"],"metadata":{"id":"4pfavcSyiEH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the vectorestore to use as the index\n","db = Chroma.from_documents(docs, embeddings)"],"metadata":{"id":"uXuDLi0gjF2e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Retriever"],"metadata":{"id":"yBXb7-9SlSB-"}},{"cell_type":"code","source":["retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"],"metadata":{"id":"3LU1lSdAkU9j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Gigachat\n","\n","**Warning!** To use GigaChat for RAG we need a langchain-compatible variant:\n","\n","`from langchain_gigachat import GigaChat as LC_GigaChat`"],"metadata":{"id":"sTkXBc7dlZWd"}},{"cell_type":"code","source":["from langchain_gigachat import GigaChat as LC_GigaChat\n","llm = LC_GigaChat(\n","    credentials=token,\n","    scope=\"GIGACHAT_API_PERS\",\n","    verify_ssl_certs=False,           # для тестовой среды\n","    model=\"GigaChat-2-Max\",                 # GigaChat-2 / -2-Pro / -2-Max — по желанию\n",")"],"metadata":{"id":"zdmI3S27lbS1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating a RetrievalQA Pipeline\n","\n","The RetrievalQA chain connects a large language model (LLM) with your retriever interface.\n","\n","\n","You can also specify the chain type as one of four options:\n","* stuff\n","* map_reduce\n","* refine\n","* map_rerank\n","\n","1. The default type, **stuff**, includes all text from the retrieved documents directly in the prompt.\n","2. The **map_reduce** type splits the texts into groups, asks the LLM the question for each group separately, and then produces a final answer based on all group responses.\n","3. The **refine** type splits the texts into chunks, presents the first chunk to the LLM, then sends the LLM’s response together with the next chunk, gradually refining the answer as it processes all batches.\n","4. The **map_rerank** type divides the texts into chunks, asks the LLM to evaluate how well each chunk answers the question, and then determines the final answer based on the highest-scoring responses."],"metadata":{"id":"QnV0Ox_M1GLK"}},{"cell_type":"code","source":["# Create a RetrievalQA chain for answering questions\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,  # Specify the language model to use\n","    chain_type=\"map_reduce\",  # Use a map-reduce chain type for efficient large-scale queries\n","    retriever=retriever,  # Define the retriever to handle document searches\n","    return_source_documents=True,  # Return source documents along with the generated answers\n","    verbose=True  # Enable detailed logging for better debugging and monitoring\n",")"],"metadata":{"id":"O4fOpm8T0-Ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"Что такое задача понижения размерности?\"\n","result = qa_chain.invoke(question)\n","print(result['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1RGWUMYmIiG","outputId":"3f5d11ba-5b47-4f66-ff49-accf5f5ac832"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Задача понижения размерности заключается в создании нового набора признаков, который включает меньшее количество характеристик по сравнению с исходным набором, однако позволяет решать задачу не хуже (либо с минимальными потерями качества решения, либо даже лучше), чем на основе исходного множества признаков. В эту категорию также входит построение латентных моделей, которые описывают процесс формирования данных через небольшой набор скрытых переменных.\n"]}]},{"cell_type":"code","source":["\n","for document in result[\"source_documents\"]:\n","    print(document.page_content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVcdPOYvm_S7","outputId":"735cf41f-2f9c-441d-b403-07f762c570a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","4. Понижение размерности /emdash.cyr задача генерации таких новых признаков, что их\n","меньше, чем исходных, но при этом с их помощью задача решаетс я не хуже (или\n","с небольшими потерями качества, или лучше /emdash.cyr зависит от постановки). К этой\n","же категории относится задача построения латентных моделе й, где требуется\n","описать процесс генерации данных с помощью некоторого (как правило, неболь-\n","шого) набора скрытых переменных. Примерами являются задач и тематическо-\n","3\n","окрестности, количество школ, магазинов, заправок, торго вых центров, банков по-\n","близости). Разработка признаков (feature engineering) дл я любой задачи является\n","одним из самых сложных и самых важных этапов анализа данных.\n","Описанная задача является примером задачи обучения с учителем (supervised\n","learning), а более конкретно задачей регрессии /emdash.cyr именно так называются задачи с\n","вещественной целевой переменной. Перечислим несколько др угих видов задач обу-\n","чения с учителем:\n","мы будем обсуждать на следующих занятиях. Впрочем, одну из и дей мы можем\n","обсудить уже сейчас. В нашем примере переобучение возникло из-за большой слож-\n","ности семейства /emdash.cyr алгоритмом могла оказаться любая функция. Очевидно, что если\n","бы мы ограничили себя только линейными моделями, то итоговы й алгоритм уже не\n","смог бы запомнить всю выборку . Т аким образом, можно боротьс я с переобучением\n","путем контроля сложности семейства алгоритмов/emdash.cyr чем меньше у нас данных для\n","торыми свойствами. Примером может служить кластеризация д окументов из\n","электронной библиотеки или кластеризация абонентов мобил ьного оператора.\n","2. Оценивание плотности /emdash.cyr задача приближения распределения объектов. При-\n","мером может служить задача обнаружения аномалий, в которой на этапе обу-\n","чения известны лишь примеры /guillemotleft.cyrправильного/guillemotright.cyr поведения оборудования (или,\n","скажем, игроков на бирже), а в дальнейшем требуется обнаруж ивать случаи\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Qa5eOP-enWS2"},"execution_count":null,"outputs":[]}]}