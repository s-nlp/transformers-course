{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "YO7Mhjt_AMiZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6U6HfU_TqGV",
        "outputId": "bb7a15f3-286b-4020-a097-82fa16a4d6d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Example\n",
        "\n",
        "Today we'll see how to work with decoder models in the zero-shot mode. We'll start with the basic GPT3 zero-shot example and then switch to more advanced LLMs."
      ],
      "metadata": {
        "id": "VAenDWgzyfuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZuwDrLOhnuq",
        "outputId": "3c56b3b1-407a-4359-bdfc-61e6f0431a8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ruGPT3 example\n",
        "\n",
        "Load [ruGPT3](https://huggingface.co/ai-forever/rugpt3large_based_on_gpt2)."
      ],
      "metadata": {
        "id": "xJVAEc6LzvOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")"
      ],
      "metadata": {
        "id": "GkT4iqBkTtIu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8dEXHEviKjT",
        "outputId": "c1470d3e-b7ce-41f7-b4b5-4d108681b1c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1536)\n",
              "    (wpe): Embedding(2048, 1536)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=4608, nx=1536)\n",
              "          (c_proj): Conv1D(nf=1536, nx=1536)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=6144, nx=1536)\n",
              "          (c_proj): Conv1D(nf=1536, nx=6144)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot\n",
        "\n",
        "We use model loss for the zero-shot classification.\n",
        "\n",
        "GPT-based models utilize per-token cross-entropy\n",
        "loss, which is reduced to negative log probability\n",
        "due to one-hot encoding of the tokens. **The idea is to select the target label associated with the prompt that results in the lowest sum of negative log probabilities for its tokens.**\n",
        "\n"
      ],
      "metadata": {
        "id": "6EkM9I5Iz6bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_loss_num(text):\n",
        "    # Tokenize the input text and move it to the specified device\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Shift the inputs to create labels for the next-token prediction task\n",
        "    labels = inputs[\"input_ids\"].clone()\n",
        "\n",
        "    # Move labels to the correct device if you're using GPU\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Calculate loss\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    return loss.item()\n",
        "\n",
        "def clean(text):\n",
        "    text = re.sub(r'\\((\\d+)\\)', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "1SEG6JH7VZRe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task: twitter tone analysis\n",
        "\n",
        "Today we'll solve a sentiment analysis task. Let us start with some toy examples and try to come up with the prompts that can distinguish positive and negative texts.\n",
        "\n",
        "**Positive promt example**"
      ],
      "metadata": {
        "id": "zF43GxCq0RVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'жизнь отличная'\n",
        "get_loss_num('Позитивный твит: ' + text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyGy73vNT0tp",
        "outputId": "c8e29eca-6a0c-4bb3-c605-b48ce7dd1671"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.202009201049805"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Negative prompt example**"
      ],
      "metadata": {
        "id": "5T7fmF3hDVft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_loss_num('Негативный твит: ' + text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrwseqWUVkQw",
        "outputId": "45fdcb4d-4497-4bef-fcc4-f1ca4ffa1517"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.3455810546875"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add smiles!"
      ],
      "metadata": {
        "id": "HgUJzqsTzSbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_loss_num('Позитивный твит: ' + text + ')))'))\n",
        "print(get_loss_num('Негативный твит: ' + text + '((('))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkLI_DgkzRgX",
        "outputId": "5d833a9d-fd69-46cd-8df1-4d453821c5f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.151878356933594\n",
            "7.050114154815674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we implement a function that selects the label which yeilds the lowest loss."
      ],
      "metadata": {
        "id": "iw_QSnoQDYyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_zero_shot(text, pos = 'Позитивный твит: {})))', neg = 'Негативный твит: {}((('):\n",
        "  pos_loss = get_loss_num(pos.format(text))\n",
        "  neg_loss = get_loss_num(neg.format(text))\n",
        "  if pos_loss < neg_loss:\n",
        "    return 'positive'\n",
        "  return 'negative'\n",
        "\n",
        "predict_zero_shot(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fOemj3PbeCZi",
        "outputId": "e1d3fe80-f29f-47b0-8221-bee4dd5fa8a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply this approach to the twitter sentimant classification task."
      ],
      "metadata": {
        "id": "hIjTg1Xr0klg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O twitter_short.csv https://drive.usercontent.google.com/download?id=17qSrjy5NyknCfhs1kqGwHcHgml9UzpvS&export=download&authuser=0&confirm=t&uuid=cb32846f-bc96-4eb0-9e29-57d27a89e369&at=AN_67v2rr2Fh_KVc0V-EDJQ7bufm:1729946024386"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0H4sqBm0QZp",
        "outputId": "01961ceb-4535-4e5d-b2c3-a81acdd85559"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-21 18:37:47--  https://drive.usercontent.google.com/download?id=17qSrjy5NyknCfhs1kqGwHcHgml9UzpvS\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.101.132, 2607:f8b0:4023:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.101.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14363 (14K) [application/octet-stream]\n",
            "Saving to: ‘twitter_short.csv’\n",
            "\n",
            "twitter_short.csv   100%[===================>]  14.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-21 18:37:50 (29.3 MB/s) - ‘twitter_short.csv’ saved [14363/14363]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('twitter_short.csv', index_col = 0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_AzZm-fQm9ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "17e543cd-d7b4-419f-a104-58345d6d7120"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  на работе был полный пиддес :| и так каждое за...  negative\n",
              "1  Коллеги сидят рубятся в Urban terror, а я из-з...  negative\n",
              "2  @elina_4post как говорят обещаного три года жд...  negative\n",
              "3  Желаю хорошего полёта и удачной посадки,я буду...  negative\n",
              "4  Обновил за каким-то лешим surf, теперь не рабо...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-670555d6-40d7-408f-9c37-b27a64daaf86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-670555d6-40d7-408f-9c37-b27a64daaf86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-670555d6-40d7-408f-9c37-b27a64daaf86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-670555d6-40d7-408f-9c37-b27a64daaf86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18d2831d-e193-4964-82ed-901480212f1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18d2831d-e193-4964-82ed-901480212f1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18d2831d-e193-4964-82ed-901480212f1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"\\u044f \\u0440\\u0430\\u0430\\u0430\\u0430\\u0430\\u0430\\u0430\\u0434,\\u0432\\u0435\\u0434\\u044c \\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f \\u0432\\u043f\\u0435\\u0440\\u0435\\u0434\\u0438 \\u0432\\u0441\\u044f \\u043d\\u043e\\u0447\\u044c,\\u0441\\u0435\\u0440\\u0438\\u0430\\u043b\\u044b,\\u0444\\u0438\\u043b\\u044c\\u043c\\u044b,\\u043a\\u043d\\u0438\\u0433\\u0430 \\u0438 \\u043a\\u043e\\u0444\\u0435:) \\u0438\\u0434\\u0435\\u0430\\u043b\\u044c\\u043d\\u0430\\u044f \\u043d\\u043e\\u0447\\u043a\\u0430:)\",\n          \"RT @digger2912: \\\"\\u041a\\u0442\\u043e \\u0442\\u043e \\u0432 \\u0443\\u0433\\u043b\\u0443 \\u0441\\u0438\\u0434\\u0438\\u0442 \\u0438 \\u043f\\u043e\\u0433\\u0438\\u0431\\u0430\\u0435\\u0442 \\u043e\\u0442 \\u0433\\u043e\\u043b\\u043e\\u0434\\u0430, \\u0430 \\u043c\\u044b \\u0435\\u0449\\u0451 2 \\u043f\\u043e\\u0440\\u0446\\u0438\\u0438 \\u0432\\u0437\\u044f\\u043b\\u0438, \\u0445\\u043e\\u0442\\u044f \\u0443\\u0436\\u0435 \\u0438 \\u0442\\u0430\\u043a \\u0436\\u0440\\u0430\\u0442\\u044c \\u043d\\u0435 \\u0445\\u043e\\u0442\\u0438\\u043c\\\" :DD\",\n          \"\\u0423 \\u043d\\u0430\\u0441 \\u0435\\u0441\\u0442\\u044c \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0430\\u044f \\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u044f, \\u043a\\u0430\\u043a \\u0441\\u0434\\u043e\\u0445\\u043d\\u0443\\u0442\\u044c \\u0437\\u0430 \\u043d\\u0435\\u0434\\u0435\\u043b\\u044e!!)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MlxCe-ldpQlN",
        "outputId": "0e2d5100-fea9-4806-d44e-6291b89cfc04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text     label\n",
              "95  Встречайте, мои супер одногруппницы, будущие и...  positive\n",
              "96  все,я вас покидаю,результаты гляну вечером)#би...  positive\n",
              "97  RT @Dasha_crazy_69: @DashkaTeddy дыы))) но кто...  positive\n",
              "98    Почти приехали в родное селенье!) @ москва-рига  positive\n",
              "99  На*уй ваши Канары и Мальдивы ! Тут новая тема ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-671dfbbb-89b6-4d73-ac0e-f9545f351afd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Встречайте, мои супер одногруппницы, будущие и...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>все,я вас покидаю,результаты гляну вечером)#би...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>RT @Dasha_crazy_69: @DashkaTeddy дыы))) но кто...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Почти приехали в родное селенье!) @ москва-рига</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>На*уй ваши Канары и Мальдивы ! Тут новая тема ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-671dfbbb-89b6-4d73-ac0e-f9545f351afd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-671dfbbb-89b6-4d73-ac0e-f9545f351afd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-671dfbbb-89b6-4d73-ac0e-f9545f351afd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7de9fb5-7b3c-4549-880a-77dfa03e0e66\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7de9fb5-7b3c-4549-880a-77dfa03e0e66')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7de9fb5-7b3c-4549-880a-77dfa03e0e66 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0432\\u0441\\u0435,\\u044f \\u0432\\u0430\\u0441 \\u043f\\u043e\\u043a\\u0438\\u0434\\u0430\\u044e,\\u0440\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u044b \\u0433\\u043b\\u044f\\u043d\\u0443 \\u0432\\u0435\\u0447\\u0435\\u0440\\u043e\\u043c)#\\u0431\\u0438\\u0430\\u0442\\u043b\\u043e\\u043d\",\n          \"\\u041d\\u0430*\\u0443\\u0439 \\u0432\\u0430\\u0448\\u0438 \\u041a\\u0430\\u043d\\u0430\\u0440\\u044b \\u0438 \\u041c\\u0430\\u043b\\u044c\\u0434\\u0438\\u0432\\u044b ! \\u0422\\u0443\\u0442 \\u043d\\u043e\\u0432\\u0430\\u044f \\u0442\\u0435\\u043c\\u0430 \\u043f\\u0440\\u043e\\u0441\\u043a\\u043e\\u0447\\u0438\\u043b\\u0430 ! ))\",\n          \"RT @Dasha_crazy_69: @DashkaTeddy \\u0434\\u044b\\u044b))) \\u043d\\u043e \\u043a\\u0442\\u043e \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b, \\u0447\\u0442\\u043e \\u044f \\u0412\\u0421\\u0415 \\u043f\\u043e\\u043d\\u044f\\u043b\\u0430 \\u0430\\u0430\\u0445\\u0445\\u0430\\u0445?)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "df['preds'] = df.text.apply(predict_zero_shot)\n",
        "accuracy_score(df.label, df.preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25IpcIkkp9-y",
        "outputId": "95d5cba9-4509-44f5-b08e-006650ffddf9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def encode_label(x):\n",
        "  if x == 'negative':\n",
        "    return 0\n",
        "  return 1\n",
        "f1_score(df.label.apply(encode_label), df.preds.apply(encode_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jNw2Q1f1BJ4",
        "outputId": "744b1ee4-86cf-41ca-92a9-e0758158949c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7868852459016393"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QWEN2.5\n",
        "\n",
        "[Qwen2.5](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct) is a small LLM which can be run in Colab."
      ],
      "metadata": {
        "id": "GhQoCfCh04z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "model.to(device);\n"
      ],
      "metadata": {
        "id": "9ZgMcDsjB-rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First look how it works for simple text generation task."
      ],
      "metadata": {
        "id": "36KM7HFk2vT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Продолжи поговорку:\\nБез труда\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zabfRYx42uJQ",
        "outputId": "d71fa3c4-444e-4dc8-e1a8-7e35b91c3d02"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZUndb6W21IH",
        "outputId": "a9dee598-4406-42a2-89b8-8d9c1c3c2f23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 53645,   9516,  47081,   1802,   5063,  14497, 125661,  35252,    510,\n",
              "          60332,  31885,  10813,  19763,  39490]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First try:"
      ],
      "metadata": {
        "id": "7e4r4Wxi29qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**tokens, top_k=1).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vcnPNTw22Z5",
        "outputId": "6092af42-4a41-4c2d-897d-29d44c64a24c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда не выйдешь, ни в чем не поверишь.\n",
            "\n",
            "Вот продолжение этой\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**tokens, num_beams=4, max_length=30).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDVIRTEO28Jn",
        "outputId": "14720c73-f5a0-463f-c471-75b75de60e56"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего не добь\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**tokens, num_beams=4, num_return_sequences=4, max_length=40).cpu()\n",
        "print(\"\\n\\n\\n\".join(tokenizer.batch_decode(outputs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqRnytNT27Yd",
        "outputId": "e750fc3a-df96-4c4f-a10a-9a64e4eb74ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Эта поговорка\n",
            "\n",
            "\n",
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Исправь ошибки\n",
            "\n",
            "\n",
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Исправь ошибку\n",
            "\n",
            "\n",
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Эта фраза под\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System prompt\n",
        "\n",
        "A **system prompt** (or system message) is a special instruction provided to an LLM that defines its behavior, tone, personality, and constraints during interactions with users. It serves as a foundational guideline that sets expectations for how the model should respond to user inputs throughout a session.\n",
        "\n",
        "But how? Let's ask [Mistral](https://chat.mistral.ai/), [ChatGPT](https://chatgpt.com), or Gemini! Open a model chat and type:\n",
        "\n",
        "\n",
        "```\n",
        "Add system prompt in gwen 2.5\n",
        "```\n",
        "\n",
        "Let's now add a system prompt!\n",
        "\n"
      ],
      "metadata": {
        "id": "-sm--d_K3aZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"Ты — помощник, который генерирует пословицы на русском языке.\"  # Define your system prompt\n",
        "\n",
        "prompt = \"Продолжи поговорку:\\nБез труда\"\n",
        "# Combine system prompt and user prompt into a full prompt\n",
        "full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
        "# Tokenize the full prompt\n",
        "tokens = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Generate the response using the Qwen-2 model\n",
        "outputs = model.generate(**tokens, num_beams=4, num_return_sequences=4, max_length=70).cpu()\n",
        "print(\"\\n\\n\\n\".join([x.split('\\n\\n')[-1] for x in tokenizer.batch_decode(outputs)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuyF54j850gw",
        "outputId": "15b7285c-a68f-44af-8e7a-a2a099bf9987"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Без труда не пришёл, без труда и не\n",
            "\n",
            "\n",
            "1. Без труда не пришё\n",
            "\n",
            "\n",
            "Без труда не пришёл, \n",
            "без труда\n",
            "\n",
            "\n",
            "Без труда не пришёл, без труда не у\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gwen2.5 for sentiment analysis\n",
        "\n",
        "Now, let's look how it solves the sentiment analysis task. First, try the simple generation approach.\n",
        "\n"
      ],
      "metadata": {
        "id": "la12JHTa-yX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'жизнь отличная'\n",
        "prompt = \"Напиши pos в случае если приведенный текст твита позитивный и neg в случае если негативный. Ничего больше не добавляй. Текст твита:\\n{}\".format(text)\n",
        "print(prompt)\n",
        "# Combine system prompt and user prompt into a full prompt\n",
        "# Tokenize the full prompt\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(**tokens, num_beams=2, num_return_sequences=1, max_length=100).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0].replace(prompt,''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbsk4YPAFIu",
        "outputId": "e7fa0d10-ec31-41d0-dfe5-ce492288809e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Напиши pos в случае если приведенный текст твита позитивный и neg в случае если негативный. Ничего больше не добавляй. Текст твита:\n",
            "жизнь отличная\n",
            ", работа хорошая, друзья хорошие, семья счастливая, планы на будущее интересные. \n",
            "\n",
            "pos = 1\n",
            "neg = 0\n",
            "\n",
            "pos = 1\n",
            "neg = 0\n",
            "\n",
            "pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a system prompt."
      ],
      "metadata": {
        "id": "jZvIy5jbEjsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"Ты — помощник, который задачу sentiment analysis.\"  # Define your system prompt\n",
        "text = 'жизнь отличная'\n",
        "\n",
        "prompt = \"Напиши pos в случае если приведенный текст твита позитивный и neg в случае если негативный. Ничего больше не добавляй. Текст твита:\\n{}\".format(text)\n",
        "# Combine system prompt and user prompt into a full prompt\n",
        "full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
        "# Tokenize the full prompt\n",
        "tokens = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(**tokens, num_beams=2, num_return_sequences=1, max_length=100).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0].replace(full_prompt,''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-QrdBw18Ax7",
        "outputId": "8525ff94-1261-44c3-dd71-9dc83774c9f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", все хорошо, я счастлив\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is too small and the result is now that good. But what about the loss variant?"
      ],
      "metadata": {
        "id": "tJrDqL8nEnIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_loss_num('Позитивный твит: ' + text))\n",
        "print(get_loss_num('Негативный твит: ' + text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4NmqIzQ_Y3c",
        "outputId": "26ee3bec-bf8f-42e6-b456-78a099ddf570"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.796105146408081\n",
            "4.003836631774902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_loss_num('Позитивный твит: ' + text + ')))'))\n",
        "print(get_loss_num('Негативный твит: ' + text + '((('))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD-0omm3A-ei",
        "outputId": "3212c02b-0042-40b4-fac5-2702575a0477"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.081405162811279\n",
            "4.601905345916748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "df['preds_qwen'] = df.text.apply(predict_zero_shot)\n",
        "accuracy_score(df.label, df.preds_qwen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi9HGC6IBbUD",
        "outputId": "8a5f05e4-1000-473e-8dd3-a8aada67c342"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(df.label.apply(encode_label), df.preds_qwen.apply(encode_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbpq_yz-Bxu6",
        "outputId": "0341d6b2-4324-4118-c955-7078c1cdf921"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8347826086956521"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}