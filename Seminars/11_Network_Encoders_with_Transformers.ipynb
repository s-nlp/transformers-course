{"cells":[{"cell_type":"markdown","metadata":{"id":"MYpDFySzrk4a"},"source":["# Seminar on Graphs for NLP: Vector representations"]},{"cell_type":"markdown","metadata":{"id":"LlhZKxv4rs2F"},"source":["## Plan for today:\n","\n","#### 0. What a taxonomy is. Taxonomy Enrichment task.\n","#### 1. Node2vec model. Implementation of node2vec.\n","#### 2. Embedding generation for the OOV words for node2vec. Linear transformation model.\n","#### 3. Graph Neural networks: GCN and GAT\n","#### 4. GraphBERT: Only Attention is Needed for Learning Graph Representations"]},{"cell_type":"markdown","metadata":{"id":"6Z0GruYny1kG"},"source":["# 0. Taxonomy\n","\n","A taxonomy is a hierarchical structure of units in terms if class inclusion such that superordinate units in the hierarchy include, or subsume, all items in subordinate units. Taxonomies are typically represented as having tree structures.\n","\n","![](https://www.digital-mr.com/media/cache/51/6f/516f493d37a7b4895f678843b6383e48.png)\n"]},{"cell_type":"markdown","metadata":{"id":"YxGSENmE6IsK"},"source":["Taxonomies can be represented as graphs!\n","\n","Let us download the most popular and well-known taxonomy called WordNet. You may also use the `from nltk.corpus import wordnet as wn`, but keep in mind that you can operate with earlier versions."]},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xi-hshM6rL9z","outputId":"26f0d195-8816-44ce-eb8b-e5511dd48d74","executionInfo":{"status":"ok","timestamp":1681215251519,"user_tz":-120,"elapsed":36566,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.0+cu118\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C91pcHIwsg_v","outputId":"53062a6b-142a-4c62-ff9f-f0616c8804bb","executionInfo":{"status":"ok","timestamp":1681215257812,"user_tz":-120,"elapsed":6301,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (3.20.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (23.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6\n"]}]},{"cell_type":"code","source":["!pip install --upgrade gensim"],"metadata":{"id":"V5VOiYm_2jjR","outputId":"bbc1321d-98bb-41d2-d017-1df9fce651fc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681215261657,"user_tz":-120,"elapsed":3871,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n"]}]},{"cell_type":"code","source":["!curl -L -o 'wordnet_n_is_directed_12_en_synsets.zip' 'https://drive.google.com/u/0/uc?id=1TvWsvz8UC0RPKHBx2GRi-iChVG4oTz-m&export=download&confirm=t'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_tZOA9BnlR0","executionInfo":{"status":"ok","timestamp":1681216282122,"user_tz":-120,"elapsed":8769,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"c25ffc16-bf0c-41c0-e2f9-05fa31b60189"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  206M  100  206M    0     0  34.0M      0  0:00:06  0:00:06 --:--:-- 46.8M\n"]}]},{"cell_type":"code","source":["!unzip wordnet_n_is_directed_12_en_synsets.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORTr2AWjwIvu","outputId":"b3815735-5c5d-4257-d6c4-f03cb5521797","executionInfo":{"status":"ok","timestamp":1681216284450,"user_tz":-120,"elapsed":2337,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  wordnet_n_is_directed_12_en_synsets.zip\n","   creating: wordnet_n_is_directed_1_en_synsets/\n","  inflating: wordnet_n_is_directed_1_en_synsets/link  \n","   creating: wordnet_n_is_directed_1_en_synsets/.ipynb_checkpoints/\n","  inflating: wordnet_n_is_directed_1_en_synsets/.ipynb_checkpoints/link-checkpoint  \n","  inflating: wordnet_n_is_directed_1_en_synsets/node  \n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('omw-1.4')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTwSPeZcjmZT","outputId":"a120603c-7f4f-483d-ec47-8f8a9cd47184","executionInfo":{"status":"ok","timestamp":1681216286749,"user_tz":-120,"elapsed":2301,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from gensim.models.poincare import PoincareModel\n","import numpy as np\n","import time\n","import os"],"metadata":{"id":"kX-L6-NLeKJ8","executionInfo":{"status":"ok","timestamp":1681216286749,"user_tz":-120,"elapsed":5,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import wordnet as wn"],"metadata":{"id":"Ap6gnMUfy146","executionInfo":{"status":"ok","timestamp":1681216286749,"user_tz":-120,"elapsed":4,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["wn.synset(\"guy.n.01\").hyponyms()[0].definition()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"40OqktlGy5Wd","outputId":"d50bf907-fd15-44df-b4ba-33e3cb166053","executionInfo":{"status":"ok","timestamp":1681216288070,"user_tz":-120,"elapsed":1324,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'an informal British term for a youth or man'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["path = f\"wordnet_n_is_directed_1_en_synsets/\"\n","\n","link_path = os.path.join(path, \"link\")\n","node_path = os.path.join(path, \"node\")"],"metadata":{"id":"XeGdLaEqekbb","executionInfo":{"status":"ok","timestamp":1681216288070,"user_tz":-120,"elapsed":4,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["id2synset = {}\n","fasttext_dict = {}\n","\n","with open(node_path) as f:\n","    for line in f:\n","        line_split = line.split(\"\\t\")\n","        id2synset[line_split[0].strip()] = line_split[-1].strip()\n","        fasttext_dict[line_split[-1].strip()] = np.array([float(num) for num in line_split[1:-1]])"],"metadata":{"id":"C26HaOfGfDkR","executionInfo":{"status":"ok","timestamp":1681216302926,"user_tz":-120,"elapsed":14859,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["link_pairs = set()\n","with open(link_path) as f:\n","    for line in f:\n","        line_split = line.split(\"\\t\")\n","        link_pairs.add((id2synset[line_split[0].strip()], id2synset[line_split[-1].strip()]))"],"metadata":{"id":"i7hmkbEXfFIG","executionInfo":{"status":"ok","timestamp":1681216302927,"user_tz":-120,"elapsed":5,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Arh9U60uDH8"},"source":["# 4. Graph Neural Networks"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"46UD5px_rcNb","executionInfo":{"status":"ok","timestamp":1681216302927,"user_tz":-120,"elapsed":4,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import torch_geometric.nn as pyg_nn\n","import torch_geometric.utils as pyg_utils"],"metadata":{"id":"B1qcGlrbre_y","executionInfo":{"status":"ok","timestamp":1681216303483,"user_tz":-120,"elapsed":559,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"eM2IXSZMuIq8","executionInfo":{"status":"ok","timestamp":1681216303483,"user_tz":-120,"elapsed":5,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["import time\n","from datetime import datetime\n","\n","import networkx as nx\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.data import DataLoader\n","from torch_geometric.utils import train_test_split_edges\n","import torch_geometric.transforms as T\n","from torch_geometric.data import Data\n","\n","from tensorboardX import SummaryWriter\n","from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{"id":"KPMU0mL6IJEA"},"source":["## Data preparation"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"2NAxJKWLmkae","executionInfo":{"status":"ok","timestamp":1681216304085,"user_tz":-120,"elapsed":4,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["from gensim.models.keyedvectors import KeyedVectors\n","\n","fasttext = KeyedVectors(vector_size=300)\n","fasttext.add_vectors(list(fasttext_dict.keys()), list(fasttext_dict.values()))"]},{"cell_type":"code","source":["import networkx as nx"],"metadata":{"id":"JL1yQgaD4mio","executionInfo":{"status":"ok","timestamp":1681216304085,"user_tz":-120,"elapsed":3,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["G = nx.DiGraph()\n","\n","for pair in link_pairs:\n","    G.add_edge(*pair)"],"metadata":{"id":"WkLOHE1t4qJo","executionInfo":{"status":"ok","timestamp":1681216305039,"user_tz":-120,"elapsed":957,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["for pair in link_pairs:\n","    print(pair)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNhTMIM9qPsQ","executionInfo":{"status":"ok","timestamp":1681216305040,"user_tz":-120,"elapsed":21,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"b6be2104-bd8d-4806-bddc-a2235ac2d1cf"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["('flight.n.09', 'connecting_flight.n.01')\n"]}]},{"cell_type":"code","execution_count":20,"metadata":{"id":"cgC4chwuIJEC","executionInfo":{"status":"ok","timestamp":1681216305040,"user_tz":-120,"elapsed":18,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["def create_edge_list(G):\n","    starts = []\n","    ends = []\n","    for left, right in G.edges:\n","        if left in fasttext.key_to_index and right in fasttext.key_to_index:\n","            starts.append(fasttext.key_to_index[left])\n","            ends.append(fasttext.key_to_index[right])\n","    return torch.tensor([starts, ends], dtype=torch.long)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ILgb5IF4a2A9","executionInfo":{"status":"ok","timestamp":1681216305040,"user_tz":-120,"elapsed":17,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["index_to_key = dict(map(reversed, fasttext.key_to_index.items()))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"f_iX7WH2nCSv","executionInfo":{"status":"ok","timestamp":1681216305041,"user_tz":-120,"elapsed":18,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["edge_index = create_edge_list(G)"]},{"cell_type":"code","source":["edge_index.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQhXglBvqwCM","executionInfo":{"status":"ok","timestamp":1681216305041,"user_tz":-120,"elapsed":17,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"e2e0afeb-efbe-451e-bb17-6c248fb4ce97"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 72370])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["x = torch.tensor([fasttext[index_to_key[int(i)]] for i in index_to_key], dtype=torch.float)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZJdPogQy1kG","outputId":"1e935c46-9230-4d8b-a30a-4c6c7c721e0d","executionInfo":{"status":"ok","timestamp":1681216307125,"user_tz":-120,"elapsed":2090,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-24-ceafeacad9cc>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  x = torch.tensor([fasttext[index_to_key[int(i)]] for i in index_to_key], dtype=torch.float)\n"]}]},{"cell_type":"code","source":["x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poQi6NZorQfp","outputId":"89693f6a-ee1f-450e-d8c0-b4e68b36c275","executionInfo":{"status":"ok","timestamp":1681216307126,"user_tz":-120,"elapsed":13,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([78748, 300])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["data = Data(x=x, edge_index=edge_index)\n","#data = train_test_split_edges(data)"],"metadata":{"id":"WC3VgJ0FyiiH","executionInfo":{"status":"ok","timestamp":1681216307126,"user_tz":-120,"elapsed":5,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.transforms import RandomLinkSplit"],"metadata":{"id":"TCVO4jfK1LFI","executionInfo":{"status":"ok","timestamp":1681216307669,"user_tz":-120,"elapsed":3,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["transform = RandomLinkSplit(is_undirected=True, split_labels=True)\n","train_data, val_data, test_data = transform(data)"],"metadata":{"id":"lPA8jPvZ1IIn","executionInfo":{"status":"ok","timestamp":1681216307669,"user_tz":-120,"elapsed":2,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCZE_0e0IJED"},"source":["### GCN and GAT Encoder\n","\n","The following code snippet describes the Encoder module with GCN or GAT networks."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"I-naFqNRumvk","executionInfo":{"status":"ok","timestamp":1681216327750,"user_tz":-120,"elapsed":615,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["class Encoder(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, mode=\"gcn\"):\n","        super(Encoder, self).__init__()\n","        if mode == \"gcn\":\n","            self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True)\n","            self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True)\n","        elif mode == 'gat':\n","            self.conv1 = pyg_nn.GATConv(in_channels, 2 * out_channels)\n","            self.conv2 = pyg_nn.GATConv(2 * out_channels, out_channels)\n","        else:\n","            raise Exception(\"Encoder mode is not recognized, try gcn/gat\")\n","\n","    def forward(self, x, edge_index):\n","        x = F.relu(self.conv1(x, edge_index))\n","        return self.conv2(x, edge_index)\n","\n","def train(epoch):\n","    model.train()\n","    optimizer.zero_grad()\n","    z = model.encode(x, train_pos_edge_index)\n","    loss = model.recon_loss(z, train_pos_edge_index)\n","    loss.backward()\n","    optimizer.step()\n","    writer.add_scalar(\"loss\", loss.item(), epoch)\n","    return loss.item()\n","\n","def test(pos_edge_index, neg_edge_index):\n","    model.eval()\n","    with torch.no_grad():\n","        z = model.encode(x, train_pos_edge_index)\n","    return model.test(z, pos_edge_index, neg_edge_index)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eplyGdMwvF57","outputId":"383310b3-35f4-47ec-97b9-9376ee08cff9","executionInfo":{"status":"ok","timestamp":1681216329243,"user_tz":-120,"elapsed":4,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA availability: True\n"]}],"source":["writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","\n","channels = 64\n","dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('CUDA availability:', torch.cuda.is_available())"]},{"cell_type":"markdown","metadata":{"id":"UHEHYEbcXCFG"},"source":["## Variational Graph Auto-Encoders\n","\n","https://arxiv.org/pdf/1611.07308.pdf\n","\n","The pipeline is working as follows: first, we train a graph autoencoder with GCN or GAT under the hoot. During the evaluation phase, the latent representations of the autoencoder are actually the embeddings we are looking for."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"mqZGTsQ7vRQM","outputId":"c8f8c2bd-715d-421f-fe49-8b3ef4557ee0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681216381786,"user_tz":-120,"elapsed":50105,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 010, AUC: 0.8365, AP: 0.8324, Loss: 0.9607\n","Epoch: 020, AUC: 0.8705, AP: 0.8702, Loss: 0.8800\n","Epoch: 030, AUC: 0.8889, AP: 0.8913, Loss: 0.8373\n","Epoch: 040, AUC: 0.8964, AP: 0.9009, Loss: 0.8187\n","Epoch: 050, AUC: 0.9042, AP: 0.9101, Loss: 0.8082\n","Epoch: 060, AUC: 0.9072, AP: 0.9133, Loss: 0.7995\n","Epoch: 070, AUC: 0.9075, AP: 0.9147, Loss: 0.7924\n","Epoch: 080, AUC: 0.9079, AP: 0.9160, Loss: 0.7824\n","Epoch: 090, AUC: 0.9111, AP: 0.9193, Loss: 0.7835\n","Epoch: 100, AUC: 0.9116, AP: 0.9202, Loss: 0.7766\n","Epoch: 110, AUC: 0.9114, AP: 0.9205, Loss: 0.7768\n","Epoch: 120, AUC: 0.9131, AP: 0.9222, Loss: 0.7757\n","Epoch: 130, AUC: 0.9108, AP: 0.9207, Loss: 0.7678\n","Epoch: 140, AUC: 0.9125, AP: 0.9222, Loss: 0.7693\n","Epoch: 150, AUC: 0.9123, AP: 0.9225, Loss: 0.7706\n","Epoch: 160, AUC: 0.9128, AP: 0.9231, Loss: 0.7659\n","Epoch: 170, AUC: 0.9139, AP: 0.9244, Loss: 0.7657\n","Epoch: 180, AUC: 0.9141, AP: 0.9245, Loss: 0.7610\n","Epoch: 190, AUC: 0.9133, AP: 0.9243, Loss: 0.7626\n","Epoch: 200, AUC: 0.9118, AP: 0.9235, Loss: 0.7634\n","Epoch: 210, AUC: 0.9115, AP: 0.9238, Loss: 0.7587\n","Epoch: 220, AUC: 0.9126, AP: 0.9246, Loss: 0.7579\n","Epoch: 230, AUC: 0.9130, AP: 0.9250, Loss: 0.7590\n","Epoch: 240, AUC: 0.9139, AP: 0.9257, Loss: 0.7597\n","Epoch: 250, AUC: 0.9113, AP: 0.9236, Loss: 0.7559\n","Epoch: 260, AUC: 0.9122, AP: 0.9245, Loss: 0.7585\n","Epoch: 270, AUC: 0.9110, AP: 0.9236, Loss: 0.7571\n","Epoch: 280, AUC: 0.9101, AP: 0.9227, Loss: 0.7532\n","Epoch: 290, AUC: 0.9110, AP: 0.9237, Loss: 0.7512\n","Epoch: 300, AUC: 0.9109, AP: 0.9242, Loss: 0.7567\n","Epoch: 310, AUC: 0.9111, AP: 0.9241, Loss: 0.7523\n","Epoch: 320, AUC: 0.9112, AP: 0.9245, Loss: 0.7526\n","Epoch: 330, AUC: 0.9118, AP: 0.9248, Loss: 0.7531\n","Epoch: 340, AUC: 0.9110, AP: 0.9246, Loss: 0.7534\n","Epoch: 350, AUC: 0.9101, AP: 0.9237, Loss: 0.7499\n","Epoch: 360, AUC: 0.9100, AP: 0.9238, Loss: 0.7519\n","Epoch: 370, AUC: 0.9092, AP: 0.9234, Loss: 0.7489\n","Epoch: 380, AUC: 0.9084, AP: 0.9227, Loss: 0.7491\n","Epoch: 390, AUC: 0.9087, AP: 0.9229, Loss: 0.7510\n","Epoch: 400, AUC: 0.9096, AP: 0.9236, Loss: 0.7453\n"]}],"source":["model = pyg_nn.GAE(Encoder(300, channels, 'gat')).to(dev)\n","x, train_pos_edge_index = train_data.x.to(dev), train_data.pos_edge_label_index.to(dev)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","for epoch in range(1, 401):\n","    loss = train(epoch)\n","    auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n","    writer.add_scalar(\"AUC\", auc, epoch)\n","    writer.add_scalar(\"AP\", ap, epoch)\n","    if epoch % 10 == 0:\n","        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}, Loss: {:.4f}'.format(epoch, auc, ap, loss))"]},{"cell_type":"markdown","metadata":{"id":"3__lKOCOXNKj"},"source":["#### Examples\n","\n","Let us see the nearest neighbours for the unseen words from the test set."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"1mWcc2HlvVLf","executionInfo":{"status":"ok","timestamp":1681216385531,"user_tz":-120,"elapsed":3749,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["model.eval()\n","new_x = torch.tensor([fasttext[index_to_key[i]] for i in index_to_key], dtype=torch.float).to(dev)\n","z = model.encode(new_x, train_pos_edge_index)"]},{"cell_type":"code","source":["id2syns = {}\n","syns2id = {}\n","with open('wordnet_n_is_directed_1_en_synsets/node') as f:\n","    for line in f:\n","        id2syns[line.split()[0]] = line.split()[-1]\n","        syns2id[line.split()[-1]] = line.split()[0]"],"metadata":{"id":"HoDN-uTq8bem","executionInfo":{"status":"ok","timestamp":1681216392083,"user_tz":-120,"elapsed":6558,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["par2orph = {}\n","orph2par = {}\n","with open('wordnet_n_is_directed_1_en_synsets/link') as f:\n","    for line in f:\n","        par_id = line.split()[0]\n","        child_id = line.split()[-1]\n","        \n","        if \"ORPHAN_\" in id2syns[child_id]:\n","            par2orph[id2syns[par_id]] = id2syns[child_id]\n","            orph2par[id2syns[child_id]] = id2syns[par_id]"],"metadata":{"id":"DGWVX-WL74KV","executionInfo":{"status":"ok","timestamp":1681216392084,"user_tz":-120,"elapsed":6,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["c = 0\n","for word in fasttext.key_to_index:\n","    if \".n.\" not in word:\n","        cur_index = fasttext.key_to_index[word]\n","        tensor_ = torch.tensor([[cur_index]*(len(G.nodes)), [i for i in range(0, len(G.nodes))]])\n","        results = model.decode(z, tensor_)\n","        top10 = list(reversed(sorted([(index_to_key[i], round(float(score.cpu().detach().float()), 4)) for i, score in enumerate(results)], key=lambda x: x[1])))[:10]       \n","        print(orph2par[word], \":\", top10)\n","        print(\"=\"*10)\n","        c += 1\n","        if c == 20:\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4jW1K0d3Fq1","outputId":"43f63ae8-c5d5-41e4-ead9-59bba644c8fe","executionInfo":{"status":"ok","timestamp":1681216445310,"user_tz":-120,"elapsed":53230,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["course.n.04 : [('act.n.03', 0.9975), ('way.n.10', 0.9955), ('way.n.09', 0.9955), ('way.n.05', 0.9952), ('ORPHAN_100000000', 0.9925), ('path.n.02', 0.9924), ('action.n.10', 0.9909), ('course.n.04', 0.9901), ('warpath.n.02', 0.9887), ('course.n.07', 0.9874)]\n","==========\n","recovery.n.03 : [('act.n.03', 0.996), ('act.n.01', 0.99), ('legislative_act.n.01', 0.9802), ('rescue.n.01', 0.9785), ('healing.n.01', 0.9777), ('nay.n.01', 0.9747), ('ORPHAN_100000001', 0.9734), ('res_gestae.n.02', 0.9723), ('recovery.n.03', 0.9713), ('beatification.n.02', 0.9693)]\n","==========\n","disappearance.n.01 : [('vanishing.n.01', 0.9848), ('ORPHAN_100000002', 0.9848), ('tracing.n.02', 0.9578), ('trace.n.06', 0.9506), ('trace.n.05', 0.9506), ('ORPHAN_100000445', 0.9481), ('flow.n.04', 0.9458), ('drawing.n.02', 0.9392), ('vanishing_point.n.01', 0.9344), ('silhouette.n.02', 0.933)]\n","==========\n","hit.n.03 : [('hit.n.05', 0.9233), ('hit.n.01', 0.9233), ('win.n.01', 0.9094), ('loss.n.01', 0.878), ('financial_loss.n.01', 0.8629), ('fluke.n.02', 0.8623), ('base_hit.n.01', 0.8561), ('odds.n.01', 0.8549), ('hit.n.02', 0.8548), ('shot.n.14', 0.853)]\n","==========\n","breach.n.01 : [('breach.n.02', 0.9998), ('breach.n.01', 0.9998), ('breach_of_contract.n.01', 0.9995), ('ORPHAN_100000004', 0.9995), ('act.n.03', 0.9989), ('material_breach.n.01', 0.9975), ('partial_breach.n.01', 0.997), ('breach_of_warranty.n.01', 0.9965), ('breach_of_trust.n.01', 0.9955), ('anticipatory_breach.n.01', 0.9947)]\n","==========\n","buying.n.01 : [('resale.n.01', 0.9957), ('ORPHAN_100000005', 0.9938), ('making.n.03', 0.993), ('shopping.n.01', 0.9929), ('buying.n.01', 0.992), ('giving.n.01', 0.9908), ('assets.n.01', 0.9864), ('purchase.n.03', 0.985), ('purchase.n.01', 0.985), ('crown_jewel.n.01', 0.9834)]\n","==========\n","restitution.n.03 : [('ORPHAN_100000006', 0.9859), ('lump_sum.n.01', 0.9679), ('cash.n.02', 0.9637), ('giver.n.01', 0.9625), ('blood_money.n.03', 0.9622), ('payoff.n.01', 0.9568), ('reward.n.02', 0.9568), ('conscience_money.n.01', 0.9553), ('refund.n.01', 0.9546), ('repayment.n.02', 0.9532)]\n","==========\n","abandonment.n.03 : [('ban.n.02', 0.9887), ('discard.n.01', 0.9582), ('ORPHAN_100000007', 0.9566), ('push.n.01', 0.9521), ('overage.n.01', 0.9514), ('bundling.n.03', 0.949), ('shove.n.01', 0.9465), ('boost.n.03', 0.9309), ('act.n.03', 0.9249), ('jostle.n.01', 0.9237)]\n","==========\n","mine_disposal.n.01 : [('ORPHAN_100000008', 0.969), ('fun.n.03', 0.9553), ('dhow.n.01', 0.9519), ('degaussing.n.01', 0.9453), ('suturing.n.01', 0.9446), ('solo.n.01', 0.9445), ('craft.n.02', 0.9444), ('cup_of_tea.n.01', 0.9441), ('act.n.03', 0.9423), ('combat.n.01', 0.9392)]\n","==========\n","expiation.n.02 : [('ORPHAN_100000009', 0.9949), ('reparation.n.02', 0.9931), ('healing.n.01', 0.9878), ('sin.n.05', 0.9869), ('nay.n.01', 0.9867), ('sainthood.n.01', 0.9843), ('prior.n.01', 0.9823), ('forgiveness.n.01', 0.9812), ('saving_grace.n.02', 0.9811), ('proof.n.02', 0.9796)]\n","==========\n","rendition.n.04 : [('ranker.n.02', 0.9688), ('spin.n.01', 0.9653), ('spin.n.03', 0.9653), ('fluke.n.02', 0.9334), ('win.n.01', 0.9152), ('ORPHAN_100000010', 0.915), ('cog.n.01', 0.9087), ('arm.n.04', 0.9087), ('odds.n.01', 0.9054), ('gear.n.03', 0.9002)]\n","==========\n","depression.n.10 : [('ORPHAN_100000011', 0.9796), ('dog.n.03', 0.9548), ('blip.n.01', 0.943), ('icon.n.01', 0.9408), ('tab.n.04', 0.9407), ('log.n.05', 0.9404), ('wood_mouse.n.01', 0.939), ('image.n.08', 0.9383), ('mouse_button.n.01', 0.9364), ('badge.n.02', 0.9346)]\n","==========\n","blink.n.01 : [('biont.n.01', 0.8639), ('iguanid.n.01', 0.8528), ('cog.n.01', 0.8436), ('phasianid.n.01', 0.8407), ('dillenia.n.01', 0.8389), ('paralogism.n.01', 0.8277), ('quail.n.02', 0.827), ('abhorrer.n.01', 0.8246), ('pushball.n.01', 0.8244), ('cynodont.n.01', 0.8199)]\n","==========\n","shooting.n.01 : [('act.n.03', 0.9861), ('shot.n.12', 0.9852), ('discharge.n.09', 0.9774), ('shoot.n.02', 0.9769), ('gunfire.n.01', 0.9764), ('ORPHAN_100000013', 0.9739), ('shooting.n.01', 0.9718), ('jotting.n.01', 0.9708), ('shooting.n.02', 0.9693), ('gun.n.07', 0.9691)]\n","==========\n","hit.n.02 : [('hit.n.05', 0.9967), ('hit.n.01', 0.9967), ('hit.n.02', 0.9938), ('fly.n.04', 0.9935), ('crash.n.04', 0.9918), ('grounder.n.01', 0.991), ('ORPHAN_100000014', 0.9908), ('liner.n.01', 0.9869), ('texas_leaguer.n.01', 0.9865), ('blast.n.01', 0.9865)]\n","==========\n","free_kick.n.01 : [('kick.n.05', 0.9865), ('kick.n.06', 0.9734), ('drug.n.01', 0.9725), ('curb.n.01', 0.9663), ('low.n.03', 0.9661), ('free_kick.n.01', 0.9649), ('hop.n.02', 0.962), ('ORPHAN_100000015', 0.9585), ('psychoactive_drug.n.01', 0.9575), ('drug_of_abuse.n.01', 0.9558)]\n","==========\n","assignment.n.03 : [('prior.n.01', 0.9893), ('assignment.n.03', 0.981), ('ORPHAN_100000016', 0.972), ('vantage.n.01', 0.9696), ('vantage_point.n.01', 0.9624), ('position.n.07', 0.9618), ('role.n.04', 0.9614), ('logical_relation.n.01', 0.9607), ('mathematical_relation.n.01', 0.9599), ('point_of_view.n.02', 0.959)]\n","==========\n","road.n.02 : [('path.n.02', 0.9326), ('road.n.02', 0.9313), ('ORPHAN_100000017', 0.9082), ('park.n.01', 0.9046), ('motorcade.n.01', 0.8993), ('road.n.01', 0.8987), ('ceremony.n.03', 0.8956), ('ceremony.n.02', 0.8956), ('national_park.n.01', 0.8905), ('safari_park.n.01', 0.886)]\n","==========\n","vote.n.02 : [('vote.n.04', 0.9978), ('vote.n.02', 0.9978), ('ban.n.02', 0.9957), ('boycott.n.01', 0.9922), ('ORPHAN_100000018', 0.992), ('pocket_veto.n.01', 0.9857), ('cumulative_vote.n.01', 0.9825), ('abort.n.01', 0.982), ('veto.n.01', 0.9809), ('takeover_bid.n.01', 0.9805)]\n","==========\n","economy.n.04 : [('rapid.n.01', 0.986), ('growth.n.02', 0.9843), ('growth.n.07', 0.9843), ('growth.n.04', 0.9843), ('stop.n.01', 0.9826), ('act.n.03', 0.9786), ('ORPHAN_100000019', 0.976), ('flow.n.04', 0.9734), ('preservation.n.01', 0.9713), ('economic_growth.n.01', 0.9706)]\n","==========\n"]}]},{"cell_type":"markdown","source":["# Graph Attention Networks v2 (GATv2)\n","\n","This is a PyTorch implementation of the GATv2 operator from the paper How Attentive are Graph Attention Networks?.\n","\n","https://nn.labml.ai/graphs/gatv2/index.html"],"metadata":{"id":"feq6fTEdTeMe"}},{"cell_type":"markdown","metadata":{"id":"ZgbmlZqBIJEN"},"source":["## GraphBERT\n","\n","https://github.com/jwzhanggy/Graph-Bert\n","\n","Yet another model for embedding generation is GraphBert. Instead of feeding large input graph, we train GRAPH-BERT with sampled subgraphs within their local contexts. The input vector embeddings to be fed to the graphtransformer model actually cover four parts: (1) raw feature vector embedding, (2) Weisfeiler-Lehman absolute role embedding, (3) intimacy based relative positional embedding, and (4) hop based relative distance embedding, respectively.\n","\n","GRAPH-BERT is trained with the node attribute reconstruction and structure recovery tasks."]},{"cell_type":"markdown","metadata":{"id":"zo0z3trCa2BC"},"source":["![](https://github.com/jwzhanggy/Graph-Bert/raw/master/result/screenshot/model.png)"]},{"cell_type":"markdown","metadata":{"id":"1fOqFVHLa2BD"},"source":["## Subgraph Sampling"]},{"cell_type":"markdown","metadata":{"id":"5htpR5J7a2BD"},"source":["![](https://i.ibb.co/5cbjJZ6/photo-2021-12-07-16-41-32.jpg)"]},{"cell_type":"markdown","metadata":{"id":"XDsdGrffa2BD"},"source":["## Positional embeddings"]},{"cell_type":"markdown","metadata":{"id":"tOny-pLQa2BE"},"source":["### Weisfeiler-Lehman Absolute Role Embedding\n","\n","![](https://i.ibb.co/bgT7gqb/wl.png)\n","\n","### Intimacy based Relative Positional Embedding\n","\n","![](https://i.ibb.co/34FvCf0/photo-2021-12-07-16-52-30.jpg)\n","\n","### Hop based Relative Distance Embedding\n","![](https://i.ibb.co/tCzRcfK/hops-drawio.png)"]},{"cell_type":"markdown","metadata":{"id":"AomlgEcXa2BE"},"source":["Actually, you are simply expected to run two scripts: `script_1_preprocess.py` and `script_2_pre_train.py`"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"9DXA9H5la2BF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eda3a057-a57a-404b-fe1b-48756eb62307","executionInfo":{"status":"ok","timestamp":1681216475641,"user_tz":-120,"elapsed":1213,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Graph-Bert'...\n","remote: Enumerating objects: 450, done.\u001b[K\n","remote: Counting objects: 100% (136/136), done.\u001b[K\n","remote: Compressing objects: 100% (58/58), done.\u001b[K\n","remote: Total 450 (delta 106), reused 79 (delta 78), pack-reused 314\u001b[K\n","Receiving objects: 100% (450/450), 2.23 MiB | 19.50 MiB/s, done.\n","Resolving deltas: 100% (232/232), done.\n"]}],"source":["!git clone https://github.com/jwzhanggy/Graph-Bert.git"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"ueo45TqXa2BF","outputId":"2f38e0c2-d51c-4aea-8675-9b21d93057d6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681216593757,"user_tz":-120,"elapsed":118119,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Graph-Bert\n","************ Start ************\n","WL, dataset: cora\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 1\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 2\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 3\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 4\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 5\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 6\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 7\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 8\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 9\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","Subgraph Batching, dataset: cora, k: 10\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 1\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 2\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 3\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 4\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 5\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 6\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 7\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 8\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 9\n","Loading cora dataset...\n","************ Finish ************\n","************ Start ************\n","HopDistance, dataset: cora, k: 10\n","Loading cora dataset...\n","************ Finish ************\n"]}],"source":["%cd Graph-Bert\n","!python3 script_1_preprocess.py"]},{"cell_type":"markdown","metadata":{"id":"tE-7RzJ1a2BK"},"source":["## View and evaluate results"]},{"cell_type":"code","source":["!gdown 1IAfd9tRgtVtdosM5vuDdxh-VSBFp3mzI\n","!gdown 1LItbxEcchOfU4TrlLBZjQweC8jpQ3b3Q\n","!gdown 1VLLLyu9YyLX3uCojiTm_VLtgK2gKCCfW\n","!gdown 1h5sSbFeCJbouH96fKIZDF2xugNiKf3La"],"metadata":{"id":"zvWT_UAaSW7m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2bcc0521-869d-48d0-d63b-f02802b9d313","executionInfo":{"status":"ok","timestamp":1681216658328,"user_tz":-120,"elapsed":18434,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1IAfd9tRgtVtdosM5vuDdxh-VSBFp3mzI\n","To: /content/Graph-Bert/MethodGraphBertGraphRecovery_model_test_embeddings.txt\n","100% 258k/258k [00:00<00:00, 105MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1LItbxEcchOfU4TrlLBZjQweC8jpQ3b3Q\n","To: /content/Graph-Bert/MethodGraphBertGraphRecovery_model_train_embeddings_.txt\n","100% 196M/196M [00:03<00:00, 56.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1VLLLyu9YyLX3uCojiTm_VLtgK2gKCCfW\n","To: /content/Graph-Bert/MethodGraphBertNodeConstruct_model_train_embeddings_.txt\n","100% 288M/288M [00:06<00:00, 42.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1h5sSbFeCJbouH96fKIZDF2xugNiKf3La\n","To: /content/Graph-Bert/MethodGraphBertNodeConstruct_model_test_embeddings.txt\n","100% 362k/362k [00:00<00:00, 111MB/s]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"FyqIy_MowB_I"}},{"cell_type":"code","source":["from gensim.models import KeyedVectors"],"metadata":{"id":"uLCgr2ibUZL9","executionInfo":{"status":"ok","timestamp":1681216658329,"user_tz":-120,"elapsed":5,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","execution_count":43,"metadata":{"id":"bW9Z8hLca2BL","executionInfo":{"status":"ok","timestamp":1681216678207,"user_tz":-120,"elapsed":19882,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[],"source":["graphBertNode_train = KeyedVectors.load_word2vec_format(\"MethodGraphBertNodeConstruct_model_train_embeddings_.txt\")\n","graphBertNode_test = KeyedVectors.load_word2vec_format(\"MethodGraphBertNodeConstruct_model_test_embeddings.txt\")"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"zdnqyA7ia2BL","outputId":"a50de088-19e6-4eee-bf13-f3a295a72b1f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681216775559,"user_tz":-120,"elapsed":950,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('hound.n.01', 0.8980603814125061),\n"," ('working_dog.n.01', 0.8848254680633545),\n"," ('dandy.n.01', 0.8751208782196045),\n"," ('old_man.n.01', 0.8639864325523376),\n"," ('professional.n.01', 0.8605043888092041),\n"," ('gravida.n.02', 0.849956750869751),\n"," ('child.n.02', 0.8499069809913635),\n"," ('spaniel.n.01', 0.8490362167358398),\n"," ('subordinate.n.01', 0.8471304178237915),\n"," ('parent.n.01', 0.8452426195144653)]"]},"metadata":{},"execution_count":44}],"source":["graphBertNode_train.similar_by_word(\"dog.n.01\")"]},{"cell_type":"code","source":["fasttext.similar_by_word(\"dog.n.01\")"],"metadata":{"id":"wyTvIjVQwy0B","executionInfo":{"status":"ok","timestamp":1681216777883,"user_tz":-120,"elapsed":3,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"37ee733d-00c2-45b1-821c-4833e6b73ead","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('dog.n.03', 0.9556826949119568),\n"," ('seizure-alert_dog.n.01', 0.9394533634185791),\n"," ('working_dog.n.01', 0.9265448451042175),\n"," ('dog_breeding.n.01', 0.9224575757980347),\n"," ('hunting_dog.n.01', 0.9179456233978271),\n"," ('dog_biscuit.n.01', 0.9155749678611755),\n"," ('ORPHAN_100000208', 0.9101989269256592),\n"," ('dog_catcher.n.01', 0.9075720906257629),\n"," ('raccoon_dog.n.01', 0.9067509770393372),\n"," ('dalmatian.n.02', 0.9053666591644287)]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["wn.synset(\"dog.n.01\").hyponyms()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAEmE4jXwJR6","outputId":"e7428f23-2470-41b5-cf6d-a9aefb0176be","executionInfo":{"status":"ok","timestamp":1681216802395,"user_tz":-120,"elapsed":525,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Synset('basenji.n.01'),\n"," Synset('corgi.n.01'),\n"," Synset('cur.n.01'),\n"," Synset('dalmatian.n.02'),\n"," Synset('great_pyrenees.n.01'),\n"," Synset('griffon.n.02'),\n"," Synset('hunting_dog.n.01'),\n"," Synset('lapdog.n.01'),\n"," Synset('leonberg.n.01'),\n"," Synset('mexican_hairless.n.01'),\n"," Synset('newfoundland.n.01'),\n"," Synset('pooch.n.01'),\n"," Synset('poodle.n.01'),\n"," Synset('pug.n.01'),\n"," Synset('puppy.n.01'),\n"," Synset('spitz.n.01'),\n"," Synset('toy_dog.n.01'),\n"," Synset('working_dog.n.01')]"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["# OpenHGNN library"],"metadata":{"id":"SZbGESB3VSYv"}},{"cell_type":"code","source":["pip install torch torchvision torchaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMEBnLKLVTyp","executionInfo":{"status":"ok","timestamp":1681216867374,"user_tz":-120,"elapsed":3672,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"7240aa13-c211-43c3-c367-965a39e8acfe"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["pip install dgl -f https://data.dgl.ai/wheels/repo.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDdKxXeQVXjW","executionInfo":{"status":"ok","timestamp":1681216887105,"user_tz":-120,"elapsed":10660,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"7471080a-2c38-42ca-a667-27fa1d976b8d"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.dgl.ai/wheels/repo.html\n","Collecting dgl\n","  Downloading https://data.dgl.ai/wheels/dgl-1.0.2-cp39-cp39-manylinux1_x86_64.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgl) (4.65.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (5.9.4)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.22.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl) (3.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (2.27.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.10.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n","Installing collected packages: dgl\n","Successfully installed dgl-1.0.2\n"]}]},{"cell_type":"code","source":["pip install openhgnn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjzYAtcbVaKA","executionInfo":{"status":"ok","timestamp":1681216909164,"user_tz":-120,"elapsed":22064,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"2144a826-571e-4a01-cc07-8edb49c476df"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openhgnn\n","  Downloading openhgnn-0.4.0.tar.gz (230 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.7/230.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/dist-packages (from openhgnn) (1.22.4)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from openhgnn) (1.4.4)\n","Collecting ogb>=1.1.0\n","  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from openhgnn) (2.0.0+cu118)\n","Collecting optuna\n","  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.1.0->openhgnn) (1.16.0)\n","Collecting outdated>=0.2.0\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.1.0->openhgnn) (1.26.15)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.1.0->openhgnn) (1.2.2)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.1.0->openhgnn) (4.65.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.0->openhgnn) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.0->openhgnn) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->openhgnn) (3.10.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->openhgnn) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->openhgnn) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->openhgnn) (3.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->openhgnn) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->openhgnn) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->openhgnn) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->openhgnn) (16.0.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna->openhgnn) (23.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna->openhgnn) (6.0)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna->openhgnn) (1.4.47)\n","Collecting cmaes>=0.9.1\n","  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n","Collecting alembic>=1.5.0\n","  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting littleutils\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.1.0->openhgnn) (67.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.1.0->openhgnn) (2.27.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb>=1.1.0->openhgnn) (1.1.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb>=1.1.0->openhgnn) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb>=1.1.0->openhgnn) (3.1.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna->openhgnn) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->openhgnn) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->openhgnn) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.1.0->openhgnn) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.1.0->openhgnn) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.1.0->openhgnn) (2.0.12)\n","Building wheels for collected packages: openhgnn, littleutils\n","  Building wheel for openhgnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openhgnn: filename=openhgnn-0.4.0-py3-none-any.whl size=297065 sha256=d77e2f138be3cd9b30dfa75456f8246ff03dc8e86bcce11e81b7f883145d3985\n","  Stored in directory: /root/.cache/pip/wheels/10/8a/b6/12b114efc5e310da3be61a15dd8aaf94c4e961f368cd78d1d6\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=cc1889c8e48c144eaa73c46e03772f7950e013746c903e72635d5e34fbdeb98c\n","  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n","Successfully built openhgnn littleutils\n","Installing collected packages: littleutils, Mako, colorlog, colorama, cmaes, outdated, alembic, optuna, ogb, openhgnn\n","Successfully installed Mako-1.2.4 alembic-1.10.3 cmaes-0.9.1 colorama-0.4.6 colorlog-6.7.0 littleutils-0.2.2 ogb-1.3.6 openhgnn-0.4.0 optuna-3.1.1 outdated-0.2.2\n"]}]},{"cell_type":"code","source":["%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2BZSr40VsL_","executionInfo":{"status":"ok","timestamp":1681216953632,"user_tz":-120,"elapsed":6,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"448eed6f-4e31-4102-b841-b21203cb4d78"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/BUPT-GAMMA/OpenHGNN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7v8yANvVyh-","executionInfo":{"status":"ok","timestamp":1681216990129,"user_tz":-120,"elapsed":2445,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"712645fc-3af0-4691-e72f-534e811882cf"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'OpenHGNN'...\n","remote: Enumerating objects: 6567, done.\u001b[K\n","remote: Counting objects: 100% (377/377), done.\u001b[K\n","remote: Compressing objects: 100% (141/141), done.\u001b[K\n","remote: Total 6567 (delta 245), reused 346 (delta 234), pack-reused 6190\u001b[K\n","Receiving objects: 100% (6567/6567), 15.20 MiB | 14.70 MiB/s, done.\n","Resolving deltas: 100% (4650/4650), done.\n"]}]},{"cell_type":"code","source":["# from networkx.algorithms.centrality import edge_betweenness_centrality"],"metadata":{"id":"6y84LVj_W1m-","executionInfo":{"status":"ok","timestamp":1681217252713,"user_tz":-120,"elapsed":5,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["!python ./OpenHGNN/main.py -m GTN -d imdb4GTN -t node_classification -g -1 --use_best_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14N_Z_UWVcbf","executionInfo":{"status":"ok","timestamp":1681218070645,"user_tz":-120,"elapsed":760907,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"49176bb1-7cd5-4769-9763-539e794bb93f"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Load the best config of model: GTN for dataset: imdb4GTN.\n","------------------------------------------------------------------------------\n"," Basic setup of this experiment: \n","     model: GTN    \n","     dataset: imdb4GTN   \n","     task: node_classification. \n"," This experiment has following parameters. You can use set_params to edit them.\n"," Use print(experiment) to print this information again.\n","------------------------------------------------------------------------------\n","adaptive_lr_flag: True\n","dataset_name: imdb4GTN\n","device: cpu\n","dropout: 0.1\n","gpu: -1\n","hidden_dim: 128\n","hpo_search_space: None\n","hpo_trials: 100\n","identity: True\n","load_from_pretrained: False\n","lr: 0.01\n","max_epoch: 100\n","mini_batch_flag: False\n","model_name: GTN\n","norm_emd_flag: True\n","num_channels: 8\n","num_layers: 2\n","optimizer: Adam\n","out_dim: 16\n","output_dir: ./openhgnn/output/GTN\n","patience: 20\n","seed: 0\n","use_best_config: True\n","weight_decay: 0.001\n","\n","11 Apr 12:48    INFO  [Config Info]\tModel: GTN,\tTask: node_classification,\tDataset: imdb4GTN\u001b[0m\n","\u001b[0m11 Apr 12:48    INFO  [NC Specific] Modify the out_dim with num_classes\u001b[0m\n","\u001b[0m11 Apr 12:48    INFO  [Feature Transformation] Feat is 0, nothing to do!\u001b[0m\n","  0% 0/100 [00:00<?, ?it/s]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:48    INFO  [Train Info] Epoch: 0, Train loss: 1.3782, Valid loss: 1.3339. [Evaluation metric]\tMode:train, Macro_f1: 0.2545; Micro_f1: 0.3633; \tMode:valid, Macro_f1: 0.2355; Micro_f1: 0.3367; \tMode:test, Macro_f1: 0.1939; Micro_f1: 0.2719; \u001b[0m\n","  1% 1/100 [00:25<42:20, 25.66s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:49    INFO  [Train Info] Epoch: 1, Train loss: 1.3316, Valid loss: 1.2202. [Evaluation metric]\tMode:train, Macro_f1: 0.1667; Micro_f1: 0.3333; \tMode:valid, Macro_f1: 0.1667; Micro_f1: 0.3333; \tMode:test, Macro_f1: 0.1576; Micro_f1: 0.3095; \u001b[0m\n","  2% 2/100 [00:51<41:43, 25.54s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:49    INFO  [Train Info] Epoch: 2, Train loss: 1.2094, Valid loss: 1.1430. [Evaluation metric]\tMode:train, Macro_f1: 0.1667; Micro_f1: 0.3333; \tMode:valid, Macro_f1: 0.1667; Micro_f1: 0.3333; \tMode:test, Macro_f1: 0.1576; Micro_f1: 0.3095; \u001b[0m\n","  3% 3/100 [01:15<40:21, 24.96s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:50    INFO  [Train Info] Epoch: 3, Train loss: 1.1147, Valid loss: 1.1007. [Evaluation metric]\tMode:train, Macro_f1: 0.4597; Micro_f1: 0.5500; \tMode:valid, Macro_f1: 0.3162; Micro_f1: 0.4067; \tMode:test, Macro_f1: 0.3234; Micro_f1: 0.5195; \u001b[0m\n","  4% 4/100 [01:40<39:44, 24.84s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:50    INFO  [Train Info] Epoch: 4, Train loss: 1.0586, Valid loss: 1.0554. [Evaluation metric]\tMode:train, Macro_f1: 0.4804; Micro_f1: 0.5767; \tMode:valid, Macro_f1: 0.3717; Micro_f1: 0.4667; \tMode:test, Macro_f1: 0.2546; Micro_f1: 0.2544; \u001b[0m\n","  5% 5/100 [02:05<39:50, 25.16s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:51    INFO  [Train Info] Epoch: 5, Train loss: 0.9931, Valid loss: 1.0193. [Evaluation metric]\tMode:train, Macro_f1: 0.5413; Micro_f1: 0.5633; \tMode:valid, Macro_f1: 0.2729; Micro_f1: 0.3867; \tMode:test, Macro_f1: 0.2527; Micro_f1: 0.3578; \u001b[0m\n","  6% 6/100 [02:31<39:34, 25.26s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:51    INFO  [Train Info] Epoch: 6, Train loss: 0.8754, Valid loss: 0.9753. [Evaluation metric]\tMode:train, Macro_f1: 0.6773; Micro_f1: 0.6967; \tMode:valid, Macro_f1: 0.3805; Micro_f1: 0.4500; \tMode:test, Macro_f1: 0.4301; Micro_f1: 0.6199; \u001b[0m\n","  7% 7/100 [02:55<38:30, 24.84s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:51    INFO  [Train Info] Epoch: 7, Train loss: 0.7422, Valid loss: 0.8333. [Evaluation metric]\tMode:train, Macro_f1: 0.9566; Micro_f1: 0.9567; \tMode:valid, Macro_f1: 0.6990; Micro_f1: 0.7000; \tMode:test, Macro_f1: 0.6148; Micro_f1: 0.6327; \u001b[0m\n","  8% 8/100 [03:19<37:56, 24.75s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:52    INFO  [Train Info] Epoch: 8, Train loss: 0.5359, Valid loss: 0.7607. [Evaluation metric]\tMode:train, Macro_f1: 0.9221; Micro_f1: 0.9233; \tMode:valid, Macro_f1: 0.6307; Micro_f1: 0.6700; \tMode:test, Macro_f1: 0.4623; Micro_f1: 0.4716; \u001b[0m\n","  9% 9/100 [03:44<37:36, 24.80s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:52    INFO  [Train Info] Epoch: 9, Train loss: 0.3839, Valid loss: 0.6912. [Evaluation metric]\tMode:train, Macro_f1: 0.9532; Micro_f1: 0.9533; \tMode:valid, Macro_f1: 0.7157; Micro_f1: 0.7233; \tMode:test, Macro_f1: 0.5719; Micro_f1: 0.5789; \u001b[0m\n"," 10% 10/100 [04:09<37:03, 24.71s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:53    INFO  [Train Info] Epoch: 10, Train loss: 0.2092, Valid loss: 0.7379. [Evaluation metric]\tMode:train, Macro_f1: 0.9667; Micro_f1: 0.9667; \tMode:valid, Macro_f1: 0.6701; Micro_f1: 0.6667; \tMode:test, Macro_f1: 0.6364; Micro_f1: 0.6682; \u001b[0m\n"," 11% 11/100 [04:34<36:51, 24.85s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:53    INFO  [Train Info] Epoch: 11, Train loss: 0.1193, Valid loss: 0.8130. [Evaluation metric]\tMode:train, Macro_f1: 0.9867; Micro_f1: 0.9867; \tMode:valid, Macro_f1: 0.6872; Micro_f1: 0.6833; \tMode:test, Macro_f1: 0.6259; Micro_f1: 0.6588; \u001b[0m\n"," 12% 12/100 [04:59<36:38, 24.99s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:53    INFO  [Train Info] Epoch: 12, Train loss: 0.0595, Valid loss: 0.8500. [Evaluation metric]\tMode:train, Macro_f1: 0.9967; Micro_f1: 0.9967; \tMode:valid, Macro_f1: 0.6943; Micro_f1: 0.6933; \tMode:test, Macro_f1: 0.6080; Micro_f1: 0.6280; \u001b[0m\n"," 13% 13/100 [05:25<36:28, 25.16s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:54    INFO  [Train Info] Epoch: 13, Train loss: 0.0204, Valid loss: 0.9685. [Evaluation metric]\tMode:train, Macro_f1: 0.9967; Micro_f1: 0.9967; \tMode:valid, Macro_f1: 0.6941; Micro_f1: 0.6967; \tMode:test, Macro_f1: 0.5774; Micro_f1: 0.5896; \u001b[0m\n"," 14% 14/100 [05:49<35:43, 24.92s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:54    INFO  [Train Info] Epoch: 14, Train loss: 0.0101, Valid loss: 1.1042. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6610; Micro_f1: 0.6667; \tMode:test, Macro_f1: 0.5521; Micro_f1: 0.5614; \u001b[0m\n"," 15% 15/100 [06:15<35:39, 25.17s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:55    INFO  [Train Info] Epoch: 15, Train loss: 0.0068, Valid loss: 1.2103. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6557; Micro_f1: 0.6633; \tMode:test, Macro_f1: 0.5555; Micro_f1: 0.5635; \u001b[0m\n"," 16% 16/100 [06:41<35:29, 25.35s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:55    INFO  [Train Info] Epoch: 16, Train loss: 0.0044, Valid loss: 1.2944. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6579; Micro_f1: 0.6633; \tMode:test, Macro_f1: 0.5561; Micro_f1: 0.5643; \u001b[0m\n"," 17% 17/100 [07:06<34:58, 25.28s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:56    INFO  [Train Info] Epoch: 17, Train loss: 0.0025, Valid loss: 1.3719. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6624; Micro_f1: 0.6667; \tMode:test, Macro_f1: 0.5609; Micro_f1: 0.5716; \u001b[0m\n"," 18% 18/100 [07:31<34:28, 25.22s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:56    INFO  [Train Info] Epoch: 18, Train loss: 0.0015, Valid loss: 1.4463. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6673; Micro_f1: 0.6700; \tMode:test, Macro_f1: 0.5665; Micro_f1: 0.5806; \u001b[0m\n"," 19% 19/100 [07:57<34:23, 25.48s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:56    INFO  [Train Info] Epoch: 19, Train loss: 0.0010, Valid loss: 1.5227. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6551; Micro_f1: 0.6567; \tMode:test, Macro_f1: 0.5695; Micro_f1: 0.5866; \u001b[0m\n"," 20% 20/100 [08:22<34:01, 25.52s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:57    INFO  [Train Info] Epoch: 20, Train loss: 0.0007, Valid loss: 1.6041. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6597; Micro_f1: 0.6600; \tMode:test, Macro_f1: 0.5674; Micro_f1: 0.5866; \u001b[0m\n"," 21% 21/100 [08:46<32:49, 24.93s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:57    INFO  [Train Info] Epoch: 21, Train loss: 0.0007, Valid loss: 1.6848. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6631; Micro_f1: 0.6633; \tMode:test, Macro_f1: 0.5657; Micro_f1: 0.5866; \u001b[0m\n"," 22% 22/100 [09:11<32:22, 24.91s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:58    INFO  [Train Info] Epoch: 22, Train loss: 0.0007, Valid loss: 1.7537. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6666; Micro_f1: 0.6667; \tMode:test, Macro_f1: 0.5648; Micro_f1: 0.5870; \u001b[0m\n"," 23% 23/100 [09:36<31:54, 24.86s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:58    INFO  [Train Info] Epoch: 23, Train loss: 0.0006, Valid loss: 1.8046. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6595; Micro_f1: 0.6600; \tMode:test, Macro_f1: 0.5592; Micro_f1: 0.5819; \u001b[0m\n"," 24% 24/100 [09:59<31:00, 24.48s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:58    INFO  [Train Info] Epoch: 24, Train loss: 0.0006, Valid loss: 1.8356. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6561; Micro_f1: 0.6567; \tMode:test, Macro_f1: 0.5579; Micro_f1: 0.5793; \u001b[0m\n"," 25% 25/100 [10:24<30:50, 24.68s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:59    INFO  [Train Info] Epoch: 25, Train loss: 0.0005, Valid loss: 1.8478. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6630; Micro_f1: 0.6633; \tMode:test, Macro_f1: 0.5545; Micro_f1: 0.5755; \u001b[0m\n"," 26% 26/100 [10:50<30:37, 24.82s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 12:59    INFO  [Train Info] Epoch: 26, Train loss: 0.0004, Valid loss: 1.8456. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6530; Micro_f1: 0.6533; \tMode:test, Macro_f1: 0.5522; Micro_f1: 0.5725; \u001b[0m\n"," 27% 27/100 [11:14<30:14, 24.86s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 13:00    INFO  [Train Info] Epoch: 27, Train loss: 0.0004, Valid loss: 1.8318. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6493; Micro_f1: 0.6500; \tMode:test, Macro_f1: 0.5493; Micro_f1: 0.5695; \u001b[0m\n"," 28% 28/100 [11:40<29:59, 24.99s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 13:00    INFO  [Train Info] Epoch: 28, Train loss: 0.0004, Valid loss: 1.8089. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6560; Micro_f1: 0.6567; \tMode:test, Macro_f1: 0.5509; Micro_f1: 0.5695; \u001b[0m\n"," 29% 29/100 [12:06<29:52, 25.24s/it]\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 13:01    INFO  [Train Info] Epoch: 29, Train loss: 0.0005, Valid loss: 1.7806. [Evaluation metric]\tMode:train, Macro_f1: 1.0000; Micro_f1: 1.0000; \tMode:valid, Macro_f1: 0.6561; Micro_f1: 0.6567; \tMode:test, Macro_f1: 0.5502; Micro_f1: 0.5682; \u001b[0m\n","\u001b[0m11 Apr 13:01    INFO  [Train Info] Early Stop!\tEpoch:29\u001b[0m\n"," 29% 29/100 [12:31<30:40, 25.93s/it]\u001b[0m\n","\u001b[0m/usr/local/lib/python3.9/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n","\u001b[0m11 Apr 13:01    INFO  [Train Info] [Test Info][Evaluation metric]\tMode:valid, Macro_f1: 0.7157; Micro_f1: 0.7233; \tMode:test, Macro_f1: 0.5719; Micro_f1: 0.5789; \u001b[0m\n","\u001b[0m\u001b[0m"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nwbPHpUYrqHA"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}