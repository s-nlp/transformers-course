{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6U6HfU_TqGV",
        "outputId": "76ef003a-f12e-450f-a0ab-d4ab080da2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore all warnings"
      ],
      "metadata": {
        "id": "lw862wrZ3Itg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Example\n",
        "\n",
        "Today we'll see how to work with decoder models in the zero-shot mode. We'll start with the basic GPT3 zero-shot example and then switch to more advanced LLMs."
      ],
      "metadata": {
        "id": "VAenDWgzyfuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZuwDrLOhnuq",
        "outputId": "6173cd15-fc43-4892-9725-38f94bb5589f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ruGPT3 example\n",
        "\n",
        "Load [ruGPT3](https://huggingface.co/ai-forever/rugpt3large_based_on_gpt2)."
      ],
      "metadata": {
        "id": "xJVAEc6LzvOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")"
      ],
      "metadata": {
        "id": "GkT4iqBkTtIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8dEXHEviKjT",
        "outputId": "d6c0be09-f955-4817-c8e5-c0a38e80e473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1536)\n",
              "    (wpe): Embedding(2048, 1536)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot\n",
        "\n",
        "We use model loss for the zero-shot classification.\n",
        "\n",
        "GPT-based models utilize per-token cross-entropy\n",
        "loss, which is reduced to negative log probability\n",
        "due to one-hot encoding of the tokens. **The idea is to select the target label associated with the prompt that results in the lowest sum of negative log probabilities for its tokens.**\n",
        "\n"
      ],
      "metadata": {
        "id": "6EkM9I5Iz6bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_loss_num(text):\n",
        "    # Tokenize the input text and move it to the specified device\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Shift the inputs to create labels for the next-token prediction task\n",
        "    labels = inputs[\"input_ids\"].clone()\n",
        "\n",
        "    # Move labels to the correct device if you're using GPU\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Calculate loss\n",
        "    outputs = model(**inputs, labels=labels, use_cache=True)  # Add use_cache=True to use the cache class\n",
        "    loss = outputs.loss\n",
        "    return loss.item()\n",
        "\n",
        "def clean(text):\n",
        "    text = re.sub(r'\\((\\d+)\\)', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "1SEG6JH7VZRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task: twitter tone analysis\n",
        "\n",
        "Today we'll solve a sentiment analysis task. Let us start with some toy examples and try to come up with the prompts that can distinguish positive and negative texts.\n",
        "\n",
        "**Positive promt example**"
      ],
      "metadata": {
        "id": "zF43GxCq0RVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'жизнь отличная'\n",
        "get_loss_num('Позитивный твит: ' + text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyGy73vNT0tp",
        "outputId": "c160128f-a755-4f90-c11e-3ff81e1e1d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.202009201049805"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Negative prompt example**"
      ],
      "metadata": {
        "id": "5T7fmF3hDVft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_loss_num('Негативный твит: ' + text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrwseqWUVkQw",
        "outputId": "ceddc8dd-4d37-440e-934e-c6f6df0f046c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.3455810546875"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add smiles!"
      ],
      "metadata": {
        "id": "HgUJzqsTzSbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_loss_num('Позитивный твит: ' + text + ')))'))\n",
        "print(get_loss_num('Негативный твит: ' + text + '((('))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkLI_DgkzRgX",
        "outputId": "64c04545-95d5-4fc6-ecd3-a093e96cb434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.151878356933594\n",
            "7.050114154815674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we implement a function that selects the label which yeilds the lowest loss."
      ],
      "metadata": {
        "id": "iw_QSnoQDYyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_zero_shot(text, pos = 'Позитивный твит: {})))', neg = 'Негативный твит: {}((('):\n",
        "  pos_loss = get_loss_num(pos.format(text))\n",
        "  neg_loss = get_loss_num(neg.format(text))\n",
        "  if pos_loss < neg_loss:\n",
        "    return 'positive'\n",
        "  return 'negative'\n",
        "\n",
        "predict_zero_shot(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fOemj3PbeCZi",
        "outputId": "78f93e58-50d4-41a9-b1ad-08f3a1d88d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply this approach to the twitter sentimant classification task."
      ],
      "metadata": {
        "id": "hIjTg1Xr0klg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O twitter_short.csv https://drive.usercontent.google.com/download?id=17qSrjy5NyknCfhs1kqGwHcHgml9UzpvS&export=download&authuser=0&confirm=t&uuid=cb32846f-bc96-4eb0-9e29-57d27a89e369&at=AN_67v2rr2Fh_KVc0V-EDJQ7bufm:1729946024386"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0H4sqBm0QZp",
        "outputId": "1311dfb1-b6c7-4fe5-cc0f-8a103f7f4b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-26 13:47:52--  https://drive.usercontent.google.com/download?id=17qSrjy5NyknCfhs1kqGwHcHgml9UzpvS\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.118.132, 2404:6800:4003:c05::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.118.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14363 (14K) [application/octet-stream]\n",
            "Saving to: ‘twitter_short.csv’\n",
            "\n",
            "twitter_short.csv   100%[===================>]  14.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-26 13:47:55 (70.3 MB/s) - ‘twitter_short.csv’ saved [14363/14363]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('twitter_short.csv', index_col = 0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_AzZm-fQm9ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "801f0cdc-577e-4f0e-b612-b55892554244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  на работе был полный пиддес :| и так каждое за...  negative\n",
              "1  Коллеги сидят рубятся в Urban terror, а я из-з...  negative\n",
              "2  @elina_4post как говорят обещаного три года жд...  negative\n",
              "3  Желаю хорошего полёта и удачной посадки,я буду...  negative\n",
              "4  Обновил за каким-то лешим surf, теперь не рабо...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a162c00-c993-4967-af87-35acc6a27ee8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a162c00-c993-4967-af87-35acc6a27ee8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a162c00-c993-4967-af87-35acc6a27ee8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a162c00-c993-4967-af87-35acc6a27ee8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a7a5f7e-5269-4d1e-a48f-6b360f44c4c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a7a5f7e-5269-4d1e-a48f-6b360f44c4c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a7a5f7e-5269-4d1e-a48f-6b360f44c4c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"\\u044f \\u0440\\u0430\\u0430\\u0430\\u0430\\u0430\\u0430\\u0430\\u0434,\\u0432\\u0435\\u0434\\u044c \\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f \\u0432\\u043f\\u0435\\u0440\\u0435\\u0434\\u0438 \\u0432\\u0441\\u044f \\u043d\\u043e\\u0447\\u044c,\\u0441\\u0435\\u0440\\u0438\\u0430\\u043b\\u044b,\\u0444\\u0438\\u043b\\u044c\\u043c\\u044b,\\u043a\\u043d\\u0438\\u0433\\u0430 \\u0438 \\u043a\\u043e\\u0444\\u0435:) \\u0438\\u0434\\u0435\\u0430\\u043b\\u044c\\u043d\\u0430\\u044f \\u043d\\u043e\\u0447\\u043a\\u0430:)\",\n          \"RT @digger2912: \\\"\\u041a\\u0442\\u043e \\u0442\\u043e \\u0432 \\u0443\\u0433\\u043b\\u0443 \\u0441\\u0438\\u0434\\u0438\\u0442 \\u0438 \\u043f\\u043e\\u0433\\u0438\\u0431\\u0430\\u0435\\u0442 \\u043e\\u0442 \\u0433\\u043e\\u043b\\u043e\\u0434\\u0430, \\u0430 \\u043c\\u044b \\u0435\\u0449\\u0451 2 \\u043f\\u043e\\u0440\\u0446\\u0438\\u0438 \\u0432\\u0437\\u044f\\u043b\\u0438, \\u0445\\u043e\\u0442\\u044f \\u0443\\u0436\\u0435 \\u0438 \\u0442\\u0430\\u043a \\u0436\\u0440\\u0430\\u0442\\u044c \\u043d\\u0435 \\u0445\\u043e\\u0442\\u0438\\u043c\\\" :DD\",\n          \"\\u0423 \\u043d\\u0430\\u0441 \\u0435\\u0441\\u0442\\u044c \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0430\\u044f \\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u044f, \\u043a\\u0430\\u043a \\u0441\\u0434\\u043e\\u0445\\u043d\\u0443\\u0442\\u044c \\u0437\\u0430 \\u043d\\u0435\\u0434\\u0435\\u043b\\u044e!!)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MlxCe-ldpQlN",
        "outputId": "a7ea59cb-f88e-4daa-e8fc-138320adc5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text     label\n",
              "95  Встречайте, мои супер одногруппницы, будущие и...  positive\n",
              "96  все,я вас покидаю,результаты гляну вечером)#би...  positive\n",
              "97  RT @Dasha_crazy_69: @DashkaTeddy дыы))) но кто...  positive\n",
              "98    Почти приехали в родное селенье!) @ москва-рига  positive\n",
              "99  На*уй ваши Канары и Мальдивы ! Тут новая тема ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98059b78-ba5c-48fe-92e1-1cbb253446bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Встречайте, мои супер одногруппницы, будущие и...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>все,я вас покидаю,результаты гляну вечером)#би...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>RT @Dasha_crazy_69: @DashkaTeddy дыы))) но кто...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Почти приехали в родное селенье!) @ москва-рига</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>На*уй ваши Канары и Мальдивы ! Тут новая тема ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98059b78-ba5c-48fe-92e1-1cbb253446bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98059b78-ba5c-48fe-92e1-1cbb253446bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98059b78-ba5c-48fe-92e1-1cbb253446bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9018967a-f02e-4669-9bb5-1ae15ed78ebb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9018967a-f02e-4669-9bb5-1ae15ed78ebb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9018967a-f02e-4669-9bb5-1ae15ed78ebb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0432\\u0441\\u0435,\\u044f \\u0432\\u0430\\u0441 \\u043f\\u043e\\u043a\\u0438\\u0434\\u0430\\u044e,\\u0440\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u044b \\u0433\\u043b\\u044f\\u043d\\u0443 \\u0432\\u0435\\u0447\\u0435\\u0440\\u043e\\u043c)#\\u0431\\u0438\\u0430\\u0442\\u043b\\u043e\\u043d\",\n          \"\\u041d\\u0430*\\u0443\\u0439 \\u0432\\u0430\\u0448\\u0438 \\u041a\\u0430\\u043d\\u0430\\u0440\\u044b \\u0438 \\u041c\\u0430\\u043b\\u044c\\u0434\\u0438\\u0432\\u044b ! \\u0422\\u0443\\u0442 \\u043d\\u043e\\u0432\\u0430\\u044f \\u0442\\u0435\\u043c\\u0430 \\u043f\\u0440\\u043e\\u0441\\u043a\\u043e\\u0447\\u0438\\u043b\\u0430 ! ))\",\n          \"RT @Dasha_crazy_69: @DashkaTeddy \\u0434\\u044b\\u044b))) \\u043d\\u043e \\u043a\\u0442\\u043e \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b, \\u0447\\u0442\\u043e \\u044f \\u0412\\u0421\\u0415 \\u043f\\u043e\\u043d\\u044f\\u043b\\u0430 \\u0430\\u0430\\u0445\\u0445\\u0430\\u0445?)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "df['preds'] = df.text.apply(predict_zero_shot)\n",
        "accuracy_score(df.label, df.preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25IpcIkkp9-y",
        "outputId": "81b970ab-fb8f-44e3-f17a-bdf87e410ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def encode_label(x):\n",
        "  if x == 'negative':\n",
        "    return 0\n",
        "  return 1\n",
        "f1_score(df.label.apply(encode_label), df.preds.apply(encode_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jNw2Q1f1BJ4",
        "outputId": "060335b8-e34a-41c7-e812-e30c35fbfc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7868852459016393"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QWEN2.5\n",
        "\n",
        "[Qwen2.5](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct) is a small LLM which can be run in Colab."
      ],
      "metadata": {
        "id": "GhQoCfCh04z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "model.to(device);\n"
      ],
      "metadata": {
        "id": "-dAGTxwv1wGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First look how it works for simple text generation task."
      ],
      "metadata": {
        "id": "36KM7HFk2vT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Продолжи поговорку:\\nБез труда\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zabfRYx42uJQ",
        "outputId": "0b69396e-d0a8-4be0-aa63-0cabcf7a015e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZUndb6W21IH",
        "outputId": "d6e6d16d-a734-4f8a-a643-f6e9f078030a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 53645,   9516,  47081,   1802,   5063,  14497, 125661,  35252,    510,\n",
              "          60332,  31885,  10813,  19763,  39490]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First try:"
      ],
      "metadata": {
        "id": "7e4r4Wxi29qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**tokens, top_k=1).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vcnPNTw22Z5",
        "outputId": "14413c8a-ce1f-4848-d0f4-1652fb6c1e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда не выйдешь,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**tokens, num_beams=4, max_length=30).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDVIRTEO28Jn",
        "outputId": "b934e274-8ee4-44cd-8a6e-12881dc3f3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего не добь\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**tokens, num_beams=4, num_return_sequences=4, max_length=40).cpu()\n",
        "print(\"\\n\\n\\n\".join(tokenizer.batch_decode(outputs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqRnytNT27Yd",
        "outputId": "2975e58c-b609-4924-f369-7e56b7781838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Эта поговорка\n",
            "\n",
            "\n",
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Исправь ошибки\n",
            "\n",
            "\n",
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Исправь ошибку\n",
            "\n",
            "\n",
            "Продолжи поговорку:\n",
            "Без труда ничего не добьешься, но без труда ничего и не добьешься.\n",
            "\n",
            "Эта фраза под\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System prompt\n",
        "\n",
        "A **system prompt** (or system message) is a special instruction provided to an LLM that defines its behavior, tone, personality, and constraints during interactions with users. It serves as a foundational guideline that sets expectations for how the model should respond to user inputs throughout a session.\n",
        "\n",
        "But how? Let's ask [Mistral](https://chat.mistral.ai/), [ChatGPT](https://chatgpt.com), or Gemini! Open a model chat and type:\n",
        "\n",
        "\n",
        "```\n",
        "Add system prompt in gwen 2.5\n",
        "```\n",
        "\n",
        "Let's now add a system prompt!\n",
        "\n"
      ],
      "metadata": {
        "id": "-sm--d_K3aZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"Ты — помощник, который генерирует пословицы на русском языке.\"  # Define your system prompt\n",
        "\n",
        "prompt = \"Продолжи поговорку:\\nБез труда\"\n",
        "# Combine system prompt and user prompt into a full prompt\n",
        "full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
        "# Tokenize the full prompt\n",
        "tokens = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Generate the response using the Qwen-2 model\n",
        "outputs = model.generate(**tokens, num_beams=4, num_return_sequences=4, max_length=70).cpu()\n",
        "print(\"\\n\\n\\n\".join([x.split('\\n\\n')[-1] for x in tokenizer.batch_decode(outputs)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuyF54j850gw",
        "outputId": "698ab84c-4f0a-4ae8-dd4c-f5d69a006e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ваш ответ: Без труда не пришёл, без тру\n",
            "\n",
            "\n",
            "1. Без труда не пришё\n",
            "\n",
            "\n",
            "Следующая поговорка:\n",
            "Без труда не при\n",
            "\n",
            "\n",
            "Ваш ответ: Без труда не пришёл, ни с т\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gwen2.5 for sentiment analysis\n",
        "\n",
        "Now, let's look how it solves the sentiment analysis task. First, try the simple generation approach.\n",
        "\n"
      ],
      "metadata": {
        "id": "la12JHTa-yX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'жизнь отличная'\n",
        "prompt = \"Напиши pos в случае если приведенный текст твита позитивный и neg в случае если негативный. Ничего больше не добавляй. Текст твита:\\n{}\".format(text)\n",
        "print(prompt)\n",
        "# Combine system prompt and user prompt into a full prompt\n",
        "# Tokenize the full prompt\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(**tokens, num_beams=2, num_return_sequences=1, max_length=100).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0].replace(prompt,''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbsk4YPAFIu",
        "outputId": "cc9a4f3a-f11b-49f9-e109-2ffda9b66307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Напиши pos в случае если приведенный текст твита позитивный и neg в случае если негативный. Ничего больше не добавляй. Текст твита:\n",
            "жизнь отличная\n",
            ", всё хорошо, счастье, радость, веселье, солнечный день, солнечный вечер, солнечный вечер, солнечный вечер, солнечный вечер, с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a system prompt."
      ],
      "metadata": {
        "id": "jZvIy5jbEjsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"Ты — помощник, который задачу sentiment analysis.\"  # Define your system prompt\n",
        "text = 'жизнь отличная'\n",
        "\n",
        "prompt = \"Напиши pos в случае если приведенный текст твита позитивный и neg в случае если негативный. Ничего больше не добавляй. Текст твита:\\n{}\".format(text)\n",
        "# Combine system prompt and user prompt into a full prompt\n",
        "full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
        "# Tokenize the full prompt\n",
        "tokens = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(**tokens, num_beams=2, num_return_sequences=1, max_length=100).cpu()\n",
        "print(tokenizer.batch_decode(outputs)[0].replace(full_prompt,''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-QrdBw18Ax7",
        "outputId": "f137a918-f262-48fd-e486-6170786fd586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", всё хорошо\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n",
            "\n",
            "pos, neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is too small and the result is now that good. But what about the loss variant?"
      ],
      "metadata": {
        "id": "tJrDqL8nEnIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_loss_num('Позитивный твит: ' + text))\n",
        "print(get_loss_num('Негативный твит: ' + text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4NmqIzQ_Y3c",
        "outputId": "14ff2a94-9ea9-4b55-dc9d-48be1f9569be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7961058616638184\n",
            "4.003838539123535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_loss_num('Позитивный твит: ' + text + ')))'))\n",
        "print(get_loss_num('Негативный твит: ' + text + '((('))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD-0omm3A-ei",
        "outputId": "eb37c5e0-bbaa-4837-e8e3-bb16d5088dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.081405162811279\n",
            "4.601905822753906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "df['preds_qwen'] = df.text.apply(predict_zero_shot)\n",
        "accuracy_score(df.label, df.preds_qwen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi9HGC6IBbUD",
        "outputId": "9553a7f2-a680-4fa9-868a-cacfbf0bf34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(df.label.apply(encode_label), df.preds_qwen.apply(encode_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbpq_yz-Bxu6",
        "outputId": "1fe9437d-a5e7-4cf6-f922-e395cba8bb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8347826086956521"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}