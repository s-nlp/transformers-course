{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"342291bb8fa0442296a5bba9e987b35e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9445dcf330d340dbbec8207e13d2debf","IPY_MODEL_bf5fe1248dd3443d969bd6d1e80b573f","IPY_MODEL_c6f2543d8e28489eb94d07b40f3048ce"],"layout":"IPY_MODEL_785b21d7be2d4bf2bb355dc71d092abd"}},"9445dcf330d340dbbec8207e13d2debf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb5b031aa9134dcd97d2ce0cb8152930","placeholder":"​","style":"IPY_MODEL_77af57a2ed4d4cf8a2a4666ab4094d0a","value":"100%"}},"bf5fe1248dd3443d969bd6d1e80b573f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb94e5392dae4e15a5b2a03c04accf7c","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65e931c271124c03b1379c35f74094ac","value":100}},"c6f2543d8e28489eb94d07b40f3048ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_444b88d366d84fc7999ac3bf5bc22847","placeholder":"​","style":"IPY_MODEL_7825cbdbc4ef405f82a3837133596a7f","value":" 100/100 [00:19&lt;00:00,  6.48it/s]"}},"785b21d7be2d4bf2bb355dc71d092abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb5b031aa9134dcd97d2ce0cb8152930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77af57a2ed4d4cf8a2a4666ab4094d0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb94e5392dae4e15a5b2a03c04accf7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e931c271124c03b1379c35f74094ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"444b88d366d84fc7999ac3bf5bc22847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7825cbdbc4ef405f82a3837133596a7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d0a644b9634f47b3b2060b4193764f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e827eb98e59a418e92400328cc8ddf3e","IPY_MODEL_f8e8354a90634f0d81dc2d56188a26fc","IPY_MODEL_a538ffa0fd524c919b5d13f62366afd8"],"layout":"IPY_MODEL_55e7f44bb9fc4cab8da81fce2d1688f5"}},"e827eb98e59a418e92400328cc8ddf3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e56bae63ce0f417b87cba1247abb8362","placeholder":"​","style":"IPY_MODEL_8272c81342b64b4e878fd519e6f6d4f9","value":"100%"}},"f8e8354a90634f0d81dc2d56188a26fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28bbebf0256e49f98217395bfdfcfebd","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8d34c20b2b04cae9f169103eb764d5e","value":100}},"a538ffa0fd524c919b5d13f62366afd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecb38a9843514613ae9701be8e03727e","placeholder":"​","style":"IPY_MODEL_ffbfe10024ff4d21834f9b9c4e213168","value":" 100/100 [00:29&lt;00:00,  3.50it/s]"}},"55e7f44bb9fc4cab8da81fce2d1688f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56bae63ce0f417b87cba1247abb8362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8272c81342b64b4e878fd519e6f6d4f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28bbebf0256e49f98217395bfdfcfebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d34c20b2b04cae9f169103eb764d5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecb38a9843514613ae9701be8e03727e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffbfe10024ff4d21834f9b9c4e213168":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f8cf359f04146c7ba1e655fdc23f0de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_192aae3c85604ba1912ae7c68223dedd","IPY_MODEL_da28dfa422c04822a36039730c5d7ab7","IPY_MODEL_f1aef256faac42cc82a45d41375ba717"],"layout":"IPY_MODEL_6594a7e200614d03bbc33580d5ca8d4e"}},"192aae3c85604ba1912ae7c68223dedd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5f786d1896f4df299f2fe15821d8181","placeholder":"​","style":"IPY_MODEL_8868d3587dd44c98a9a6c9d02c04f398","value":"100%"}},"da28dfa422c04822a36039730c5d7ab7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e019239cea6c40f288d28492dae5d0b0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccbf573016664a79ad8b5b1761fbaa4d","value":1}},"f1aef256faac42cc82a45d41375ba717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_398bb71f17bf4c89a1451af098ab5130","placeholder":"​","style":"IPY_MODEL_9fa007bf7f624a129dff9925b70b794d","value":" 1/1 [02:20&lt;00:00, 140.46s/it]"}},"6594a7e200614d03bbc33580d5ca8d4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5f786d1896f4df299f2fe15821d8181":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8868d3587dd44c98a9a6c9d02c04f398":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e019239cea6c40f288d28492dae5d0b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccbf573016664a79ad8b5b1761fbaa4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"398bb71f17bf4c89a1451af098ab5130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa007bf7f624a129dff9925b70b794d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f74355c9517a4e249d2369477e6fd2de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd3d801ca0984e20af04de607ff5dca6","IPY_MODEL_11d2650bff54453a8875a6e0077a1d0b","IPY_MODEL_6bb39f6d4277493e9a7fc2d130b9a34f"],"layout":"IPY_MODEL_9ddd57db06204f0ca0048ae447014bc4"}},"bd3d801ca0984e20af04de607ff5dca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f373efae00d6467cb20c623bdbebc92d","placeholder":"​","style":"IPY_MODEL_af78d1592d364706acea748be84c1398","value":"1.9498082399368286: 100%"}},"11d2650bff54453a8875a6e0077a1d0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8889a068550042bab820739d7afd4662","max":2529,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dff15591cfb04a58878a430396b8335b","value":2529}},"6bb39f6d4277493e9a7fc2d130b9a34f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_946b53ba521548d989c70233909c3d31","placeholder":"​","style":"IPY_MODEL_f921ee72030b47178c1c3ef83f680aa8","value":" 2529/2529 [02:20&lt;00:00, 17.90it/s]"}},"9ddd57db06204f0ca0048ae447014bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f373efae00d6467cb20c623bdbebc92d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af78d1592d364706acea748be84c1398":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8889a068550042bab820739d7afd4662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dff15591cfb04a58878a430396b8335b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"946b53ba521548d989c70233909c3d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f921ee72030b47178c1c3ef83f680aa8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7a621c44e3c49c497e3fa8d97b18e87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54eab803c0ff41d49920c834fef0cf0c","IPY_MODEL_285c9bc84cec44b2b08bb8aa8d7d6b5f","IPY_MODEL_ba75cd47a13f48bd8109a8ccc7a6c4ce"],"layout":"IPY_MODEL_63b95ff2b3a54e51b56e3f8d90066b41"}},"54eab803c0ff41d49920c834fef0cf0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8198b7fbeb03444aa5c61d8e6db43cd2","placeholder":"​","style":"IPY_MODEL_fda90f847f92478e82c2706328e05602","value":"100%"}},"285c9bc84cec44b2b08bb8aa8d7d6b5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eebd94dd44546b088ac8261cd482f06","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f740d297bc4b4ec1a1d074c875e95a6e","value":100}},"ba75cd47a13f48bd8109a8ccc7a6c4ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f635e7bb78a4fcaafe31583965f14bf","placeholder":"​","style":"IPY_MODEL_b801dbf70930491384b61f7a4b0e0634","value":" 100/100 [00:13&lt;00:00, 10.88it/s]"}},"63b95ff2b3a54e51b56e3f8d90066b41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8198b7fbeb03444aa5c61d8e6db43cd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fda90f847f92478e82c2706328e05602":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4eebd94dd44546b088ac8261cd482f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f740d297bc4b4ec1a1d074c875e95a6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f635e7bb78a4fcaafe31583965f14bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b801dbf70930491384b61f7a4b0e0634":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb6982a1981346a89d80e13a381471b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e883fab69a654211b9c25355480b02eb","IPY_MODEL_8bbfb2dde74c4d0cb04b628d2453ef99","IPY_MODEL_c52f7964e0bc43119c0db39202b70b75"],"layout":"IPY_MODEL_19aa7e418f9e489d8f529f591684d28b"}},"e883fab69a654211b9c25355480b02eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5069dbe6fe16496d8bd1bb8e0ea6db36","placeholder":"​","style":"IPY_MODEL_38526c7411ad4135b75913f148484068","value":"100%"}},"8bbfb2dde74c4d0cb04b628d2453ef99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54e9cc5b40a64781a2d8a3794d9ca5e7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7ef3d5236864b2eb8ddd21a9ca0fe45","value":1}},"c52f7964e0bc43119c0db39202b70b75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b760cd2ef9374e42a2eaaca491eacee3","placeholder":"​","style":"IPY_MODEL_4701fcc644d24c6783126c0865bee192","value":" 1/1 [03:35&lt;00:00, 215.87s/it]"}},"19aa7e418f9e489d8f529f591684d28b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5069dbe6fe16496d8bd1bb8e0ea6db36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38526c7411ad4135b75913f148484068":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54e9cc5b40a64781a2d8a3794d9ca5e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ef3d5236864b2eb8ddd21a9ca0fe45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b760cd2ef9374e42a2eaaca491eacee3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4701fcc644d24c6783126c0865bee192":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0813c5db8e804be7b7ef7eb443c2857e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_815aa269eb8b4410b3a1b5d0684c943f","IPY_MODEL_27d6bfe53e5f4875a57b889de836f9bf","IPY_MODEL_22a2c177de6b40caac76b2c8f1f2d40b"],"layout":"IPY_MODEL_2de3484f64204a098f9d693a80817cad"}},"815aa269eb8b4410b3a1b5d0684c943f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af85b39708b847059ac0d82c9c67851c","placeholder":"​","style":"IPY_MODEL_2db5cb63803d44a1be120df7346391cd","value":"1.4418598413467407: 100%"}},"27d6bfe53e5f4875a57b889de836f9bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c32e3e4643d46b9828e08567e8233ec","max":2529,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7241db72c80d406cadbb73ca6cdb906e","value":2529}},"22a2c177de6b40caac76b2c8f1f2d40b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8108cf6ad8fa44adbcaccde7b8ab6c5e","placeholder":"​","style":"IPY_MODEL_b8b3cae9d2104e95b41589ea654e6189","value":" 2529/2529 [03:35&lt;00:00, 11.80it/s]"}},"2de3484f64204a098f9d693a80817cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af85b39708b847059ac0d82c9c67851c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db5cb63803d44a1be120df7346391cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c32e3e4643d46b9828e08567e8233ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7241db72c80d406cadbb73ca6cdb906e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8108cf6ad8fa44adbcaccde7b8ab6c5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b3cae9d2104e95b41589ea654e6189":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"298ecf71a4f946acbcb2b1bb7fbbb0fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd9d4e4328dc4ef2bc1db3cc0f1df090","IPY_MODEL_2b4a3c278e8240308da6ce430690b930","IPY_MODEL_a67059a3bdcd4aebbe3ada34fba95847"],"layout":"IPY_MODEL_81d9091f8bd3472bae635d57f0d7a361"}},"dd9d4e4328dc4ef2bc1db3cc0f1df090":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0500f4b3d1ef4717a61184a2a4f3ee76","placeholder":"​","style":"IPY_MODEL_20bfa6a1000f4366beecebb3da4cddb1","value":"100%"}},"2b4a3c278e8240308da6ce430690b930":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78d304765f0e4b8abed6ac784164cc38","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84a0e46a8e20488ba92d9c7eecbb28f7","value":100}},"a67059a3bdcd4aebbe3ada34fba95847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa053c59d2f64d30a2c2422ab927e86c","placeholder":"​","style":"IPY_MODEL_b3fa467dff9e42dd9cafc70376f884e6","value":" 100/100 [00:16&lt;00:00,  6.88it/s]"}},"81d9091f8bd3472bae635d57f0d7a361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0500f4b3d1ef4717a61184a2a4f3ee76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20bfa6a1000f4366beecebb3da4cddb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78d304765f0e4b8abed6ac784164cc38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84a0e46a8e20488ba92d9c7eecbb28f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa053c59d2f64d30a2c2422ab927e86c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3fa467dff9e42dd9cafc70376f884e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6509bfe519d6437c9832e0acb4e53865":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37c83fe1fc4d4aa8a97e1f37a0d16765","IPY_MODEL_3974da0eae8e4ae985186633ca1fb23f","IPY_MODEL_6c1fd3620c584d119870f0b36ee81a17"],"layout":"IPY_MODEL_48bb5c2cf19247919223fbf88934c78f"}},"37c83fe1fc4d4aa8a97e1f37a0d16765":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_573f75055bd54a4d9674786e25e6824a","placeholder":"​","style":"IPY_MODEL_1b970a5492ae4f78aec48438e1e84ab8","value":"Downloading: 100%"}},"3974da0eae8e4ae985186633ca1fb23f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d35e118f1c44626934b05e769cae075","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b0197c484094f15917d680c1775d8f6","value":1042301}},"6c1fd3620c584d119870f0b36ee81a17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff83615bf3a413eb635820b01e3aaee","placeholder":"​","style":"IPY_MODEL_8ba7c62679a745a18f0dee2ea1f423ca","value":" 0.99M/0.99M [00:00&lt;00:00, 1.10MB/s]"}},"48bb5c2cf19247919223fbf88934c78f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"573f75055bd54a4d9674786e25e6824a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b970a5492ae4f78aec48438e1e84ab8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d35e118f1c44626934b05e769cae075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b0197c484094f15917d680c1775d8f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ff83615bf3a413eb635820b01e3aaee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ba7c62679a745a18f0dee2ea1f423ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7930cc4f5e24745a23b73bbb7992627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_432293249dd847f196332d15b336de0e","IPY_MODEL_653af791977a49d58b4cf1215f2607c5","IPY_MODEL_8b7e486e45f842d7bfa5ef812447209a"],"layout":"IPY_MODEL_0b5cf460b58d4c9293c464196ad5b3fd"}},"432293249dd847f196332d15b336de0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9277d91b90d84dc2b4836526473d206e","placeholder":"​","style":"IPY_MODEL_4a0bf463ed9348608f2c00a8a042d044","value":"Downloading: 100%"}},"653af791977a49d58b4cf1215f2607c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8aa91e88b6d4bc58897ed9539044870","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d67df0c4c7fe4850907d41a333802861","value":456318}},"8b7e486e45f842d7bfa5ef812447209a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43445b90528c4fc8a38de0956a44ea2a","placeholder":"​","style":"IPY_MODEL_fed3bce34f754267ac2b714e360b942a","value":" 446k/446k [00:00&lt;00:00, 437kB/s]"}},"0b5cf460b58d4c9293c464196ad5b3fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9277d91b90d84dc2b4836526473d206e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a0bf463ed9348608f2c00a8a042d044":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8aa91e88b6d4bc58897ed9539044870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d67df0c4c7fe4850907d41a333802861":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43445b90528c4fc8a38de0956a44ea2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fed3bce34f754267ac2b714e360b942a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e40e6bf6838475089a7041cbbebcaf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64fd663546b34c2a91491264846148f5","IPY_MODEL_40e29996fe9148d58b237ab478582d71","IPY_MODEL_3d96c70ad5c34db0bcfcae079c3748b1"],"layout":"IPY_MODEL_4a8fbb02800f46bb9af0f78f1207ed0d"}},"64fd663546b34c2a91491264846148f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_816df566528b482297e2163494203050","placeholder":"​","style":"IPY_MODEL_95d644b7add7438f93aa9c35d0e8929e","value":"Downloading: 100%"}},"40e29996fe9148d58b237ab478582d71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a866254e52ea424199acecbe45abfdc5","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4767ac04694e4aa2aa777c6a61a55d3e","value":665}},"3d96c70ad5c34db0bcfcae079c3748b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87b0fef684184f5e8d1aef0e74c05394","placeholder":"​","style":"IPY_MODEL_6fed732613c54d79a614c66016e5227f","value":" 665/665 [00:00&lt;00:00, 47.7kB/s]"}},"4a8fbb02800f46bb9af0f78f1207ed0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816df566528b482297e2163494203050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95d644b7add7438f93aa9c35d0e8929e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a866254e52ea424199acecbe45abfdc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4767ac04694e4aa2aa777c6a61a55d3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87b0fef684184f5e8d1aef0e74c05394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fed732613c54d79a614c66016e5227f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe638df73bde42aaad6f310ad7d29b95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12d1d5e522334fc1b784013b26662b69","IPY_MODEL_f927e217ea6d42c9bec8dcef6c61dd78","IPY_MODEL_acf11f0541744d8e9ac8cf25760b2ccc"],"layout":"IPY_MODEL_e18dffc3b2ec4716b1876943b7dc1d65"}},"12d1d5e522334fc1b784013b26662b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60c937d9d8ab42f7975dab50efdacb37","placeholder":"​","style":"IPY_MODEL_d066e100ffe54e8eb022814cf6e95fe1","value":"Downloading: 100%"}},"f927e217ea6d42c9bec8dcef6c61dd78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41f40efa5d4348088aaebf4dfa31db3f","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c68d37c228a41888fd1cf5d01f66a11","value":548118077}},"acf11f0541744d8e9ac8cf25760b2ccc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c65151d0e8ec4907863440d027a5eb41","placeholder":"​","style":"IPY_MODEL_f561f446726e4cbd8c89d19c08fdd298","value":" 523M/523M [00:05&lt;00:00, 74.2MB/s]"}},"e18dffc3b2ec4716b1876943b7dc1d65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60c937d9d8ab42f7975dab50efdacb37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d066e100ffe54e8eb022814cf6e95fe1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41f40efa5d4348088aaebf4dfa31db3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c68d37c228a41888fd1cf5d01f66a11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c65151d0e8ec4907863440d027a5eb41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f561f446726e4cbd8c89d19c08fdd298":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"Vp3XPuaTu9jl"},"source":["\n","# How to generate text: using different decoding methods for language generation with Transformers\n","\n","(based on https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"KxLvv6UaPa33"},"source":["### **Introduction**\n","\n","In recent years, there has been an increasing interest in open-ended language generation thanks to the rise of large transformer-based language models trained on millions of webpages, such as OpenAI's famous [GPT2 model](https://openai.com/blog/better-language-models/). The results on conditioned open-ended language generation are impressive, e.g. [GPT2 on unicorns](https://openai.com/blog/better-language-models/#samples), [XLNet](https://medium.com/@amanrusia/xlnet-speaks-comparison-to-gpt-2-ea1a4e9ba39e), [Controlled language with CTRL](https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/). Besides the improved transformer architecture and massive unsupervised training data, **better decoding methods** have also played an important role.\n","\n","This blog post gives a brief overview of different decoding strategies and more importantly shows how *you* can implement them with very little effort using the popular `transformers` library!\n","\n","All of the following functionalities can be used for **auto-regressive** language generation ([here](http://jalammar.github.io/illustrated-gpt2/) a refresher). In short, *auto-regressive* language generation is based on the assumption that the probability distribution of a word sequence can be decomposed into the product of conditional next word distributions:\n","$$ P(w_{1:T} | W_0 ) = \\prod_{t=1}^T P(w_{t} | w_{1: t-1}, W_0) \\text{ ,with }  w_{1: 0} = \\emptyset, $$\n","\n","and $W_0$ being the initial *context* word sequence. The length $T$ of the word sequence is usually determined *on-the-fly* and corresponds to the timestep $t=T$ the EOS token is generated from $P(w_{t} | w_{1: t-1}, W_{0})$.\n","\n","\n","Auto-regressive language generation is now available for `GPT2`, `XLNet`, `OpenAi-GPT`, `CTRL`, `TransfoXL`, `XLM`, `Bart`, `T5` in both PyTorch and Tensorflow >= 2.0!\n","\n","We will give a tour of the currently most prominent decoding methods, mainly *Greedy search*, *Beam search*, *Top-K sampling* and *Top-p sampling*.\n"]},{"cell_type":"markdown","metadata":{"id":"Si4GyYhOQMzi"},"source":["Let's quickly install transformers and load the model. ~~We will use GPT2 in Tensorflow 2.1 for demonstration, but the API is 1-to-1 the same for PyTorch.~~"]},{"cell_type":"code","metadata":{"id":"XbzZ_IVTtoQe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3721e4c-9f16-461c-87ad-6ed4a4356ee2","executionInfo":{"status":"ok","timestamp":1688488779672,"user_tz":-180,"elapsed":11566,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["#!pip install -q git+https://github.com/huggingface/transformers.git  # the bleeding edge version\n","#!pip install -q tensorflow==2.1\n","!pip install transformers==4.18.0"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.18.0\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.18.0)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (2.27.1)\n","Collecting sacremoses (from transformers==4.18.0)\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.18.0)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (3.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=f91f5d6300ce0e36a423feebb4aff42a1e73bbbe5e88d00926e7e2e7bffe66a3\n","  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"]}]},{"cell_type":"code","metadata":{"id":"eL5Ky2ESXOzz","executionInfo":{"status":"ok","timestamp":1688488783931,"user_tz":-180,"elapsed":4275,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["import torch"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ue2kOQhXTAMU","executionInfo":{"status":"ok","timestamp":1688488846640,"user_tz":-180,"elapsed":12947,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["6509bfe519d6437c9832e0acb4e53865","37c83fe1fc4d4aa8a97e1f37a0d16765","3974da0eae8e4ae985186633ca1fb23f","6c1fd3620c584d119870f0b36ee81a17","48bb5c2cf19247919223fbf88934c78f","573f75055bd54a4d9674786e25e6824a","1b970a5492ae4f78aec48438e1e84ab8","2d35e118f1c44626934b05e769cae075","3b0197c484094f15917d680c1775d8f6","4ff83615bf3a413eb635820b01e3aaee","8ba7c62679a745a18f0dee2ea1f423ca","a7930cc4f5e24745a23b73bbb7992627","432293249dd847f196332d15b336de0e","653af791977a49d58b4cf1215f2607c5","8b7e486e45f842d7bfa5ef812447209a","0b5cf460b58d4c9293c464196ad5b3fd","9277d91b90d84dc2b4836526473d206e","4a0bf463ed9348608f2c00a8a042d044","d8aa91e88b6d4bc58897ed9539044870","d67df0c4c7fe4850907d41a333802861","43445b90528c4fc8a38de0956a44ea2a","fed3bce34f754267ac2b714e360b942a","2e40e6bf6838475089a7041cbbebcaf9","64fd663546b34c2a91491264846148f5","40e29996fe9148d58b237ab478582d71","3d96c70ad5c34db0bcfcae079c3748b1","4a8fbb02800f46bb9af0f78f1207ed0d","816df566528b482297e2163494203050","95d644b7add7438f93aa9c35d0e8929e","a866254e52ea424199acecbe45abfdc5","4767ac04694e4aa2aa777c6a61a55d3e","87b0fef684184f5e8d1aef0e74c05394","6fed732613c54d79a614c66016e5227f","fe638df73bde42aaad6f310ad7d29b95","12d1d5e522334fc1b784013b26662b69","f927e217ea6d42c9bec8dcef6c61dd78","acf11f0541744d8e9ac8cf25760b2ccc","e18dffc3b2ec4716b1876943b7dc1d65","60c937d9d8ab42f7975dab50efdacb37","d066e100ffe54e8eb022814cf6e95fe1","41f40efa5d4348088aaebf4dfa31db3f","3c68d37c228a41888fd1cf5d01f66a11","c65151d0e8ec4907863440d027a5eb41","f561f446726e4cbd8c89d19c08fdd298"]},"outputId":"29b9c746-e176-4c60-e102-9bc9f4fac406"},"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# add the EOS token as PAD token to avoid warnings\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6509bfe519d6437c9832e0acb4e53865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7930cc4f5e24745a23b73bbb7992627"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e40e6bf6838475089a7041cbbebcaf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe638df73bde42aaad6f310ad7d29b95"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"a8Y7cgu9ohXP"},"source":["### **Greedy Search**\n","\n","Greedy search simply selects the word with the highest probability as its next word: $w_t = argmax_{w}P(w | w_{1:t-1})$ at each timestep $t$. The following sketch shows greedy search.\n","\n","![Greedy Search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/greedy_search.png)\n","\n","Starting from the word $\\text{\"The\"}$, the algorithm\n","greedily chooses the next word of highest probability $\\text{\"nice\"}$ and so on, so that the final generated word sequence is $\\text{\"The\", \"nice\", \"woman\"}$ having an overall probability of $0.5 \\times 0.4 = 0.2$.\n","\n","In the following we will generate word sequences using GPT2 on the context $(\\text{\"I\", \"enjoy\", \"walking\", \"with\", \"my\", \"cute\", \"dog\"})$. Let's see how greedy search can be used in `transformers` as follows:"]},{"cell_type":"code","metadata":{"id":"OWLd_J6lXz_t","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc5a85fd-ff11-4308-cf7e-d6c1e5cbb615","executionInfo":{"status":"ok","timestamp":1688488883147,"user_tz":-180,"elapsed":5896,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# encode context the generation is conditioned on\n","input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","greedy_output = model.generate(input_ids, max_length=50)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n","\n","I'm not sure if I'll\n"]}]},{"cell_type":"markdown","metadata":{"id":"BBn1ePmJvhrl"},"source":["Alright! We have generated our first short text with GPT2 😊. The generated words following the context are reasonable, but the model quickly starts repeating itself! This is a very common problem in language generation in general and seems to be even more so in greedy and beam search - check out [Vijayakumar et al., 2016](https://arxiv.org/abs/1610.02424) and [Shao et al., 2017](https://arxiv.org/abs/1701.03185).\n","\n","The major drawback of greedy search though is that it misses high probability words hidden behind a low probability word as can be seen in our sketch above:\n","\n","The word $\\text{\"has\"}$ with its high conditional probability of $0.9$ is hidden behind the word $\\text{\"dog\"}$, which has only the second-highest conditional probability, so that greedy search misses the word sequence $\\text{\"The\"}, \\text{\"dog\"}, \\text{\"has\"}$.\n","\n","Thankfully, we have beam search to alleviate this problem!\n"]},{"cell_type":"markdown","metadata":{"id":"g8DnXZ1WiuNd"},"source":["### **Beam search**\n","\n","Beam search reduces the risk of missing hidden high probability word sequences by keeping the most likely `num_beams` of hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability. Let's illustrate with `num_beams=2`:\n","\n","![Beam search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/beam_search.png)\n","\n","At time step $1$, besides the most likely hypothesis $\\text{\"The\", \"woman\"}$, beam search also keeps track of the second most likely one $\\text{\"The\", \"dog\"}$. At time step $2$, beam search finds that the word sequence $\\text{\"The\", \"dog\", \"has\"}$ has with $0.36$ a higher probability than $\\text{\"The\", \"nice\", \"woman\"}$, which has $0.2$. Great, it has found the most likely word sequence in our toy example!\n","\n","Beam search will always find an output sequence with higher probability than greedy search, but is not guaranteed to find the most likely output.\n","\n","Let's see how beam search can be used in `transformers`. We set `num_beams > 1` and `early_stopping=True` so that generation is finished when all beam hypotheses reached the EOS token."]},{"cell_type":"code","metadata":{"id":"R1R5kx30Ynej","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d879d373-2950-45a2-d45f-6f661ed9f581","executionInfo":{"status":"ok","timestamp":1688488956070,"user_tz":-180,"elapsed":4951,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# activate beam search and early_stopping\n","beam_output = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    early_stopping=True\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll\n"]}]},{"cell_type":"markdown","metadata":{"id":"AZ6xs-KLi9jT"},"source":["While the result is arguably more fluent, the output still includes repetitions of the same word sequences.  \n","A simple remedy is to introduce *n-grams* (*a.k.a* word sequences of $n$ words) penalties as introduced by [Paulus et al. (2017)](https://arxiv.org/abs/1705.04304) and [Klein et al. (2017)](https://arxiv.org/abs/1701.02810). The most common *n-grams* penalty makes sure that no *n-gram* appears twice by manually setting the probability of next words that could create an already seen *n-gram* to $0$.\n","\n","Let's try it out by setting `no_repeat_ngram_size=2` so that no *2-gram* appears twice:"]},{"cell_type":"code","metadata":{"id":"jy3iVJgfnkMi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ee417f5-0fbb-497f-c87d-75d4bf5ee2f9","executionInfo":{"status":"ok","timestamp":1688489027012,"user_tz":-180,"elapsed":4842,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set no_repeat_ngram_size to 2\n","beam_output = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    early_stopping=True\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a break\n"]}]},{"cell_type":"markdown","metadata":{"id":"nxsksOGDpmA0"},"source":["Nice, that looks much better! We can see that the repetition does not appear anymore. Nevertheless, *n-gram* penalties have to be used with care. An article generated about the city *New York* should not use a *2-gram* penalty or otherwise, the name of the city would only appear once in the whole text!\n","\n","Another important feature about beam search is that we can compare the top beams after generation and choose the generated beam that fits our purpose best.\n","\n","In `transformers`, we simply set the parameter `num_return_sequences` to the number of highest scoring beams that should be returned. Make sure though that `num_return_sequences <= num_beams`!"]},{"cell_type":"code","metadata":{"id":"5ClO3VphqGp6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eedb572b-3766-4d3d-c0bf-9fc1c32b0cd5","executionInfo":{"status":"ok","timestamp":1688489087884,"user_tz":-180,"elapsed":3973,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set return_num_sequences > 1\n","beam_outputs = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True\n",")\n","\n","# now we have 3 output sequences\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a break\n","\n","1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to get back to\n","\n","2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a break\n","\n","3: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to get back to\n","\n","4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a step\n","\n"]}]},{"cell_type":"markdown","source":["As can be seen, the five beam hypotheses are only marginally different to each other - which should not be too surprising when using only 5 beams."],"metadata":{"id":"HTAtnY_cek9m"}},{"cell_type":"markdown","source":["## Diverse beam search"],"metadata":{"id":"_FTLZ5ajedK3"}},{"cell_type":"code","source":["# set return_num_sequences > 1\n","beam_outputs = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True,\n","    num_beam_groups=5, # this must be a divisor of num_beams\n","    diversity_penalty=1.0,\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPa_ZSBheluH","outputId":"6a0bbe0c-4f4b-4db4-a7b3-e9d6464d4eb4","executionInfo":{"status":"ok","timestamp":1688489306532,"user_tz":-180,"elapsed":5709,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation_beam_search.py:196: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I'm a big fan of the \"I love you\" sign, and I love the fact that it's a\n","\n","1: I enjoy walking with my cute dog and I'm always looking for a place to go. I've been to a lot of places and it's always been a great experience.\n","\n","I've always wanted to be a veterinarian. My parents were both\n","\n","2: I enjoy walking with my cute dog. I love to play with her and she loves to be with me. She loves being with us and I'm happy to have her around.\n","\n","I love my dog and her love for me and my family\n","\n","3: I enjoy walking with my cute dog. He's a great dog and I love to play with him. I'm a big fan of his.\n","\n","I love my dog, and he's my best friend. We're both very happy and happy\n","\n","4: I enjoy walking with my cute dog, and I love to play with her. I'm also a big fan of the new \"Pony\" series, which is a little bit more of a \"pony-friendly\" version of \"The Simpsons\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HhLKyfdbsjXc"},"source":["In open-ended generation, a couple of reasons have recently been brought forward why beam search might not be the best possible option:\n","\n","- Beam search can work very well in tasks where the length of the desired generation is more or less predictable as in machine translation or summarization - see [Murray et al. (2018)](https://arxiv.org/abs/1808.10006) and [Yang et al. (2018)](https://arxiv.org/abs/1808.09582). But this is not the case for open-ended generation where the desired output length can vary greatly, e.g. dialog and story generation.\n","\n","- We have seen that beam search heavily suffers from repetitive generation. This is especially hard to control with *n-gram*- or other penalties in story generation since finding a good trade-off between forced \"no-repetition\" and repeating cycles of identical *n-grams* requires a lot of finetuning.\n","\n","- As argued in [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751), high quality human language does not follow a distribution of high probability next words. In other words, as humans, we want generated text to surprise us and not to be boring/predictable. The authors show this nicely by plotting the probability, a model would give to human text vs. what beam search does.\n","\n","![alt text](https://blog.fastforwardlabs.com/images/2019/05/Screen_Shot_2019_05_08_at_3_06_36_PM-1557342561886.png)\n","\n","\n","So let's stop being boring and introduce some randomness 🤪."]},{"cell_type":"markdown","metadata":{"id":"XbbIyK84wHq6"},"source":["## **Sampling**\n","\n","In its most basic form, sampling means randomly picking the next word $w_t$ according to its conditional probability distribution:\n","\n","$$w_t \\sim P(w|w_{1:t-1})$$\n","\n","Taking the example from above, the following graphic visualizes language generation when sampling.\n","\n","![vanilla_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/sampling_search.png)\n","\n","It becomes obvious that language generation using sampling is not *deterministic* anymore. The word\n","$\\text{\"car\"}$ is sampled from the conditioned probability distribution $P(w | \\text{\"The\"})$, followed by sampling $\\text{\"drives\"}$ from $P(w | \\text{\"The\"}, \\text{\"car\"})$.\n","\n","In `transformers`, we set `do_sample=True` and deactivate *Top-K* sampling (more on this later) via `top_k=0`. In the following, we will fix `random_seed=0` for illustration purposes. Feel free to change the `random_seed` to play around with the model.\n"]},{"cell_type":"code","metadata":{"id":"aRAz4D-Ks0_4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e21683ec-0ba8-4189-8003-c61b5a611933","executionInfo":{"status":"ok","timestamp":1688489482322,"user_tz":-180,"elapsed":3150,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","torch.random.manual_seed(1)\n","\n","# activate sampling and deactivate top_k by setting top_k sampling to 0\n","sample_output = model.generate(\n","    input_ids,\n","    do_sample=True,\n","    max_length=50,\n","    top_k=0\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog when there are other people around, though.\n","\n","No, ladies, enjoying your dog and publicly embracing her is not my thing. It doesn't even bother me, woman-like. I'm happy you think\n"]}]},{"cell_type":"markdown","metadata":{"id":"mQHuo911wfT-"},"source":["Interesting! The text seems alright - but when taking a closer look, it is not very coherent. the *3-grams* *new hand sense* and *local batte harness* are very weird and don't sound like they were written by a human. That is the big problem when sampling word sequences: The models often generate incoherent gibberish, *cf.* [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751).\n","\n","A trick is to make the distribution $P(w|w_{1:t-1})$ sharper (increasing the likelihood of high probability words and decreasing the likelihood of low probability words) by lowering the so-called `temperature` of the [softmax](https://en.wikipedia.org/wiki/Softmax_function#Smooth_arg_max).\n","\n","$q = \\frac{exp(z_i / T)}{\\sum_j exp(z_j / T)}$\n","\n","An illustration of applying temperature to our example from above could look as follows.\n","\n","![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/sampling_search_with_temp.png?raw=true)\n","\n","The conditional next word distribution of step $t=1$ becomes much sharper leaving almost no chance for word $\\text{\"car\"}$ to be selected.\n","\n","\n","Let's see how we can cool down the distribution in the library by setting `temperature=0.7`:"]},{"cell_type":"code","metadata":{"id":"WgJredc-0j0Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab292c87-80f0-4460-97eb-1d253deb367b","executionInfo":{"status":"ok","timestamp":1688489533524,"user_tz":-180,"elapsed":3121,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","torch.random.manual_seed(0)\n","\n","# use temperature to decrease the sensitivity to low probability candidates\n","sample_output = model.generate(\n","    input_ids,\n","    do_sample=True,\n","    max_length=50,\n","    top_k=0,\n","    temperature=0.7\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog,\" she said. \"He has a lot of aggression and eventually gets aggressive and starts barking at you. So I just make sure I'm smart enough to find a safe place to stop and look for him. It\n"]}]},{"cell_type":"markdown","source":["## !!! SEMINAR QUIZ:\n","Provide examples with regular samplings with 0.0007 and 4.6 temperature"],"metadata":{"id":"TatoLUMkA9dA"}},{"cell_type":"markdown","metadata":{"id":"kzGuu24hZZnq"},"source":["OK. There are less weird n-grams and the output is a bit more coherent now! While applying temperature can make a distribution less random, in its limit, when setting `temperature` $ \\to 0$, temperature scaled sampling becomes equal to greedy decoding and will suffer from the same problems as before.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"binNTroyzQBu"},"source":["## **Top-K Sampling**\n","\n","[Fan et. al (2018)](https://arxiv.org/pdf/1805.04833.pdf) introduced a simple, but very powerful sampling scheme, called ***Top-K*** sampling. In *Top-K* sampling, the *K* most likely next words are filtered and the probability mass is redistributed among only those *K* next words.\n","GPT2 adopted this sampling scheme, which was one of the reasons for its success in story generation.\n","\n","We extend the range of words used for both sampling steps in the example above from 3 words to 10 words to better illustrate *Top-K* sampling.\n","\n","![top_k_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/top_k_sampling.png)\n","\n","Having set $K = 6$, in both sampling steps we limit our sampling pool to 6 words. While the 6 most likely words, defined as $V_{\\text{top-K}}$ encompass only *ca.* two-thirds of the whole probability mass in the first step, it includes almost all of the probability mass in the second step. Nevertheless, we see that it successfully eliminates the rather weird candidates $\\text{\"not\", \"the\", \"small\", \"told\"}$\n","in the second sampling step.\n","\n","\n","Let's see how *Top-K* can be used in the library by setting `top_k=50`:"]},{"cell_type":"code","metadata":{"id":"HBtDOdD0wx3l","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71ac399d-976e-4704-e9a9-4e0e360e6a6a","executionInfo":{"status":"ok","timestamp":1688489686881,"user_tz":-180,"elapsed":4478,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","torch.random.manual_seed(0)\n","\n","# set top_k to 50\n","sample_output = model.generate(\n","    input_ids,\n","    do_sample=True,\n","    max_length=100,\n","    top_k=50\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog,\" she says. \"You get a lot of love and support out of it. It has helped me to be open and see why and what I have to do to be successful.\"\n","\n","I'd say the positive result over the last year has been an increase of activity to my home. It's gotten over to me where I started to take into account what my dogs have to say. When I was little, my two dogs got their start. We are\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y77H5m4ZmhEX"},"source":["Not bad at all! The text is arguably the most *human-sounding* text so far.\n","One concern though with *Top-K* sampling is that it does not dynamically adapt the number of words that are filtered from the next word probability distribution $P(w|w_{1:t-1})$.\n","This can be problematic as some words might be sampled from a very sharp distribution (distribution on the right in the graph above), whereas others from a much more flat distribution (distribution on the left in the graph above).\n","\n","In step $t=1$, *Top-K* eliminates the possibility to\n","sample $\\text{\"people\", \"big\", \"house\", \"cat\"}$, which seem like reasonable candidates. On the other hand, in step $t=2$ the method includes the arguably ill-fitted words $\\text{\"down\", \"a\"}$ in the sample pool of words. Thus, limiting the sample pool to a fixed size *K* could endanger the model to produce gibberish for sharp distributions and limit the model's creativity for flat distribution.\n","This intuition led [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751) to create ***Top-p***- or ***nucleus***-sampling.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ki9LAaexzV3H"},"source":["## **Top-p (nucleus) sampling**\n","\n","Instead of sampling only from the most likely *K* words, in *Top-p* sampling chooses from the smallest possible set of words whose cumulative probability exceeds the probability *p*. The probability mass is then redistributed among this set of words. This way, the size of the set of words (*a.k.a* the number of words in the set) can dynamically increase and decrease according to the next word's probability distribution. Ok, that was very wordy, let's visualize.\n","\n","![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/top_p_sampling.png?raw=true)\n","\n","Having set $p=0.92$, *Top-p* sampling picks the *minimum* number of words to exceed together $p=92\\%$ of the probability mass, defined as $V_{\\text{top-p}}$. In the first example, this included the 9 most likely words, whereas it only has to pick the top 3 words in the second example to exceed 92%. Quite simple actually! It can be seen that it keeps a wide range of words where the next word is arguably less predictable, *e.g.* $P(w | \\text{\"The\"})$, and only a few words when the next word seems more predictable, *e.g.* $P(w | \\text{\"The\", \"car\"})$.\n","\n","Alright, time to check it out in `transformers`!\n","We activate *Top-p* sampling by setting `0 < top_p < 1`:"]},{"cell_type":"code","metadata":{"id":"EvwIc7YAx77F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"66522832-c79b-409b-d950-6062eded1d2a","executionInfo":{"status":"ok","timestamp":1688489722076,"user_tz":-180,"elapsed":3121,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","torch.random.manual_seed(3)\n","\n","# deactivate top_k sampling and sample only from 92% most likely words\n","sample_output = model.generate(\n","    input_ids,\n","    do_sample=True,\n","    max_length=50,\n","    top_p=0.92,\n","    top_k=0\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog and traveling.\" The owner\n","\n","Jillian said, \"Our pet started showing us signs of anxiety and suicide last week and he's now all swollen. But then he started showing signs of freedom for a change.\"\n"]}]},{"cell_type":"markdown","metadata":{"id":"tn-8gLaR4lat"},"source":["Great, that sounds like it could have been written by a human. Well, maybe not quite yet.\n","\n","While in theory, *Top-p* seems more elegant than *Top-K*, both methods work  well in practice. *Top-p* can also be used in combination with *Top-K*, which can avoid very low ranked words while allowing for some dynamic selection.\n","\n","Finally, to get multiple independently sampled outputs, we can *again* set the parameter `num_return_sequences > 1`:"]},{"cell_type":"code","metadata":{"id":"3kY8P9VG8Gi9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"73bd600d-b52d-45c6-fd67-276251ae4eaa","executionInfo":{"status":"ok","timestamp":1688489804979,"user_tz":-180,"elapsed":5305,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","torch.random.manual_seed(0)\n","\n","# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n","sample_outputs = model.generate(\n","    input_ids,\n","    do_sample=True,\n","    max_length=50,\n","    top_k=50,\n","    top_p=0.95,\n","    num_return_sequences=3\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog,\" she says. \"You get a lot of love and support out of it. It has helped me to be open and see what's really cool. I'm happy to see people are supporting my cause and just\n","1: I enjoy walking with my cute dog. I would also like to see a new feature for our cats, the cute bear, that is called 'Spend Your Sunday, Beating Dogs, by Feeding Dogs'.\n","\n","Please see our page for\n","2: I enjoy walking with my cute dog, but I would definitely encourage anyone that will play around with your dog's ears to use a bit of patience and patience.\n","\n","The dog's ears should be removed right away. After they are gone from the\n"]}]},{"cell_type":"markdown","metadata":{"id":"-vRPfMl88rk0"},"source":["Cool, now you should have all the tools to let your model write your stories with `transformers`!"]},{"cell_type":"markdown","source":["## Constrained generation"],"metadata":{"id":"oZpN3QTweA0J"}},{"cell_type":"markdown","source":["For better readability, we will use end-of-line as the EOS token, instead of just always generating 50 tokens."],"metadata":{"id":"QYsyCeBUJAVy"}},{"cell_type":"code","source":["END_OF_LINE = tokenizer('\\n').input_ids[0]\n","print(END_OF_LINE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUK1B7WsJCpM","outputId":"fc5196f5-7fce-4874-a1db-2a38f9a679d9","executionInfo":{"status":"ok","timestamp":1688489849770,"user_tz":-180,"elapsed":1090,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["198\n"]}]},{"cell_type":"markdown","source":["The baseline beam search produces very similar sentences; all of them contain \"not sure\" or \"don't think\"."],"metadata":{"id":"yBATNPrxJwPB"}},{"cell_type":"code","source":["beam_outputs = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True,\n","    eos_token_id=END_OF_LINE,\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgsoFsmOI9Pe","outputId":"432812ac-1455-4821-ac6f-c44ba7faaecc","executionInfo":{"status":"ok","timestamp":1688489868106,"user_tz":-180,"elapsed":3661,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n","\n","2: I enjoy walking with my cute dog, but I don't think I'll ever be able to walk with her again.\n","\n","3: I enjoy walking with my cute dog, but I don't think I'll ever be able to walk with him again.\n","\n","4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again. I don't know what to do.\n","\n"]}]},{"cell_type":"markdown","source":["What would happen if we forbid the model to use these phrases?"],"metadata":{"id":"xj3S7FkgI9lv"}},{"cell_type":"code","source":["beam_outputs = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True,\n","    eos_token_id=END_OF_LINE,\n","    bad_words_ids=tokenizer(['sure', 'think', 'thundersnatch'], add_prefix_space=True)['input_ids'],\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-nlHOYzJ_bP","outputId":"73e375e3-840e-485b-8ebd-f367c1ed0f38","executionInfo":{"status":"ok","timestamp":1688489897570,"user_tz":-180,"elapsed":2978,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog, but I don't like to walk alone.\n","\n","1: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet.\n","\n","2: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet to get a new dog.\n","\n","3: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet to get a new one.\n","\n","4: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet to see if my dog is sick.\n","\n"]}]},{"cell_type":"markdown","source":["Why `add_prefix space`? Because the BPE tokenization used by GPT prepends the space to the next word, and this changes the token:"],"metadata":{"id":"oqjdJiyVMIAm"}},{"cell_type":"code","source":["tokenizer(['sure', ' sure', ' I am not sure'])['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ng2xaRxaMSXS","outputId":"5d9cc6d3-d8e4-4b53-b6e7-71bb228b211c","executionInfo":{"status":"ok","timestamp":1688489932758,"user_tz":-180,"elapsed":972,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[19532], [1654], [314, 716, 407, 1654]]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["tokenizer(['sure', ' sure', ' I am not sure'], add_prefix_space=True)['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahj-eZ-XCBMt","executionInfo":{"status":"ok","timestamp":1688489951692,"user_tz":-180,"elapsed":435,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}},"outputId":"bc7da36a-5c43-41f1-c839-56f8147544f7"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1654], [220, 1654], [220, 314, 716, 407, 1654]]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["We can see that the meaning of these texts has changed a lot – but in some unpredictable way.\n","\n","Can we force the model to write a text involving cats?"],"metadata":{"id":"J16fr3qDKOz3"}},{"cell_type":"code","source":["beam_outputs = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True,\n","    eos_token_id=END_OF_LINE,\n","    bad_words_ids=tokenizer(['sure', 'think'], add_prefix_space=True)['input_ids'],\n","    force_words_ids=[tokenizer(['cat'], add_prefix_space=True, add_special_tokens=False).input_ids],\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsOq5q5PKspB","outputId":"440f1cae-e2d3-4590-d250-c437afbd7125","executionInfo":{"status":"ok","timestamp":1688489968300,"user_tz":-180,"elapsed":3621,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog, but I'm not a cat person.\n","\n","1: I enjoy walking with my cute dog, but I'm not a cat person.\"\n","\n","2: I enjoy walking with my cute dog, but I'm not a cat person, so I don't know what to do with him.\"\n","\n","3: I enjoy walking with my cute dog, but I'm not a cat person, so I don't know what to do with him. He's my best friend.\"\n","\n","4: I enjoy walking with my cute dog, but I'm not a cat person, so I don't know what to do with him. He's my best friend.\n","\n"]}]},{"cell_type":"markdown","source":["A clarification: **force_words_ids** is a list of constraints. Each constraint is a list of expressions, such that at least one expression should be included into the generated text. And each expression is just a list of tokens.\n","\n","See the discussion in [the HF pull request](https://github.com/huggingface/transformers/issues/14081), or read the paper \"[Guided Generation of Cause and Effect](https://www.ijcai.org/proceedings/2020/0502.pdf)\" by Li et al, where the algorithm was proposed.  \n","\n","To evaluate the power of these constraints, let us force the model to include a mouse (or even many mice) into the text. We can also relax the \"cat\" constraint by allowing the words \"cats\", \"kitten\" or \"feline\" instead."],"metadata":{"id":"40lA3WrhK726"}},{"cell_type":"code","source":["beam_outputs = model.generate(\n","    input_ids,\n","    max_length=50,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True,\n","    eos_token_id=END_OF_LINE,\n","    bad_words_ids=tokenizer(['sure', 'think'], add_prefix_space=True)['input_ids'],\n","    force_words_ids = [\n","        tokenizer(['cat', 'cats', 'kitten', 'feline', 'Cat', 'Cats'], add_prefix_space=True, add_special_tokens=False).input_ids,\n","        tokenizer(['mouse', 'mice'], add_prefix_space=True, add_special_tokens=False).input_ids,\n","    ],\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXvaYLFFLQWT","outputId":"c3631aa9-6bcf-4acd-f37c-0945568bdb51","executionInfo":{"status":"ok","timestamp":1688490014303,"user_tz":-180,"elapsed":3102,"user":{"displayName":"Viktoriia Chekalina","userId":"01961971800886548445"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog. I love feline companionship and I like mice.\"\n","\n","1: I enjoy walking with my cute dog. I love feline companionship and I like mice.\n","\n","2: I enjoy walking with my cute dog. I love feline companionship and I like mice and cats.\n","\n","3: I enjoy walking with my cute dog. I love feline companionship and I like to mouse my way around the house.\n","\n","4: I enjoy walking with my cute dog. I love feline companionship and I like to mouse my way through the world.\n","\n"]}]},{"cell_type":"markdown","source":["The texts satisfy the constraints and look fluent. Still, the model has somehow fooled us: it used the verb \"to mouse\" in its secondary sense, instead of referring to animals."],"metadata":{"id":"bkkfGBd9L6uL"}},{"cell_type":"markdown","metadata":{"id":"NsWd7e98Vcs3"},"source":["## **Conclusion**\n","\n","As *ad-hoc* decoding methods, *top-p* and *top-K* sampling seem to produce more fluent text than traditional *greedy* - and *beam* search on open-ended language generation.\n","Recently, there has been more evidence though that the apparent flaws of *greedy* and *beam* search - mainly generating repetitive word sequences - are  caused by the model (especially the way the model is trained), rather than the decoding method, *cf.* [Welleck et al. (2019)](https://arxiv.org/pdf/1908.04319.pdf). Also, as demonstrated in [Welleck et al. (2020)](https://arxiv.org/abs/2002.02492), it looks as *top-K* and *top-p* sampling also suffer from generating repetitive word sequences.\n","\n","In [Welleck et al. (2019)](https://arxiv.org/pdf/1908.04319.pdf), the authors show that according to human evaluations, *beam* search can generate more fluent text than *Top-p* sampling, when adapting the model's training objective.\n","\n","Open-ended language generation is a rapidly evolving field of research and as it is often the case there is no one-size-fits-all method here, so one has to see what works best in one's specific use case.\n","\n","Good thing, that *you* can try out all the different decoding methods in `transfomers` 🤗.\n","\n","That was a short introduction on how to use different decoding methods in `transformers` and recent trends in open-ended language generation.\n","\n","Feedback and questions are very welcome on the [Github repository](https://github.com/huggingface/transformers).\n","\n","For more fun generating stories, please take a look at [Writing with Transformers](https://transformer.huggingface.co).\n","\n","Thanks to everybody, who has contributed to the blog post: Alexander Rush, Julien Chaumand, Thomas Wolf, Victor Sanh, Sam Shleifer, Clément Delangue, Yacine Jernite, Oliver Åstrand and John de Wasseige.\n"]},{"cell_type":"markdown","metadata":{"id":"w4CYi91h11yd"},"source":["## **Appendix**\n","\n","There are a couple of additional parameters for the `generate` method that were not mentioned above. We will explain them here briefly!\n","\n","- `min_length` can be used to force the model to not produce an EOS token (= not finish the sentence) before `min_length` is reached. This is used quite frequently in summarization, but can be useful in general if the user wants to have longer outputs.\n","- `repetition_penalty` can be used to penalize words that were already generated or belong to the context. It was first introduced by [Kesker et al. (2019)](https://arxiv.org/abs/1909.05858) and is also used in the training objective in [Welleck et al. (2019)](https://arxiv.org/pdf/1908.04319.pdf). It can be quite effective at preventing repetitions, but seems to be very sensitive to different models and use cases, *e.g.* see this [discussion](https://github.com/huggingface/transformers/pull/2303) on Github.\n","\n","- `attention_mask` can be used to mask padded tokens\n","- `pad_token_id`, `bos_token_id`, `eos_token_id`: If the model does not have those tokens by default, the user can manually choose other token ids to represent them.\n","\n","For more information please also look into the `generate` function [docstring](https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.TFPreTrainedModel.generate)."]},{"cell_type":"markdown","source":["# Chatbots"],"metadata":{"id":"dbtRbQccMc3e"}},{"cell_type":"code","source":["def respond_to_dialog(texts):\n","    prefix = '\\nx:'\n","    for i, t in enumerate(texts):\n","        prefix += t\n","        prefix += '\\nx:' if i % 2 == 1 else '\\ny:'\n","    tokens = tokenizer(prefix, return_tensors='pt').to(model.device)\n","    end_token_id = tokenizer.encode('\\n')[0]\n","    size = tokens['input_ids'].shape[1]\n","    output = model.generate(\n","        **tokens,\n","        eos_token_id=end_token_id,\n","        do_sample=True,\n","        max_length=size + 32,\n","        repetition_penalty=3.2,\n","        temperature=1,\n","        num_beams=1,\n","        length_penalty=0.01,\n","        pad_token_id=tokenizer.eos_token_id,\n","    )\n","    decoded = tokenizer.decode(output[0])\n","    result = decoded[len(prefix):]\n","    return result.strip()"],"metadata":{"id":"JbRkSUkVMeHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed = input('Start the dialog by saying anything to the bot:\\n')\n","history = [seed]\n","while True:\n","    result = respond_to_dialog(history[-10:])\n","    next_sentence = input(result + '\\n')\n","    history.append(result)\n","    history.append(next_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"Bc1_wcTrMpen","outputId":"d50704e4-b892-472a-964b-504e1b457aec","executionInfo":{"status":"error","timestamp":1670344903724,"user_tz":-60,"elapsed":70931,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Start the dialog by saying anything to the bot:\n","hi! how are you?\n","I was just about to get home, when someone came. It's kinda like she asked me this question because it said 'you know what?! She thought her\n","Where do you live?\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-97b546995bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrespond_to_dialog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnext_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":["!pip install -q pytelegrambotapi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hzkMYcrNNUs","outputId":"9a788df1-72e9-484a-87c1-6268b08998d2","executionInfo":{"status":"ok","timestamp":1670344917145,"user_tz":-60,"elapsed":5652,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 43.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30 kB 52.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 40 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 51 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 71 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 92 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 102 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 112 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 122 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 133 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 143 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 153 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 163 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 174 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 184 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 194 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 204 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 215 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 217 kB 29.6 MB/s \n","\u001b[?25h  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import telebot\n","\n","bot = telebot.TeleBot(\"5817745470:AAHMf1dwPKh94fzy4aNVuzUmGVyAxE_MW-o\", parse_mode=None)"],"metadata":{"id":"bO5G2nykOjjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@bot.message_handler(commands=['start', 'help'])\n","def send_welcome(message):\n","\tbot.reply_to(message, \"Howdy, how are you doing?\")\n","history = [\"Howdy, how are you doing?\"]"],"metadata":{"id":"paz50rBvPEk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@bot.message_handler(func=lambda m: True)\n","def echo_all(message):\n","    history.append(message.text)\n","    result = respond_to_dialog(history[-10:])\n","    history.append(result)\n","    bot.reply_to(message, result)"],"metadata":{"id":"-dPlgVuKPISV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bot.infinity_polling()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnPqhJOfPqA1","outputId":"91fd14df-4210-4a65-84ae-8308832e4793","executionInfo":{"status":"ok","timestamp":1670345108081,"user_tz":-60,"elapsed":67524,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-12-06 16:45:07,458 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n","ERROR:TeleBot:Infinity polling: polling exited\n","2022-12-06 16:45:07,461 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n","ERROR:TeleBot:Break infinity polling\n"]}]},{"cell_type":"markdown","source":["# Controlling generation\n"],"metadata":{"id":"_KcFC7yNd8Rh"}},{"cell_type":"markdown","source":["Let's try to solve a seq2seq task with a GPT model: text detoxification (i.e. paraphrasing toxic text in less toxic words).\n","\n","We will use the dataset from https://github.com/skoltech-nlp/parallel_detoxification_dataset"],"metadata":{"id":"pDf9mSTaSNTo"}},{"cell_type":"code","source":["!pip install transformers sacrebleu -q"],"metadata":{"id":"hM6oKS69WQ8C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b7b95a4-fd5d-4f17-982d-df5dd007e569","executionInfo":{"status":"ok","timestamp":1670345170980,"user_tz":-60,"elapsed":5691,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20 kB 39.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30 kB 49.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 51 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 61 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 71 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 81 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 92 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 102 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 112 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 118 kB 32.6 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# add the EOS token as PAD token to avoid warnings\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).cuda()"],"metadata":{"id":"DXMnC79EVgS5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's use end of line as EOS token."],"metadata":{"id":"IkIwSPvKWYhu"}},{"cell_type":"code","source":["END_OF_LINE = tokenizer('\\n').input_ids[0]\n","print(END_OF_LINE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63KBw1OpY8L7","outputId":"d07daf95-4e4e-4186-8f61-44b75b29cff8","executionInfo":{"status":"ok","timestamp":1670345229996,"user_tz":-60,"elapsed":585,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["198\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_csv('https://raw.githubusercontent.com/skoltech-nlp/parallel_detoxification_dataset/main/parallel_detoxification_dataset_small.tsv', sep='\\t')"],"metadata":{"id":"d5XpM9PvTwrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.options.display.max_colwidth = 300\n","data.sample(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"VEZy86OnT3Us","outputId":"b1e7fd62-0e95-4db5-ab91-c01b97d91a71","executionInfo":{"status":"ok","timestamp":1670345241864,"user_tz":-60,"elapsed":1132,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                         toxic_comment  \\\n","1824                                                                       so pelosi is scum as well .   \n","857   holy shit , just finished the season and it is so good but so * dark * , especially at the end .   \n","1656                           possibly because white teachers are biased against the black students ?   \n","\n","                                                          civil_comment  \n","1824                               So pelosi is wrongful person as well  \n","857                  This serie is great although it have a dark ending  \n","1656  may be cause white teacher are sloping against the black students  "],"text/html":["\n","  <div id=\"df-0fe12b61-3baf-4244-a815-48f901704471\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic_comment</th>\n","      <th>civil_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1824</th>\n","      <td>so pelosi is scum as well .</td>\n","      <td>So pelosi is wrongful person as well</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>holy shit , just finished the season and it is so good but so * dark * , especially at the end .</td>\n","      <td>This serie is great although it have a dark ending</td>\n","    </tr>\n","    <tr>\n","      <th>1656</th>\n","      <td>possibly because white teachers are biased against the black students ?</td>\n","      <td>may be cause white teacher are sloping against the black students</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fe12b61-3baf-4244-a815-48f901704471')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0fe12b61-3baf-4244-a815-48f901704471 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0fe12b61-3baf-4244-a815-48f901704471');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["data.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170},"id":"n8ZXDKloT-7U","outputId":"c94109ca-b7b6-4867-a0c6-404e6cea5637","executionInfo":{"status":"ok","timestamp":1670345252299,"user_tz":-60,"elapsed":588,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        toxic_comment  \\\n","count                                            2778   \n","unique                                           1108   \n","top     yurope is fucking awesome that way , yeah s .   \n","freq                                                4   \n","\n","                                                                       civil_comment  \n","count                                                                           2778  \n","unique                                                                          2778  \n","top     or the loud  one - thousand ton beast roaring towards you howling its horn .  \n","freq                                                                               1  "],"text/html":["\n","  <div id=\"df-d9f4e950-2241-4ff0-9f22-5c5ae1ac9132\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic_comment</th>\n","      <th>civil_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2778</td>\n","      <td>2778</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>1108</td>\n","      <td>2778</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>yurope is fucking awesome that way , yeah s .</td>\n","      <td>or the loud  one - thousand ton beast roaring towards you howling its horn .</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f4e950-2241-4ff0-9f22-5c5ae1ac9132')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d9f4e950-2241-4ff0-9f22-5c5ae1ac9132 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d9f4e950-2241-4ff0-9f22-5c5ae1ac9132');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["To evaluate the paraphrasing algorithms, we will need a test set. Because one toxic comment in the dataset may have several paraphrases, we need to separate them to avoid leakages."],"metadata":{"id":"5IH7FDk6UKFU"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train_texts, test_texts = train_test_split(data.toxic_comment.drop_duplicates(), random_state=1, test_size=100)\n","train_texts, test_texts = set(train_texts), set(test_texts)\n","\n","train_data = data[data.toxic_comment.apply(lambda x: x in train_texts)]\n","test_data = data[data.toxic_comment.apply(lambda x: x in test_texts)]\n","print(train_data.shape, test_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"311AKVXQU0yn","outputId":"6a4f9b6b-2685-47d1-d117-9f95150997bd","executionInfo":{"status":"ok","timestamp":1670345290744,"user_tz":-60,"elapsed":2,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2529, 2) (249, 2)\n"]}]},{"cell_type":"markdown","source":["For evaluation, we will use BLEU (see https://github.com/mjpost/sacrebleu#variable-number-of-references for interface description)"],"metadata":{"id":"HrBnMG7YVujM"}},{"cell_type":"code","source":["from sacrebleu.metrics import BLEU\n","refs = [\n","    # First set of references\n","    ['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.'],\n","    # Second set of references\n","    ['The dog had bit the man.', 'No one was surprised.', 'The man had bitten the dog.'],\n","]\n","sys = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n","bleu = BLEU(force=True)\n","print(bleu.corpus_score(sys, refs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5Ff8L7sVyAn","outputId":"de8180db-f5d0-4ba8-9a7e-d3ac855b37be","executionInfo":{"status":"ok","timestamp":1670345388233,"user_tz":-60,"elapsed":421,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU = 48.53 82.4/50.0/45.5/37.5 (BP = 0.943 ratio = 0.944 hyp_len = 17 ref_len = 18)\n"]}]},{"cell_type":"markdown","source":["We will re-format the test set for easier BLEU calculation:"],"metadata":{"id":"3ffc-ih_XGMW"}},{"cell_type":"code","source":["test_inputs = []\n","test_outputs = []\n","for k, v in test_data.groupby('toxic_comment'):\n","    test_inputs.append(k)\n","    test_outputs.append(v.civil_comment.tolist())\n","max_n_refs = max(len(r) for r in test_outputs)\n","test_outputs_transposed = [[item[i] if i < len(item) else '' for item in test_outputs] for i in range(max_n_refs)]\n","\n","print(bleu.corpus_score(test_inputs, test_outputs_transposed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxVfbFRKWFxL","outputId":"40b269ce-917a-4533-b50c-0335cfac2d93","executionInfo":{"status":"ok","timestamp":1670345480805,"user_tz":-60,"elapsed":519,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU = 49.10 69.4/53.6/43.7/35.8 (BP = 1.000 ratio = 1.124 hyp_len = 1242 ref_len = 1105)\n"]}]},{"cell_type":"markdown","source":["We can see that just repeating the original (toxic) sentence gives us 49% BLEU.\n","\n","Can we do better with a GPT model?"],"metadata":{"id":"OsTi2EoEXnfr"}},{"cell_type":"markdown","source":["### Try zero-shot and few-shot generation"],"metadata":{"id":"dt9XYZ2HYKTW"}},{"cell_type":"code","source":["row = train_data.sample(1, random_state=20)\n","bad_text = row.toxic_comment.iloc[0]\n","row"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":78},"id":"Ro6WVeumZHG8","outputId":"618dcf03-591d-4dff-c3f5-fd689465fee0","executionInfo":{"status":"ok","timestamp":1670345602690,"user_tz":-60,"elapsed":468,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                       toxic_comment  \\\n","1200  if you think a town in texas would cover this kind of shit up you 're insane .   \n","\n","                                                                       civil_comment  \n","1200  If you think a town in texas would cover something like this up..you are wrong  "],"text/html":["\n","  <div id=\"df-55d8332d-4c09-4c5e-9684-e3a1f46761e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic_comment</th>\n","      <th>civil_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1200</th>\n","      <td>if you think a town in texas would cover this kind of shit up you 're insane .</td>\n","      <td>If you think a town in texas would cover something like this up..you are wrong</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55d8332d-4c09-4c5e-9684-e3a1f46761e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55d8332d-4c09-4c5e-9684-e3a1f46761e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55d8332d-4c09-4c5e-9684-e3a1f46761e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["template = ' a toxic text: {}\\n a civil rephrase:'"],"metadata":{"id":"Ecdq3UU3Ytdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer(template.format(bad_text), return_tensors='pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RX5rBPtVZYjh","outputId":"0960c683-cf39-4248-e517-b6f47972520b","executionInfo":{"status":"ok","timestamp":1670345629367,"user_tz":-60,"elapsed":2,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  257, 11422,  2420,    25,   611,   345,   892,   257,  3240,   287,\n","         48659,   292,   561,  3002,   428,  1611,   286,  7510,   510,   345,\n","           705,   260, 13251,   764,   198,   257,  3026,   302, 34675,    25]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["inputs = tokenizer(template.format(bad_text), return_tensors='pt').to(model.device)\n","length = inputs.input_ids.shape[1]\n","\n","beam_outputs = model.generate(\n","    **inputs,\n","    max_length=100,\n","    min_length=length+3,  # the new text should be at least 3 tokens long\n","    num_beams=5,\n","    num_return_sequences=1,\n","    early_stopping=True,\n","    eos_token_id=END_OF_LINE,\n",")\n","\n","for i, beam_output in enumerate(beam_outputs):\n","  print(tokenizer.decode(beam_output, skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLNkyu1dY1Qo","outputId":"962edef8-24fd-4b29-a225-dd9448b03b59","executionInfo":{"status":"ok","timestamp":1670345691789,"user_tz":-60,"elapsed":3488,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" a toxic text: if you think a town in texas would cover this kind of shit up you're insane.\n"," a civil rephrase: if you think a town in texas would cover this kind of shit up\n","\n"]}]},{"cell_type":"markdown","source":["Zero-shot learning does not work well enough. Let's try a few-shot approach."],"metadata":{"id":"OZKYta9kaANW"}},{"cell_type":"code","source":["examples = train_data.sample(3, random_state=20)\n","examples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"tR1hYs9YaeJ6","outputId":"3baa94da-6dc9-4914-a075-1d84cf66fc11","executionInfo":{"status":"ok","timestamp":1670345729136,"user_tz":-60,"elapsed":473,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                       toxic_comment  \\\n","1200  if you think a town in texas would cover this kind of shit up you 're insane .   \n","2294                                  this shit has been happening for generations .   \n","2593                             yah some straight up glory hole shit to , no less .   \n","\n","                                                                       civil_comment  \n","1200  If you think a town in texas would cover something like this up..you are wrong  \n","2294                                    Its something that has been there in decades  \n","2593                                  No less, some straight up glory hole stuff to.  "],"text/html":["\n","  <div id=\"df-fab11606-7e3c-49d5-9705-08d7bfcf9ba9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic_comment</th>\n","      <th>civil_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1200</th>\n","      <td>if you think a town in texas would cover this kind of shit up you 're insane .</td>\n","      <td>If you think a town in texas would cover something like this up..you are wrong</td>\n","    </tr>\n","    <tr>\n","      <th>2294</th>\n","      <td>this shit has been happening for generations .</td>\n","      <td>Its something that has been there in decades</td>\n","    </tr>\n","    <tr>\n","      <th>2593</th>\n","      <td>yah some straight up glory hole shit to , no less .</td>\n","      <td>No less, some straight up glory hole stuff to.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fab11606-7e3c-49d5-9705-08d7bfcf9ba9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fab11606-7e3c-49d5-9705-08d7bfcf9ba9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fab11606-7e3c-49d5-9705-08d7bfcf9ba9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["template2 = '\\n\\n'.join([template.format(' ' + row.toxic_comment) + ' ' + row.civil_comment for i, row in examples.iterrows()] + [template])"],"metadata":{"id":"Y-OsPcYya0am"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(template2.format(bad_text), return_tensors='pt').to(model.device)\n","length = inputs.input_ids.shape[1]\n","\n","beam_outputs = model.generate(\n","    **inputs,\n","    max_length=length+100,\n","    min_length=length+3,  # the new text should be at least 3 tokens long\n","    num_beams=5,\n","    num_return_sequences=1,\n","    early_stopping=True,\n","    eos_token_id=END_OF_LINE,\n",")\n","\n","for i, beam_output in enumerate(beam_outputs):\n","  print(tokenizer.decode(beam_output, skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alV3lniga2Vh","outputId":"76876e8d-28d9-48cd-9ec9-4e313d5fe669","executionInfo":{"status":"ok","timestamp":1670345806399,"user_tz":-60,"elapsed":430,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" a toxic text:  if you think a town in texas would cover this kind of shit up you're insane.\n"," a civil rephrase: If you think a town in texas would cover something like this up..you are wrong\n","\n"," a toxic text:  this shit has been happening for generations.\n"," a civil rephrase: Its something that has been there in decades\n","\n"," a toxic text:  yah some straight up glory hole shit to, no less.\n"," a civil rephrase: No less, some straight up glory hole stuff to.\n","\n"," a toxic text: if you think a town in texas would cover this kind of shit up you're insane.\n"," a civil rephrase: If you think a town in texas would cover this kind of shit up you're insane.\n","\n"]}]},{"cell_type":"markdown","source":["Still, the model does not seem to understand what we want from it.\n","\n","Let's try to quantify this."],"metadata":{"id":"7Vku5xjMbK9_"}},{"cell_type":"code","source":["def generate(prompt):\n","    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n","    length = inputs.input_ids.shape[1]\n","\n","    beam_outputs = model.generate(\n","        **inputs,\n","        max_length=length+32,\n","        min_length=length+3,  # the new text should be at least 3 tokens long\n","        num_beams=3,\n","        num_return_sequences=1,\n","        early_stopping=True,\n","        eos_token_id=END_OF_LINE,\n","    )\n","    return tokenizer.decode(beam_outputs[0][length:], skip_special_tokens=True).strip()\n","\n","print(generate(template2.format(bad_text)))"],"metadata":{"id":"0FE4fGs2b7p9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3881137a-b49a-4f97-cb27-d19b5e5fb261","executionInfo":{"status":"ok","timestamp":1670345840665,"user_tz":-60,"elapsed":401,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["If you think a town in texas would cover this kind of shit up you're insane.\n"]}]},{"cell_type":"code","source":["from tqdm.auto import tqdm, trange"],"metadata":{"id":"1Fcmrqf4XdqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs_0shot = [generate(template.format(text)) for text in tqdm(test_inputs)]\n","print(bleu.corpus_score(outputs_0shot, test_outputs_transposed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":65,"referenced_widgets":["342291bb8fa0442296a5bba9e987b35e","9445dcf330d340dbbec8207e13d2debf","bf5fe1248dd3443d969bd6d1e80b573f","c6f2543d8e28489eb94d07b40f3048ce","785b21d7be2d4bf2bb355dc71d092abd","eb5b031aa9134dcd97d2ce0cb8152930","77af57a2ed4d4cf8a2a4666ab4094d0a","cb94e5392dae4e15a5b2a03c04accf7c","65e931c271124c03b1379c35f74094ac","444b88d366d84fc7999ac3bf5bc22847","7825cbdbc4ef405f82a3837133596a7f"]},"id":"_v5M7u7cXOWX","outputId":"c39f42ac-fd15-4681-894d-3e70014ad78c","executionInfo":{"status":"ok","timestamp":1670345878117,"user_tz":-60,"elapsed":19665,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342291bb8fa0442296a5bba9e987b35e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["BLEU = 32.83 50.6/36.2/28.7/22.1 (BP = 1.000 ratio = 1.145 hyp_len = 1069 ref_len = 934)\n"]}]},{"cell_type":"code","source":["outputs_3shot = [generate(template2.format(text)) for text in tqdm(test_inputs)]\n","print(bleu.corpus_score(outputs_3shot, test_outputs_transposed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":65,"referenced_widgets":["e6d0a644b9634f47b3b2060b4193764f","e827eb98e59a418e92400328cc8ddf3e","f8e8354a90634f0d81dc2d56188a26fc","a538ffa0fd524c919b5d13f62366afd8","55e7f44bb9fc4cab8da81fce2d1688f5","e56bae63ce0f417b87cba1247abb8362","8272c81342b64b4e878fd519e6f6d4f9","28bbebf0256e49f98217395bfdfcfebd","a8d34c20b2b04cae9f169103eb764d5e","ecb38a9843514613ae9701be8e03727e","ffbfe10024ff4d21834f9b9c4e213168"]},"id":"5iHVi7hlXRDo","outputId":"297a6288-69f8-4a86-ee0e-444be351de02","executionInfo":{"status":"ok","timestamp":1670345932437,"user_tz":-60,"elapsed":29547,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6d0a644b9634f47b3b2060b4193764f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["BLEU = 23.37 40.2/25.2/19.5/15.1 (BP = 1.000 ratio = 1.212 hyp_len = 1265 ref_len = 1044)\n"]}]},{"cell_type":"markdown","source":["We can see that often the model repeats one of the previous output examples instead of paraphrasing the last input. It is a pity."],"metadata":{"id":"4ckY21soa1mA"}},{"cell_type":"code","source":["pd.DataFrame({'x': test_inputs, 'y': outputs_3shot}).sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"iBuZe1RzaJ-g","outputId":"4f19c5cb-e3b2-43aa-c4c2-b387e0a4348e","executionInfo":{"status":"ok","timestamp":1670346108523,"user_tz":-60,"elapsed":382,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                             x  \\\n","92                                                                     yeah i hate this shit .   \n","2   all conservatives are bigoted redneck homophobes who dont care about clean air and water .   \n","70                                                       thank god for the magical fuck frog .   \n","5                                           and dumdums actually throw money at these clowns ?   \n","21                                         but you little man are a proven antialberta bigot .   \n","14                                                  assad must be shitting his pants in fear .   \n","87                                                                 what a bunch of sick lies !   \n","76                                           they 're living streaming on bbc for fucks sake .   \n","47                    i thought you were a russian troll , but maybe you are a chinese troll .   \n","57                                                                 look the shit up yourself .   \n","\n","                                                                                                                            y  \n","92                                                                             No less, some straight up glory hole stuff to.  \n","2                                   All conservatives are bigoted redneck homophobes who dont care about clean air and water.  \n","70                                                                                       Thank god for the magical fuck frog.  \n","5                                                                              No less, some straight up glory hole stuff to.  \n","21  No less, some straight up glory hole shit to, no less. a toxic text: but you little man are a proven antialberta bigot. a  \n","14                                                                             No less, some straight up glory hole stuff to.  \n","87                                                                                                 What a bunch of sick lies!  \n","76                                                                             No less, some straight up glory hole stuff to.  \n","47                                                     i thought you were a russian troll, but maybe you are a chinese troll.  \n","57                                                                                                 Look the shit up yourself.  "],"text/html":["\n","  <div id=\"df-4d78c88f-3be5-49eb-a760-17ff9844b938\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>92</th>\n","      <td>yeah i hate this shit .</td>\n","      <td>No less, some straight up glory hole stuff to.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>all conservatives are bigoted redneck homophobes who dont care about clean air and water .</td>\n","      <td>All conservatives are bigoted redneck homophobes who dont care about clean air and water.</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>thank god for the magical fuck frog .</td>\n","      <td>Thank god for the magical fuck frog.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>and dumdums actually throw money at these clowns ?</td>\n","      <td>No less, some straight up glory hole stuff to.</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>but you little man are a proven antialberta bigot .</td>\n","      <td>No less, some straight up glory hole shit to, no less. a toxic text: but you little man are a proven antialberta bigot. a</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>assad must be shitting his pants in fear .</td>\n","      <td>No less, some straight up glory hole stuff to.</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>what a bunch of sick lies !</td>\n","      <td>What a bunch of sick lies!</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>they 're living streaming on bbc for fucks sake .</td>\n","      <td>No less, some straight up glory hole stuff to.</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>i thought you were a russian troll , but maybe you are a chinese troll .</td>\n","      <td>i thought you were a russian troll, but maybe you are a chinese troll.</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>look the shit up yourself .</td>\n","      <td>Look the shit up yourself.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d78c88f-3be5-49eb-a760-17ff9844b938')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4d78c88f-3be5-49eb-a760-17ff9844b938 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4d78c88f-3be5-49eb-a760-17ff9844b938');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["## Prompt tuning"],"metadata":{"id":"fwUMpCLRZeLt"}},{"cell_type":"markdown","source":["Instead of manually engineering the prompt, we can just learn it with gradient descent!\n","\n","We will code it manually. Instead, you can use a library by Sber, [RuPrompts](https://github.com/ai-forever/ru-prompts) (see a [post](https://habr.com/ru/company/sberdevices/blog/596103/) about it in Russian)."],"metadata":{"id":"SFDUVakCZjMa"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"GiFsPmJGZnsM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We initialize the prompts as a matrices of embeddings of random tokens.\n","\n","The inputs to train the model will be like `<promtp1><toxic text>\\n<prompt2><safe text>\\n`."],"metadata":{"id":"YsVfOLB8c04H"}},{"cell_type":"code","source":["prompt_matrix1 = torch.nn.Parameter(\n","    data=model.transformer.wte(torch.randint(0, len(tokenizer), size=(50,)).to(model.device).unsqueeze(0)),\n",")\n","prompt_matrix2 = torch.nn.Parameter(\n","    data=model.transformer.wte(torch.randint(0, len(tokenizer), size=(50,)).to(model.device).unsqueeze(0)),\n",")\n","prompt_matrix1"],"metadata":{"id":"3PxtxaHRcDie","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1da87b38-c9de-457b-c95a-6bced84c9b85","executionInfo":{"status":"ok","timestamp":1670346325889,"user_tz":-60,"elapsed":497,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[[ 0.0107,  0.0902,  0.1795,  ...,  0.0869,  0.0159,  0.0944],\n","         [-0.0170, -0.1271,  0.1674,  ..., -0.0184, -0.0570, -0.1476],\n","         [ 0.0368, -0.0300,  0.1702,  ...,  0.1399,  0.0258, -0.1304],\n","         ...,\n","         [-0.1700, -0.2485,  0.1894,  ..., -0.1558, -0.0486,  0.0789],\n","         [ 0.1509,  0.0297,  0.1237,  ...,  0.0464, -0.1738, -0.0932],\n","         [-0.2011, -0.2117,  0.0212,  ...,  0.0716, -0.1405,  0.3140]]],\n","       device='cuda:0', requires_grad=True)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["For simplicity, we use batch_size=1 here, but a more elaborate training loop would use larger batches.\n"],"metadata":{"id":"y44MY1mShjUs"}},{"cell_type":"code","source":["prompt_matrix1.shape, prompt_matrix1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGoqFF9XZkRo","executionInfo":{"status":"ok","timestamp":1670346338301,"user_tz":-60,"elapsed":7,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}},"outputId":"76e233d5-e234-47df-e05c-c2408bba33ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 50, 768]), torch.Size([1, 50, 768]))"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["def compute_loss(x_text, y_text):\n","    x_ids = tokenizer(x_text + '\\n', return_tensors='pt', add_prefix_space=True).to(model.device).input_ids\n","    y_ids = tokenizer(y_text + '\\n', return_tensors='pt', add_prefix_space=True).to(model.device).input_ids\n","    input_embeds = torch.cat([prompt_matrix1, model.transformer.wte(x_ids), prompt_matrix2, model.transformer.wte(y_ids)], 1)\n","    labels = torch.cat([torch.tensor([[-100]]).to(model.device).repeat(1, prompt_matrix1.shape[1] + x_ids.shape[1] + prompt_matrix2.shape[1] ), y_ids], 1)\n","    out = model(\n","        inputs_embeds=input_embeds,\n","        labels=labels\n","    )\n","    return out.loss"],"metadata":{"id":"xQpv7aztf4mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","optimizer = Adam([prompt_matrix1, prompt_matrix2], lr=1e-4)"],"metadata":{"id":"4qENbp0BgTOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in trange(1):\n","    sum_loss = 0\n","    tq = tqdm(train_data.sample(frac=1.0).values)\n","    for i, (x_text, y_text) in enumerate(tq):\n","        loss = compute_loss(x_text, y_text)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        sum_loss += loss.item()\n","        tq.set_description(str(loss.item()))\n","    print('epoch', epoch, 'loss', sum_loss / len(train_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97,"referenced_widgets":["5f8cf359f04146c7ba1e655fdc23f0de","192aae3c85604ba1912ae7c68223dedd","da28dfa422c04822a36039730c5d7ab7","f1aef256faac42cc82a45d41375ba717","6594a7e200614d03bbc33580d5ca8d4e","f5f786d1896f4df299f2fe15821d8181","8868d3587dd44c98a9a6c9d02c04f398","e019239cea6c40f288d28492dae5d0b0","ccbf573016664a79ad8b5b1761fbaa4d","398bb71f17bf4c89a1451af098ab5130","9fa007bf7f624a129dff9925b70b794d","f74355c9517a4e249d2369477e6fd2de","bd3d801ca0984e20af04de607ff5dca6","11d2650bff54453a8875a6e0077a1d0b","6bb39f6d4277493e9a7fc2d130b9a34f","9ddd57db06204f0ca0048ae447014bc4","f373efae00d6467cb20c623bdbebc92d","af78d1592d364706acea748be84c1398","8889a068550042bab820739d7afd4662","dff15591cfb04a58878a430396b8335b","946b53ba521548d989c70233909c3d31","f921ee72030b47178c1c3ef83f680aa8"]},"id":"EXjYIHcSgbR6","outputId":"d86e5403-830a-4c41-cd9b-a01c286b43e7","executionInfo":{"status":"ok","timestamp":1670346640978,"user_tz":-60,"elapsed":140815,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8cf359f04146c7ba1e655fdc23f0de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2529 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74355c9517a4e249d2369477e6fd2de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 0 loss 2.4177038870860863\n"]}]},{"cell_type":"code","source":["def generate_with_soft_prompt(text):\n","    x_ids = tokenizer(text + '\\n', return_tensors='pt', add_prefix_space=True).to(model.device).input_ids\n","    input_embeds = torch.cat([prompt_matrix1, model.transformer.wte(x_ids), prompt_matrix2], 1)\n","\n","    # we are using greedy decoding, because model.generate() does not support inputs_embeds for GPT so far.\n","    # see https://github.com/huggingface/transformers/issues/6535#issuecomment-983454474 for discussion.\n","    with torch.inference_mode():\n","        out = model(inputs_embeds=input_embeds)\n","\n","    result = []\n","    for i in range(100):\n","        with torch.inference_mode():\n","            i2 = out.logits[0, -1, :].argmax().unsqueeze(0).unsqueeze(0)\n","            if i2.item() == END_OF_LINE:\n","                break\n","            result.append(i2.item())\n","            out = model(input_ids=i2, past_key_values=out.past_key_values)\n","    return tokenizer.decode(result).strip()"],"metadata":{"id":"p8bPWDpSrvoR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_with_soft_prompt('Go fuck yourself!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"toW5sI-ipcoi","outputId":"852e2258-a6f0-427e-e7bd-1c14342b00df","executionInfo":{"status":"ok","timestamp":1670346640980,"user_tz":-60,"elapsed":13,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Go fuck yourself!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["generate_with_soft_prompt('Who is this idiot?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"QsJhhnvwsCk0","outputId":"2e283402-aeba-4b09-c653-9a58cd012952","executionInfo":{"status":"ok","timestamp":1670346640980,"user_tz":-60,"elapsed":11,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Who is this idiot?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["outputs_pt = [generate_with_soft_prompt(text) for text in tqdm(test_inputs)]\n","print(bleu.corpus_score(outputs_pt, test_outputs_transposed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":65,"referenced_widgets":["e7a621c44e3c49c497e3fa8d97b18e87","54eab803c0ff41d49920c834fef0cf0c","285c9bc84cec44b2b08bb8aa8d7d6b5f","ba75cd47a13f48bd8109a8ccc7a6c4ce","63b95ff2b3a54e51b56e3f8d90066b41","8198b7fbeb03444aa5c61d8e6db43cd2","fda90f847f92478e82c2706328e05602","4eebd94dd44546b088ac8261cd482f06","f740d297bc4b4ec1a1d074c875e95a6e","6f635e7bb78a4fcaafe31583965f14bf","b801dbf70930491384b61f7a4b0e0634"]},"id":"CihRGqud3nwr","outputId":"3f7f3363-344a-434b-cafd-76c6b017173e","executionInfo":{"status":"ok","timestamp":1670346654960,"user_tz":-60,"elapsed":13989,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a621c44e3c49c497e3fa8d97b18e87"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["BLEU = 41.05 58.6/45.0/36.5/29.5 (BP = 1.000 ratio = 1.249 hyp_len = 1239 ref_len = 992)\n"]}]},{"cell_type":"markdown","source":["The outputs look a little bit btter than inputs, but the BLEU is still 49% – just as if we used the original texts."],"metadata":{"id":"XC-i5Kb74c-a"}},{"cell_type":"code","source":["pd.DataFrame({'x': test_inputs, 'y': outputs_pt}).sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"i423WOUp33IO","outputId":"02ce254b-463c-451a-a863-f363c50ac7d0","executionInfo":{"status":"ok","timestamp":1670346654961,"user_tz":-60,"elapsed":10,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                         x  \\\n","74       the uo needs to step up , and potty train their brats in public .   \n","72                    that more than enough room statement is ridiculous .   \n","81                      this asshole was arrested twice , in one month , .   \n","63           people don t even wash their damn hands after taking a shit .   \n","14                              assad must be shitting his pants in fear .   \n","75              these people deserve all the contempt and scorn of society   \n","16                                     beers endorse shitting in the woods   \n","10  any of us who did half this shit would be locked the fuck up already .   \n","19                                 but damn it it has to be trumps fault !   \n","53       it would be fucking illegal as shit to straight up kill someone .   \n","\n","                                                                        y  \n","74         The uo needs to step up and potty train their brats in public.  \n","72                    That more than enough room statement is ridiculous.  \n","81                        This asshole was arrested twice, in one month,.  \n","63                      People don t wash their hands after taking a shit  \n","14                               Assad must be shitting his pants in fear  \n","75             These people deserve all the contempt and scorn of society  \n","16                                     Beer endorse shitting in the woods  \n","10  Any of us who did half this shit would be locked the fuck up already.  \n","19                                     but damn it has to be trumps fault  \n","53                            It would be illegal as shit to kill someone  "],"text/html":["\n","  <div id=\"df-9c4b606d-fcdd-4a8e-b056-6c6d5bb54f34\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>74</th>\n","      <td>the uo needs to step up , and potty train their brats in public .</td>\n","      <td>The uo needs to step up and potty train their brats in public.</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>that more than enough room statement is ridiculous .</td>\n","      <td>That more than enough room statement is ridiculous.</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>this asshole was arrested twice , in one month , .</td>\n","      <td>This asshole was arrested twice, in one month,.</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>people don t even wash their damn hands after taking a shit .</td>\n","      <td>People don t wash their hands after taking a shit</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>assad must be shitting his pants in fear .</td>\n","      <td>Assad must be shitting his pants in fear</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>these people deserve all the contempt and scorn of society</td>\n","      <td>These people deserve all the contempt and scorn of society</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>beers endorse shitting in the woods</td>\n","      <td>Beer endorse shitting in the woods</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>any of us who did half this shit would be locked the fuck up already .</td>\n","      <td>Any of us who did half this shit would be locked the fuck up already.</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>but damn it it has to be trumps fault !</td>\n","      <td>but damn it has to be trumps fault</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>it would be fucking illegal as shit to straight up kill someone .</td>\n","      <td>It would be illegal as shit to kill someone</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c4b606d-fcdd-4a8e-b056-6c6d5bb54f34')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9c4b606d-fcdd-4a8e-b056-6c6d5bb54f34 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9c4b606d-fcdd-4a8e-b056-6c6d5bb54f34');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## Full model tuning"],"metadata":{"id":"0nP1_rXt4Bac"}},{"cell_type":"markdown","source":["Let us now use the simple prompt, but fine-tune the model itself."],"metadata":{"id":"_v0BEyyQ4o48"}},{"cell_type":"code","source":["template"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"hkD8Y3E944WW","outputId":"c2bddebd-4029-4b01-bb53-7c6c2657e07c","executionInfo":{"status":"ok","timestamp":1670346704256,"user_tz":-60,"elapsed":992,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' a toxic text: {}\\n a civil rephrase:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["def compute_loss(x_text, y_text):\n","    x_ids = tokenizer(template.format(x_text), return_tensors='pt', add_prefix_space=True).to(model.device).input_ids\n","    y_ids = tokenizer(y_text + '\\n', return_tensors='pt', add_prefix_space=True).to(model.device).input_ids\n","    input_ids = torch.cat([x_ids, y_ids], 1)\n","    labels = torch.cat([torch.tensor([[-100]]).to(model.device).repeat(1, x_ids.shape[1]), y_ids], 1)\n","    out = model(\n","        input_ids=input_ids,\n","        labels=labels\n","    )\n","    return out.loss"],"metadata":{"id":"SpRYXxVw4tGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","optimizer = Adam(model.parameters(), lr=1e-4)"],"metadata":{"id":"1hb0ZzWg5GZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train()\n","for epoch in trange(1):\n","    sum_loss = 0\n","    tq = tqdm(train_data.sample(frac=1.0).values)\n","    for i, (x_text, y_text) in enumerate(tq):\n","        loss = compute_loss(x_text, y_text)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        sum_loss += loss.item()\n","        tq.set_description(str(loss.item()))\n","    print('epoch', epoch, 'loss', sum_loss / len(train_data))\n","model.eval();"],"metadata":{"id":"W7iOG_625LT_","colab":{"base_uri":"https://localhost:8080/","height":97,"referenced_widgets":["fb6982a1981346a89d80e13a381471b9","e883fab69a654211b9c25355480b02eb","8bbfb2dde74c4d0cb04b628d2453ef99","c52f7964e0bc43119c0db39202b70b75","19aa7e418f9e489d8f529f591684d28b","5069dbe6fe16496d8bd1bb8e0ea6db36","38526c7411ad4135b75913f148484068","54e9cc5b40a64781a2d8a3794d9ca5e7","e7ef3d5236864b2eb8ddd21a9ca0fe45","b760cd2ef9374e42a2eaaca491eacee3","4701fcc644d24c6783126c0865bee192","0813c5db8e804be7b7ef7eb443c2857e","815aa269eb8b4410b3a1b5d0684c943f","27d6bfe53e5f4875a57b889de836f9bf","22a2c177de6b40caac76b2c8f1f2d40b","2de3484f64204a098f9d693a80817cad","af85b39708b847059ac0d82c9c67851c","2db5cb63803d44a1be120df7346391cd","1c32e3e4643d46b9828e08567e8233ec","7241db72c80d406cadbb73ca6cdb906e","8108cf6ad8fa44adbcaccde7b8ab6c5e","b8b3cae9d2104e95b41589ea654e6189"]},"outputId":"77bce979-e91e-4674-9866-9b28ead1a1b4","executionInfo":{"status":"ok","timestamp":1670346955949,"user_tz":-60,"elapsed":216214,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb6982a1981346a89d80e13a381471b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2529 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0813c5db8e804be7b7ef7eb443c2857e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 0 loss 1.9432618660199024\n"]}]},{"cell_type":"code","source":["print(generate(template.format('Go fuck yourself!')))\n","print(generate(template.format('Who is this idiot?')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKTjHFzo5Sps","outputId":"21c3bf40-cd43-4131-9775-0ac7a953dd3e","executionInfo":{"status":"ok","timestamp":1670346955950,"user_tz":-60,"elapsed":22,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Go away!\n","Who is this person?\n"]}]},{"cell_type":"code","source":["outputs_full = [generate(template.format(text)) for text in tqdm(test_inputs)]\n","print(bleu.corpus_score(outputs_full, test_outputs_transposed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":65,"referenced_widgets":["298ecf71a4f946acbcb2b1bb7fbbb0fa","dd9d4e4328dc4ef2bc1db3cc0f1df090","2b4a3c278e8240308da6ce430690b930","a67059a3bdcd4aebbe3ada34fba95847","81d9091f8bd3472bae635d57f0d7a361","0500f4b3d1ef4717a61184a2a4f3ee76","20bfa6a1000f4366beecebb3da4cddb1","78d304765f0e4b8abed6ac784164cc38","84a0e46a8e20488ba92d9c7eecbb28f7","aa053c59d2f64d30a2c2422ab927e86c","b3fa467dff9e42dd9cafc70376f884e6"]},"id":"yDGG_Lhw6xHd","outputId":"2bec75c6-d0fb-4aef-8651-a2c9031560a9","executionInfo":{"status":"ok","timestamp":1670346973012,"user_tz":-60,"elapsed":17073,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"298ecf71a4f946acbcb2b1bb7fbbb0fa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["BLEU = 54.52 73.2/58.6/49.4/41.7 (BP = 1.000 ratio = 1.049 hyp_len = 1003 ref_len = 956)\n"]}]},{"cell_type":"markdown","source":["At least after fine-tuning the whole model we were able to beat the \"do not change the text\" baseline.\n","\n","But who knows, maybe with larger model sizes, few-shot or prompt-tuning methods would work better."],"metadata":{"id":"egjX0SQF61na"}},{"cell_type":"code","source":["pd.DataFrame({'x': test_inputs, 'y': outputs_full}).sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"7dRKtjof7H8L","outputId":"ac1cbfe4-90d7-4228-e2f9-3d04e7565f2f","executionInfo":{"status":"ok","timestamp":1670346973013,"user_tz":-60,"elapsed":11,"user":{"displayName":"Irina Nikishina","userId":"06548341279621459266"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                           x  \\\n","34                                       haha , fuck me we need to wake up .   \n","99                         your questions are kind of odd , are you rapist ?   \n","47  i thought you were a russian troll , but maybe you are a chinese troll .   \n","77                                     they are worse than dirty sicilians .   \n","8                               another piece of useless manufactured junk !   \n","81                        this asshole was arrested twice , in one month , .   \n","6            and redditors still choose to keep their heads up their asses .   \n","31                fuck novick and his supposed fighting for the little man .   \n","38       holy fucking shit ! i just read that as \" ebola confirmed in mail .   \n","73                                           that scum is smiling in court !   \n","\n","                                                                         y  \n","34                                                     We need to wake up.  \n","99                         Your questions are kind of odd, are you rapist?  \n","47  I thought you were a Russian troll, but maybe you are a Chinese troll.  \n","77                                                      they are not good.  \n","8                                                 Another piece of useless  \n","81                          this person was arrested twice, in one month,.  \n","6            and redditors still choose to keep their heads up their asses  \n","31                                                He is not a good person.  \n","38                          I just read that as \" ebola confirmed in mail.  \n","73                                                  that person is smiling  "],"text/html":["\n","  <div id=\"df-7ccd61d8-809f-451f-91c9-471ed0a164ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>34</th>\n","      <td>haha , fuck me we need to wake up .</td>\n","      <td>We need to wake up.</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>your questions are kind of odd , are you rapist ?</td>\n","      <td>Your questions are kind of odd, are you rapist?</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>i thought you were a russian troll , but maybe you are a chinese troll .</td>\n","      <td>I thought you were a Russian troll, but maybe you are a Chinese troll.</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>they are worse than dirty sicilians .</td>\n","      <td>they are not good.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>another piece of useless manufactured junk !</td>\n","      <td>Another piece of useless</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>this asshole was arrested twice , in one month , .</td>\n","      <td>this person was arrested twice, in one month,.</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>and redditors still choose to keep their heads up their asses .</td>\n","      <td>and redditors still choose to keep their heads up their asses</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>fuck novick and his supposed fighting for the little man .</td>\n","      <td>He is not a good person.</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>holy fucking shit ! i just read that as \" ebola confirmed in mail .</td>\n","      <td>I just read that as \" ebola confirmed in mail.</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>that scum is smiling in court !</td>\n","      <td>that person is smiling</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ccd61d8-809f-451f-91c9-471ed0a164ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7ccd61d8-809f-451f-91c9-471ed0a164ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7ccd61d8-809f-451f-91c9-471ed0a164ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":[],"metadata":{"id":"bxjHF8KfqrKi"},"execution_count":null,"outputs":[]}]}